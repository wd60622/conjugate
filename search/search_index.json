{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Conjugate Models","text":"<p>Bayesian conjugate models in Python</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install conjugate-models\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Connection to Scipy Distributions with <code>dist</code> attribute</li> <li>Built in Plotting with <code>plot_pdf</code> and <code>plot_pmf</code> methods</li> <li>Vectorized Operations for parameters and data</li> <li>Indexing Parameters for subsetting and slicing</li> <li>Generalized Numerical Inputs for any inputs that act like numbers<ul> <li>Out of box compatibility with <code>polars</code>, <code>pandas</code>, <code>numpy</code>, and more.</li> </ul> </li> <li>Unsupported Distributions for sampling from unsupported distributions</li> </ul>"},{"location":"#supported-models","title":"Supported Models","text":"<p>Many likelihoods are supported including</p> <ul> <li><code>Bernoulli</code> / <code>Binomial</code></li> <li><code>Categorical</code> / <code>Multinomial</code></li> <li><code>Poisson</code></li> <li><code>Normal</code> (including linear regression)</li> <li>and many more</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":"<ol> <li>Define prior distribution from <code>distributions</code> module</li> <li>Pass data and prior into model from <code>models</code> modules</li> <li>Analytics with posterior and posterior predictive distributions</li> </ol> <pre><code>from conjugate.distributions import Beta, BetaBinomial\nfrom conjugate.models import binomial_beta, binomial_beta_predictive\n\n# Observed Data\nX = 4\nN = 10\n\n# Analytics\nprior = Beta(1, 1)\nprior_predictive: BetaBinomial = binomial_beta_predictive(n=N, distribution=prior)\n\nposterior: Beta = binomial_beta(n=N, x=X, prior=prior)\nposterior_predictive: BetaBinomial = binomial_beta_predictive(n=N, distribution=posterior) \n</code></pre> <p>From here, do any analysis you'd like!</p> <pre><code># Figure\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(ncols=2)\n\nax = axes[0]\nax = posterior.plot_pdf(ax=ax, label=\"posterior\")\nprior.plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x=X/N, color=\"black\", ymax=0.05, label=\"MLE\")\nax.set_title(\"Success Rate\")\nax.legend()\n\nax = axes[1]\nposterior_predictive.plot_pmf(ax=ax, label=\"posterior predictive\")\nprior_predictive.plot_pmf(ax=ax, label=\"prior predictive\")\nax.axvline(x=X, color=\"black\", ymax=0.05, label=\"Sample\")\nax.set_title(\"Number of Successes\")\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"#too-simple","title":"Too Simple?","text":"<p>Simple model, sure. Useful model, potentially.</p> <p>Constant probability of success, <code>p</code>, for <code>n</code> trials.</p> <pre><code>rng = np.random.default_rng(42)\n\n# Observed Data\nn_times = 75\np = np.repeat(0.5, n_times)\nsamples = rng.binomial(n=1, p=p, size=n_times)\n\n# Model\nn = np.arange(n_times) + 1\nprior = Beta(alpha=1, beta=1)\nposterior = binomial_beta(n=n, x=samples.cumsum(), prior=prior)\n\n# Figure\nplt.plot(n, p, color=\"black\", label=\"true p\", linestyle=\"--\")\nplt.scatter(n, samples, color=\"black\", label=\"observed samples\")\nplt.plot(n, posterior.dist.mean(), color=\"red\", label=\"posterior mean\")\n# fill between the 95% credible interval\nplt.fill_between(\n    n, \n    posterior.dist.ppf(0.025),\n    posterior.dist.ppf(0.975),\n    color=\"red\",\n    alpha=0.2,\n    label=\"95% credible interval\",\n)\npadding = 0.025\nplt.ylim(0 - padding, 1 + padding)\nplt.xlim(1, n_times)\nplt.legend(loc=\"best\")\nplt.xlabel(\"Number of trials\")\nplt.ylabel(\"Probability\")\nplt.show()\n</code></pre> <p></p> <p>Even with a moving probability, this simple to implement model can be useful.</p> <pre><code>...\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\np_raw = rng.normal(loc=0, scale=0.2, size=n_times).cumsum()\np = sigmoid(p_raw)\n\n...\n</code></pre> <p></p>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Conjugate Priors</li> </ul>"},{"location":"distributions/","title":"Distributions","text":"<p>These are the supported distributions based on the conjugate models.</p> <p>Many have the <code>dist</code> attribute which is a scipy.stats distribution object. From there, you can use the methods from scipy.stats to get the pdf, cdf, etc.</p> <p>Distributions can be plotted using the <code>plot_pmf</code> or <code>plot_pdf</code> methods of the distribution.</p> <pre><code>from conjugate.distribution import Beta\n\nbeta = Beta(1, 1)\nscipy_dist = beta.dist\n\nprint(scipy_dist.mean())\n# 0.5\nprint(scipy_dist.ppf([0.025, 0.975]))\n# [0.025 0.975]\n\nsamples = scipy_dist.rvs(100)\n\nbeta.plot_pmf(label=\"beta distribution\")\n</code></pre> <p>Distributions like Poisson can be added with other Poissons or multiplied by numerical values in order to scale rate. For instance,</p> <pre><code>daily_rate = 0.25\ndaily_pois = Poisson(lam=daily_rate)\n\ntwo_day_pois = daily_pois + daily_pois\nweekly_pois = 7 * daily_pois\n</code></pre> <p>Below are the currently supported distributions</p>"},{"location":"distributions/#conjugate.distributions.Beta","title":"<code>Beta</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Beta distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Beta(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Beta distribution.\n\n    Args:\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        self.max_value = 1.0\n\n    @classmethod\n    def from_mean(cls, mean: NUMERIC, alpha: NUMERIC) -&gt; \"Beta\":\n        \"\"\"Alternative constructor from mean and alpha.\"\"\"\n        beta = get_beta_param_from_mean_and_alpha(mean=mean, alpha=alpha)\n        return cls(alpha=alpha, beta=beta)\n\n    @classmethod\n    def uninformative(cls) -&gt; \"Beta\":\n        return cls(alpha=1, beta=1)\n\n    @classmethod\n    def from_successes_and_failures(\n        cls, successes: NUMERIC, failures: NUMERIC\n    ) -&gt; \"Beta\":\n        \"\"\"Alternative constructor based on hyperparameter interpretation.\"\"\"\n        alpha = successes + 1\n        beta = failures + 1\n        return cls(alpha=alpha, beta=beta)\n\n    @property\n    def dist(self):\n        return stats.beta(self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Beta.from_mean","title":"<code>from_mean(mean, alpha)</code>  <code>classmethod</code>","text":"<p>Alternative constructor from mean and alpha.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_mean(cls, mean: NUMERIC, alpha: NUMERIC) -&gt; \"Beta\":\n    \"\"\"Alternative constructor from mean and alpha.\"\"\"\n    beta = get_beta_param_from_mean_and_alpha(mean=mean, alpha=alpha)\n    return cls(alpha=alpha, beta=beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Beta.from_successes_and_failures","title":"<code>from_successes_and_failures(successes, failures)</code>  <code>classmethod</code>","text":"<p>Alternative constructor based on hyperparameter interpretation.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_successes_and_failures(\n    cls, successes: NUMERIC, failures: NUMERIC\n) -&gt; \"Beta\":\n    \"\"\"Alternative constructor based on hyperparameter interpretation.\"\"\"\n    alpha = successes + 1\n    beta = failures + 1\n    return cls(alpha=alpha, beta=beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaBinomial","title":"<code>BetaBinomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Beta binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Beta binomial distribution.\n\n    Args:\n        n: number of trials\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    n: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        return stats.betabinom(self.n, self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaGeometric","title":"<code>BetaGeometric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Beta geometric distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>one_start</code> <code>bool</code> <p>whether to start at 1 or 0. Default is 1.</p> <code>True</code> Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaGeometric(DiscretePlotMixin, SliceMixin):\n    \"\"\"Beta geometric distribution.\n\n    Args:\n        alpha: shape parameter\n        beta: shape parameter\n        one_start: whether to start at 1 or 0. Default is 1.\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n    one_start: bool = True\n\n    @property\n    def dist(self):\n        return beta_geometric(self.alpha, self.beta, one_start=self.one_start)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaNegativeBinomial","title":"<code>BetaNegativeBinomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Beta negative binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of successes</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaNegativeBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Beta negative binomial distribution.\n\n    Args:\n        n: number of successes\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    n: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        if version.parse(scipy_version).release &lt; version.parse(\"1.12.0\").release:\n            msg = \"BetaNegativeBinomial.dist requires scipy &gt;= 1.12.0\"\n            raise NotImplementedError(msg)\n\n        return stats.betanbinom(self.n, self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaProportional","title":"<code>BetaProportional</code>  <code>dataclass</code>","text":"<p>Beta proportional distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>NUMERIC</code> <p>product of observations</p> required <code>q</code> <code>NUMERIC</code> <p>product of complements</p> required <code>k</code> <code>NUMERIC</code> <p>number of observations</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaProportional:\n    \"\"\"Beta proportional distribution.\n\n    Args:\n        p: product of observations\n        q: product of complements\n        k: number of observations\n\n    \"\"\"\n\n    p: NUMERIC\n    q: NUMERIC\n    k: NUMERIC\n\n    def approx_log_likelihood(\n        self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n    ) -&gt; NUMERIC:\n        \"\"\"Approximate log likelihood.\n\n        Args:\n            alpha: shape parameter\n            beta: shape parameter\n            ln: log function\n            gammaln: log gamma function\n\n        Returns:\n            log likelihood up to a constant\n\n        \"\"\"\n        return (\n            self.k * gammaln(alpha + beta)\n            + alpha * ln(self.p)\n            + beta * ln(self.q)\n            - self.k * gammaln(alpha)\n            - self.k * gammaln(beta)\n        )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaProportional.approx_log_likelihood","title":"<code>approx_log_likelihood(alpha, beta, ln=np.log, gammaln=gammaln)</code>","text":"<p>Approximate log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>ln</code> <p>log function</p> <code>log</code> <code>gammaln</code> <p>log gamma function</p> <code>gammaln</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>log likelihood up to a constant</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def approx_log_likelihood(\n    self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n) -&gt; NUMERIC:\n    \"\"\"Approximate log likelihood.\n\n    Args:\n        alpha: shape parameter\n        beta: shape parameter\n        ln: log function\n        gammaln: log gamma function\n\n    Returns:\n        log likelihood up to a constant\n\n    \"\"\"\n    return (\n        self.k * gammaln(alpha + beta)\n        + alpha * ln(self.p)\n        + beta * ln(self.q)\n        - self.k * gammaln(alpha)\n        - self.k * gammaln(beta)\n    )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Binomial","title":"<code>Binomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Binomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Binomial distribution.\n\n    Args:\n        n: number of trials\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        return stats.binom(n=self.n, p=self.p)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.CompoundGamma","title":"<code>CompoundGamma</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Compound gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required <code>lam</code> <code>NUMERIC</code> <p>rate</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass CompoundGamma(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Compound gamma distribution.\n\n    Args:\n        alpha: shape\n        beta: scale\n        lam: rate\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return compound_gamma(a=self.alpha, b=self.beta, q=self.lam)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Dirichlet","title":"<code>Dirichlet</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DirichletPlotDistMixin</code></p> <p>Dirichlet distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Dirichlet(DirichletPlotDistMixin):\n    \"\"\"Dirichlet distribution.\n\n    Args:\n        alpha: shape parameter\n\n    \"\"\"\n\n    alpha: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        self.max_value = 1.0\n\n    @classmethod\n    def uninformative(cls, n: int) -&gt; \"Dirichlet\":\n        return cls(alpha=np.ones(n))\n\n    @property\n    def dist(self):\n        if self.alpha.ndim == 1:\n            return stats.dirichlet(self.alpha)\n\n        return VectorizedDist(self.alpha, dist=stats.dirichlet)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.DirichletMultinomial","title":"<code>DirichletMultinomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SliceMixin</code></p> <p>Dirichlet multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass DirichletMultinomial(SliceMixin):\n    \"\"\"Dirichlet multinomial distribution.\n\n    Args:\n        alpha: shape parameter\n        n: number of trials\n\n    \"\"\"\n\n    alpha: NUMERIC\n    n: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.dirichlet_multinomial(self.alpha, self.n)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Exponential","title":"<code>Exponential</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>lam</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Exponential(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Exponential distribution.\n\n    Args:\n        lam: rate parameter\n\n    \"\"\"\n\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.expon(scale=self.lam)\n\n    def __mul__(self, other):\n        return Gamma(alpha=other, beta=1 / self.lam)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Gamma","title":"<code>Gamma</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Gamma distribution.</p> <p>Gamma Distribution Scipy Docmentation</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Gamma(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Gamma distribution.\n\n    &lt;a href=https://en.wikipedia.org/wiki/Gamma_distribution&gt;Gamma Distribution&lt;/a&gt;\n    &lt;a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html&gt;Scipy Docmentation&lt;/a&gt;\n\n    Args:\n        alpha: shape parameter\n        beta: rate parameter\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @classmethod\n    def from_occurrences_in_intervals(cls, occurrences: NUMERIC, intervals: NUMERIC):\n        return cls(alpha=occurrences, beta=intervals)\n\n    @property\n    def dist(self):\n        return stats.gamma(a=self.alpha, scale=1 / self.beta)\n\n    def __mul__(self, other):\n        return Gamma(alpha=self.alpha * other, beta=self.beta)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.GammaKnownRateProportional","title":"<code>GammaKnownRateProportional</code>  <code>dataclass</code>","text":"<p>Gamma known rate proportional distribution.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>NUMERIC</code> <p>prod of observations</p> required <code>b</code> <code>NUMERIC</code> <p>number of observations</p> required <code>c</code> <code>NUMERIC</code> <p>number of observations</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass GammaKnownRateProportional:\n    \"\"\"Gamma known rate proportional distribution.\n\n    Args:\n        a: prod of observations\n        b: number of observations\n        c: number of observations\n\n    \"\"\"\n\n    a: NUMERIC\n    b: NUMERIC\n    c: NUMERIC\n\n    def approx_log_likelihood(\n        self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n    ) -&gt; NUMERIC:\n        \"\"\"Approximate log likelihood.\n\n        Args:\n            alpha: shape parameter\n            beta: known rate parameter\n            ln: log function\n            gammaln: log gamma function\n\n        Returns:\n            log likelihood up to a constant\n\n        \"\"\"\n        return (\n            (alpha - 1) * ln(self.a)\n            + alpha * self.c * ln(beta)\n            - self.b * gammaln(alpha)\n        )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.GammaKnownRateProportional.approx_log_likelihood","title":"<code>approx_log_likelihood(alpha, beta, ln=np.log, gammaln=gammaln)</code>","text":"<p>Approximate log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>known rate parameter</p> required <code>ln</code> <p>log function</p> <code>log</code> <code>gammaln</code> <p>log gamma function</p> <code>gammaln</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>log likelihood up to a constant</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def approx_log_likelihood(\n    self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n) -&gt; NUMERIC:\n    \"\"\"Approximate log likelihood.\n\n    Args:\n        alpha: shape parameter\n        beta: known rate parameter\n        ln: log function\n        gammaln: log gamma function\n\n    Returns:\n        log likelihood up to a constant\n\n    \"\"\"\n    return (\n        (alpha - 1) * ln(self.a)\n        + alpha * self.c * ln(beta)\n        - self.b * gammaln(alpha)\n    )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.GammaProportional","title":"<code>GammaProportional</code>  <code>dataclass</code>","text":"<p>Gamma proportional distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>NUMERIC</code> <p>product of r observations</p> required <code>q</code> <code>NUMERIC</code> <p>sum of s observations</p> required <code>r</code> <code>NUMERIC</code> <p>number of observations for p</p> required <code>s</code> <code>NUMERIC</code> <p>number of observations for q</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass GammaProportional:\n    \"\"\"Gamma proportional distribution.\n\n    Args:\n        p: product of r observations\n        q: sum of s observations\n        r: number of observations for p\n        s: number of observations for q\n\n    \"\"\"\n\n    p: NUMERIC\n    q: NUMERIC\n    r: NUMERIC\n    s: NUMERIC\n\n    def approx_log_likelihood(\n        self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n    ) -&gt; NUMERIC:\n        \"\"\"Approximate log likelihood.\n\n        Args:\n            alpha: shape parameter\n            beta: rate parameter\n            ln: log function\n            gammaln: log gamma function\n\n        Returns:\n            log likelihood up to a constant\n\n        \"\"\"\n        return (\n            (alpha - 1) * ln(self.p)\n            - self.q * beta\n            - self.r * gammaln(alpha)\n            + self.s * alpha * ln(beta)\n        )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.GammaProportional.approx_log_likelihood","title":"<code>approx_log_likelihood(alpha, beta, ln=np.log, gammaln=gammaln)</code>","text":"<p>Approximate log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>rate parameter</p> required <code>ln</code> <p>log function</p> <code>log</code> <code>gammaln</code> <p>log gamma function</p> <code>gammaln</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>log likelihood up to a constant</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def approx_log_likelihood(\n    self, alpha: NUMERIC, beta: NUMERIC, ln=np.log, gammaln=gammaln\n) -&gt; NUMERIC:\n    \"\"\"Approximate log likelihood.\n\n    Args:\n        alpha: shape parameter\n        beta: rate parameter\n        ln: log function\n        gammaln: log gamma function\n\n    Returns:\n        log likelihood up to a constant\n\n    \"\"\"\n    return (\n        (alpha - 1) * ln(self.p)\n        - self.q * beta\n        - self.r * gammaln(alpha)\n        + self.s * alpha * ln(beta)\n    )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Geometric","title":"<code>Geometric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Geometric distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required <code>one_start</code> <code>bool</code> <p>whether to start at 1 or 0. Default is 1.</p> <code>True</code> Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Geometric(DiscretePlotMixin, SliceMixin):\n    \"\"\"Geometric distribution.\n\n    Args:\n        p: probability of success\n        one_start: whether to start at 1 or 0. Default is 1.\n\n    \"\"\"\n\n    p: NUMERIC\n    one_start: bool = True\n\n    @property\n    def dist(self):\n        loc = 0 if self.one_start else -1\n        return stats.geom(self.p, loc=loc)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Hypergeometric","title":"<code>Hypergeometric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Hypergeometric distribution.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>NUMERIC</code> <p>population size</p> required <code>k</code> <code>NUMERIC</code> <p>number of successes in the population</p> required <code>n</code> <code>NUMERIC</code> <p>number of draws</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Hypergeometric(DiscretePlotMixin, SliceMixin):\n    \"\"\"Hypergeometric distribution.\n\n    Args:\n        N: population size\n        k: number of successes in the population\n        n: number of draws\n\n    \"\"\"\n\n    N: NUMERIC\n    k: NUMERIC\n    n: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        if isinstance(self.N, np.ndarray):\n            self.max_value = self.N.max()\n        else:\n            self.max_value = self.N\n\n    @property\n    def dist(self):\n        return stats.hypergeom(self.N, self.k, self.n)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.InverseGamma","title":"<code>InverseGamma</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>InverseGamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass InverseGamma(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"InverseGamma distribution.\n\n    Args:\n        alpha: shape\n        beta: scale\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.invgamma(a=self.alpha, scale=self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.InverseWishart","title":"<code>InverseWishart</code>  <code>dataclass</code>","text":"<p>Inverse Wishart distribution.</p> <p>Parameters:</p> Name Type Description Default <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required <code>psi</code> <code>NUMERIC</code> <p>scale matrix</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass InverseWishart:\n    \"\"\"Inverse Wishart distribution.\n\n    Args:\n        nu: degrees of freedom\n        psi: scale matrix\n\n    \"\"\"\n\n    nu: NUMERIC\n    psi: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.invwishart(df=self.nu, scale=self.psi)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.LogNormal","title":"<code>LogNormal</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Log normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>standard deviation</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass LogNormal(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Log normal distribution.\n\n    Args:\n        mu: mean\n        sigma: standard deviation\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.lognorm(s=self.sigma, loc=self.mu)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Lomax","title":"<code>Lomax</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Lomax distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>lam</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Lomax(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Lomax distribution.\n\n    Args:\n        alpha: shape\n        lam: scale\n\n    \"\"\"\n\n    alpha: NUMERIC\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.lomax(c=self.alpha, scale=self.lam)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Multinomial","title":"<code>Multinomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SliceMixin</code></p> <p>Multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Multinomial(SliceMixin):\n    \"\"\"Multinomial distribution.\n\n    Args:\n        n: number of trials\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.multinomial(n=self.n, p=self.p)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.MultivariateNormal","title":"<code>MultivariateNormal</code>  <code>dataclass</code>","text":"<p>Multivariate normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>cov</code> <code>NUMERIC</code> <p>covariance matrix</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass MultivariateNormal:\n    \"\"\"Multivariate normal distribution.\n\n    Args:\n        mu: mean\n        cov: covariance matrix\n\n    \"\"\"\n\n    mu: NUMERIC\n    cov: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.multivariate_normal(mean=self.mu, cov=self.cov)\n\n    def __getitem__(self, key):\n        if isinstance(key, int):\n            return Normal(mu=self.mu[key], sigma=self.cov[key, key] ** 0.5)\n\n        return MultivariateNormal(mu=self.mu[key], cov=self.cov[key][:, key])\n</code></pre>"},{"location":"distributions/#conjugate.distributions.MultivariateStudentT","title":"<code>MultivariateStudentT</code>  <code>dataclass</code>","text":"<p>MultivariateStudentT distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>covariance matrix</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass MultivariateStudentT:\n    \"\"\"MultivariateStudentT distribution.\n\n    Args:\n        mu: mean\n        sigma: covariance matrix\n        nu: degrees of freedom\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n    nu: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.multivariate_t(loc=self.mu, shape=self.sigma, df=self.nu)\n\n    def __getitem__(self, key):\n        if isinstance(key, int):\n            return StudentT(mu=self.mu[key], sigma=self.sigma[key, key], nu=self.nu)\n\n        return MultivariateStudentT(\n            mu=self.mu[key], sigma=self.sigma[key][:, key], nu=self.nu\n        )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NegativeBinomial","title":"<code>NegativeBinomial</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Negative binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of successes</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NegativeBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Negative binomial distribution.\n\n    Args:\n        n: number of successes\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.nbinom(n=self.n, p=self.p)\n\n    def __mul__(self, other):\n        return NegativeBinomial(n=self.n * other, p=self.p)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Normal","title":"<code>Normal</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>standard deviation</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Normal(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Normal distribution.\n\n    Args:\n        mu: mean\n        sigma: standard deviation\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.norm(self.mu, self.sigma)\n\n    @classmethod\n    def uninformative(cls, sigma: NUMERIC = 1) -&gt; \"Normal\":\n        \"\"\"Uninformative normal distribution.\"\"\"\n        return cls(mu=0, sigma=sigma)\n\n    @classmethod\n    def from_mean_and_variance(cls, mean: NUMERIC, variance: NUMERIC) -&gt; \"Normal\":\n        \"\"\"Alternative constructor from mean and variance.\"\"\"\n        return cls(mu=mean, sigma=variance**0.5)\n\n    @classmethod\n    def from_mean_and_precision(cls, mean: NUMERIC, precision: NUMERIC) -&gt; \"Normal\":\n        \"\"\"Alternative constructor from mean and precision.\"\"\"\n        return cls(mu=mean, sigma=precision**-0.5)\n\n    def __mul__(self, other):\n        sigma = ((self.sigma**2) * other) ** 0.5\n        return Normal(mu=self.mu * other, sigma=sigma)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Normal.from_mean_and_precision","title":"<code>from_mean_and_precision(mean, precision)</code>  <code>classmethod</code>","text":"<p>Alternative constructor from mean and precision.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_mean_and_precision(cls, mean: NUMERIC, precision: NUMERIC) -&gt; \"Normal\":\n    \"\"\"Alternative constructor from mean and precision.\"\"\"\n    return cls(mu=mean, sigma=precision**-0.5)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Normal.from_mean_and_variance","title":"<code>from_mean_and_variance(mean, variance)</code>  <code>classmethod</code>","text":"<p>Alternative constructor from mean and variance.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_mean_and_variance(cls, mean: NUMERIC, variance: NUMERIC) -&gt; \"Normal\":\n    \"\"\"Alternative constructor from mean and variance.\"\"\"\n    return cls(mu=mean, sigma=variance**0.5)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Normal.uninformative","title":"<code>uninformative(sigma=1)</code>  <code>classmethod</code>","text":"<p>Uninformative normal distribution.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef uninformative(cls, sigma: NUMERIC = 1) -&gt; \"Normal\":\n    \"\"\"Uninformative normal distribution.\"\"\"\n    return cls(mu=0, sigma=sigma)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalGamma","title":"<code>NormalGamma</code>  <code>dataclass</code>","text":"<p>Normal gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>lam</code> <code>NUMERIC</code> <p>precision</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NormalGamma:\n    \"\"\"Normal gamma distribution.\n\n    Args:\n        mu: mean\n        lam: precision\n        alpha: shape\n        beta: scale\n\n    \"\"\"\n\n    mu: NUMERIC\n    lam: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @property\n    def gamma(self) -&gt; Gamma:\n        return Gamma(alpha=self.alpha, beta=self.beta)\n\n    def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n        \"\"\"Sample precision from gamma distribution and invert.\n\n        Args:\n            size: number of samples\n            random_state: random state\n\n        Returns:\n            samples from the inverse gamma distribution\n\n        \"\"\"\n        precision = self.lam * self.gamma.dist.rvs(size=size, random_state=random_state)\n\n        return 1 / precision\n\n    def sample_mean(\n        self,\n        size: int,\n        return_variance: bool = False,\n        random_state=None,\n    ) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n        \"\"\"Sample mean from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution\n\n        \"\"\"\n        return self.sample_beta(\n            size=size, return_variance=return_variance, random_state=random_state\n        )\n\n    def sample_beta(\n        self, size: int, return_variance: bool = False, random_state=None\n    ) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n        \"\"\"Sample beta from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution\n\n        \"\"\"\n        variance = self.sample_variance(size=size, random_state=random_state)\n        sigma = variance**0.5\n        beta = stats.norm(loc=self.mu, scale=sigma).rvs(\n            size=size, random_state=random_state\n        )\n\n        if return_variance:\n            return beta, variance\n\n        return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalGamma.sample_beta","title":"<code>sample_beta(size, return_variance=False, random_state=None)</code>","text":"<p>Sample beta from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC | tuple[NUMERIC, NUMERIC]</code> <p>samples from the normal distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_beta(\n    self, size: int, return_variance: bool = False, random_state=None\n) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n    \"\"\"Sample beta from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution\n\n    \"\"\"\n    variance = self.sample_variance(size=size, random_state=random_state)\n    sigma = variance**0.5\n    beta = stats.norm(loc=self.mu, scale=sigma).rvs(\n        size=size, random_state=random_state\n    )\n\n    if return_variance:\n        return beta, variance\n\n    return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalGamma.sample_mean","title":"<code>sample_mean(size, return_variance=False, random_state=None)</code>","text":"<p>Sample mean from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC | tuple[NUMERIC, NUMERIC]</code> <p>samples from the normal distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_mean(\n    self,\n    size: int,\n    return_variance: bool = False,\n    random_state=None,\n) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n    \"\"\"Sample mean from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution\n\n    \"\"\"\n    return self.sample_beta(\n        size=size, return_variance=return_variance, random_state=random_state\n    )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalGamma.sample_variance","title":"<code>sample_variance(size, random_state=None)</code>","text":"<p>Sample precision from gamma distribution and invert.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>samples from the inverse gamma distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n    \"\"\"Sample precision from gamma distribution and invert.\n\n    Args:\n        size: number of samples\n        random_state: random state\n\n    Returns:\n        samples from the inverse gamma distribution\n\n    \"\"\"\n    precision = self.lam * self.gamma.dist.rvs(size=size, random_state=random_state)\n\n    return 1 / precision\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma","title":"<code>NormalInverseGamma</code>  <code>dataclass</code>","text":"<p>Normal inverse gamma distribution.</p> <p>Supports both 1 dimensional and multivariate cases.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required <code>delta_inverse</code> <code>NUMERIC | None</code> <p>covariance matrix, 2d array for multivariate case</p> <code>None</code> <code>nu</code> <code>NUMERIC | None</code> <p>alternative precision parameter for 1 dimensional case</p> <code>None</code> Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NormalInverseGamma:\n    \"\"\"Normal inverse gamma distribution.\n\n    Supports both 1 dimensional and multivariate cases.\n\n    Args:\n        mu: mean\n        alpha: shape\n        beta: scale\n        delta_inverse: covariance matrix, 2d array for multivariate case\n        nu: alternative precision parameter for 1 dimensional case\n\n    \"\"\"\n\n    mu: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n    delta_inverse: NUMERIC | None = None\n    nu: NUMERIC | None = None\n\n    def __post_init__(self) -&gt; None:\n        if self.delta_inverse is None and self.nu is None:\n            raise ValueError(\"Either delta_inverse or nu must be provided.\")\n\n        if self.delta_inverse is not None and self.nu is not None:\n            raise ValueError(\"Only one of delta_inverse or nu must be provided.\")\n\n    @classmethod\n    def from_inverse_gamma(\n        cls,\n        mu: NUMERIC,\n        inverse_gamma: InverseGamma,\n        delta_inverse: NUMERIC | None = None,\n        nu: NUMERIC | None = None,\n    ) -&gt; \"NormalInverseGamma\":\n        return cls(\n            mu=mu,\n            alpha=inverse_gamma.alpha,\n            beta=inverse_gamma.beta,\n            delta_inverse=delta_inverse,\n            nu=nu,\n        )\n\n    @property\n    def inverse_gamma(self) -&gt; InverseGamma:\n        return InverseGamma(alpha=self.alpha, beta=self.beta)\n\n    def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n        \"\"\"Sample variance from the inverse gamma distribution.\n\n        Args:\n            size: number of samples\n            random_state: random state\n\n        Returns:\n            samples from the inverse gamma distribution\n\n        \"\"\"\n        return self.inverse_gamma.dist.rvs(size=size, random_state=random_state)\n\n    def _sample_beta_1d(self, variance, size: int, random_state=None) -&gt; NUMERIC:\n        sigma = (variance / self.nu) ** 0.5\n        return stats.norm(self.mu, sigma).rvs(size=size, random_state=random_state)\n\n    def _sample_beta_nd(self, variance, size: int, random_state=None) -&gt; NUMERIC:\n        variance = (self.delta_inverse[None, ...].T * variance).T\n        return np.stack(\n            [\n                stats.multivariate_normal(self.mu, v).rvs(\n                    size=1, random_state=random_state\n                )\n                for v in variance\n            ]\n        )\n\n    def sample_mean(\n        self,\n        size: int,\n        return_variance: bool = False,\n        random_state=None,\n    ) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n        \"\"\"Sample the mean from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution and optionally variance\n\n        \"\"\"\n        return self.sample_beta(\n            size=size, return_variance=return_variance, random_state=random_state\n        )\n\n    def sample_beta(\n        self, size: int, return_variance: bool = False, random_state=None\n    ) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n        \"\"\"Sample beta from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution and optionally variance\n\n        \"\"\"\n        variance = self.sample_variance(size=size, random_state=random_state)\n\n        sample_beta = (\n            self._sample_beta_1d if self.delta_inverse is None else self._sample_beta_nd\n        )\n        beta = sample_beta(variance=variance, size=size, random_state=random_state)\n\n        if return_variance:\n            return beta, variance\n\n        return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma.sample_beta","title":"<code>sample_beta(size, return_variance=False, random_state=None)</code>","text":"<p>Sample beta from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC | tuple[NUMERIC, NUMERIC]</code> <p>samples from the normal distribution and optionally variance</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_beta(\n    self, size: int, return_variance: bool = False, random_state=None\n) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n    \"\"\"Sample beta from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution and optionally variance\n\n    \"\"\"\n    variance = self.sample_variance(size=size, random_state=random_state)\n\n    sample_beta = (\n        self._sample_beta_1d if self.delta_inverse is None else self._sample_beta_nd\n    )\n    beta = sample_beta(variance=variance, size=size, random_state=random_state)\n\n    if return_variance:\n        return beta, variance\n\n    return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma.sample_mean","title":"<code>sample_mean(size, return_variance=False, random_state=None)</code>","text":"<p>Sample the mean from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC | tuple[NUMERIC, NUMERIC]</code> <p>samples from the normal distribution and optionally variance</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_mean(\n    self,\n    size: int,\n    return_variance: bool = False,\n    random_state=None,\n) -&gt; NUMERIC | tuple[NUMERIC, NUMERIC]:\n    \"\"\"Sample the mean from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution and optionally variance\n\n    \"\"\"\n    return self.sample_beta(\n        size=size, return_variance=return_variance, random_state=random_state\n    )\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma.sample_variance","title":"<code>sample_variance(size, random_state=None)</code>","text":"<p>Sample variance from the inverse gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>samples from the inverse gamma distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n    \"\"\"Sample variance from the inverse gamma distribution.\n\n    Args:\n        size: number of samples\n        random_state: random state\n\n    Returns:\n        samples from the inverse gamma distribution\n\n    \"\"\"\n    return self.inverse_gamma.dist.rvs(size=size, random_state=random_state)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseWishart","title":"<code>NormalInverseWishart</code>  <code>dataclass</code>","text":"<p>Normal inverse Wishart distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>kappa</code> <code>NUMERIC</code> <p>precision</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required <code>psi</code> <code>NUMERIC</code> <p>scale matrix</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NormalInverseWishart:\n    \"\"\"Normal inverse Wishart distribution.\n\n    Args:\n        mu: mean\n        kappa: precision\n        nu: degrees of freedom\n        psi: scale matrix\n\n    \"\"\"\n\n    mu: NUMERIC\n    kappa: NUMERIC\n    nu: NUMERIC\n    psi: NUMERIC\n\n    @property\n    def inverse_wishart(self):\n        \"\"\"Inverse wishart distribution.\"\"\"\n        return InverseWishart(nu=self.nu, psi=self.psi)\n\n    @classmethod\n    def from_inverse_wishart(\n        cls,\n        mu: NUMERIC,\n        kappa: NUMERIC,\n        inverse_wishart: InverseWishart,\n    ):\n        return cls(mu=mu, kappa=kappa, nu=inverse_wishart.nu, psi=inverse_wishart.psi)\n\n    def sample_variance(\n        self, size: int, random_state: np.random.Generator | None = None\n    ) -&gt; NUMERIC:\n        \"\"\"Sample precision from gamma distribution and invert.\n\n        Args:\n            size: number of samples\n            random_state: random state\n\n        Returns:\n            samples from the inverse wishart distribution\n\n        \"\"\"\n        variance = (\n            self.inverse_wishart.dist.rvs(size=size, random_state=random_state)\n            / self.kappa\n        )\n        if size == 1:\n            variance = variance[None, ...]\n\n        return variance\n\n    def sample_mean(\n        self,\n        size: int,\n        return_variance: bool = False,\n        random_state: np.random.Generator | None = None,\n    ) -&gt; NUMERIC:\n        \"\"\"Sample the mean from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution and optionally variance\n\n        \"\"\"\n        variance = self.sample_variance(size=size, random_state=random_state)\n\n        mean = np.stack(\n            [\n                stats.multivariate_normal(self.mu, cov=cov).rvs(\n                    size=1, random_state=random_state\n                )\n                for cov in variance\n            ]\n        )\n\n        if return_variance:\n            return mean, variance\n\n        return mean\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseWishart.inverse_wishart","title":"<code>inverse_wishart</code>  <code>property</code>","text":"<p>Inverse wishart distribution.</p>"},{"location":"distributions/#conjugate.distributions.NormalInverseWishart.sample_mean","title":"<code>sample_mean(size, return_variance=False, random_state=None)</code>","text":"<p>Sample the mean from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <code>Generator | None</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>samples from the normal distribution and optionally variance</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_mean(\n    self,\n    size: int,\n    return_variance: bool = False,\n    random_state: np.random.Generator | None = None,\n) -&gt; NUMERIC:\n    \"\"\"Sample the mean from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution and optionally variance\n\n    \"\"\"\n    variance = self.sample_variance(size=size, random_state=random_state)\n\n    mean = np.stack(\n        [\n            stats.multivariate_normal(self.mu, cov=cov).rvs(\n                size=1, random_state=random_state\n            )\n            for cov in variance\n        ]\n    )\n\n    if return_variance:\n        return mean, variance\n\n    return mean\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseWishart.sample_variance","title":"<code>sample_variance(size, random_state=None)</code>","text":"<p>Sample precision from gamma distribution and invert.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>random_state</code> <code>Generator | None</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>samples from the inverse wishart distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_variance(\n    self, size: int, random_state: np.random.Generator | None = None\n) -&gt; NUMERIC:\n    \"\"\"Sample precision from gamma distribution and invert.\n\n    Args:\n        size: number of samples\n        random_state: random state\n\n    Returns:\n        samples from the inverse wishart distribution\n\n    \"\"\"\n    variance = (\n        self.inverse_wishart.dist.rvs(size=size, random_state=random_state)\n        / self.kappa\n    )\n    if size == 1:\n        variance = variance[None, ...]\n\n    return variance\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalWishart","title":"<code>NormalWishart</code>  <code>dataclass</code>","text":"<p>Normal Wishart distribution.</p> <p>Parameterization from Wikipedia.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>lam</code> <code>NUMERIC</code> <p>precision</p> required <code>W</code> <code>NUMERIC</code> <p>scale matrix</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NormalWishart:\n    \"\"\"Normal Wishart distribution.\n\n    Parameterization from &lt;a href=https://en.wikipedia.org/wiki/Normal-Wishart_distribution&gt;Wikipedia&lt;/a&gt;.\n\n    Args:\n        mu: mean\n        lam: precision\n        W: scale matrix\n        nu: degrees of freedom\n\n    \"\"\"\n\n    mu: NUMERIC\n    lam: NUMERIC\n    W: NUMERIC\n    nu: NUMERIC\n\n    @property\n    def wishart(self):\n        return Wishart(nu=self.nu, V=self.W)\n\n    def sample_variance(\n        self,\n        size: int = 1,\n        random_state: np.random.Generator | None = None,\n        inv: Callable = np.linalg.inv,\n    ) -&gt; np.ndarray:\n        \"\"\"Sample variance\n\n        Args:\n            size: number of samples\n            random_state: random state\n            inv: matrix inversion function\n\n        Returns:\n            samples from the inverse wishart distribution\n\n        \"\"\"\n\n        variance = inv(\n            self.lam * self.wishart.dist.rvs(size=size, random_state=random_state)\n        )\n\n        if size == 1:\n            variance = variance[None, ...]\n\n        return variance\n\n    def sample_mean(\n        self,\n        size: int = 1,\n        return_variance: bool = False,\n        random_state: np.random.Generator | None = None,\n    ) -&gt; np.ndarray | tuple[np.ndarray, np.ndarray]:\n        \"\"\"Sample mean\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution and optionally variance\n\n        \"\"\"\n\n        variance = self.sample_variance(size=size, random_state=random_state)\n\n        mean = np.stack(\n            [\n                stats.multivariate_normal(self.mu, cov=cov).rvs(\n                    size=1,\n                    random_state=random_state,\n                )\n                for cov in variance\n            ]\n        )\n\n        if return_variance:\n            return mean, variance\n\n        return mean\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalWishart.sample_mean","title":"<code>sample_mean(size=1, return_variance=False, random_state=None)</code>","text":"<p>Sample mean</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> <code>1</code> <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <code>Generator | None</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray | tuple[ndarray, ndarray]</code> <p>samples from the normal distribution and optionally variance</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_mean(\n    self,\n    size: int = 1,\n    return_variance: bool = False,\n    random_state: np.random.Generator | None = None,\n) -&gt; np.ndarray | tuple[np.ndarray, np.ndarray]:\n    \"\"\"Sample mean\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution and optionally variance\n\n    \"\"\"\n\n    variance = self.sample_variance(size=size, random_state=random_state)\n\n    mean = np.stack(\n        [\n            stats.multivariate_normal(self.mu, cov=cov).rvs(\n                size=1,\n                random_state=random_state,\n            )\n            for cov in variance\n        ]\n    )\n\n    if return_variance:\n        return mean, variance\n\n    return mean\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalWishart.sample_variance","title":"<code>sample_variance(size=1, random_state=None, inv=np.linalg.inv)</code>","text":"<p>Sample variance</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> <code>1</code> <code>random_state</code> <code>Generator | None</code> <p>random state</p> <code>None</code> <code>inv</code> <code>Callable</code> <p>matrix inversion function</p> <code>inv</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>samples from the inverse wishart distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_variance(\n    self,\n    size: int = 1,\n    random_state: np.random.Generator | None = None,\n    inv: Callable = np.linalg.inv,\n) -&gt; np.ndarray:\n    \"\"\"Sample variance\n\n    Args:\n        size: number of samples\n        random_state: random state\n        inv: matrix inversion function\n\n    Returns:\n        samples from the inverse wishart distribution\n\n    \"\"\"\n\n    variance = inv(\n        self.lam * self.wishart.dist.rvs(size=size, random_state=random_state)\n    )\n\n    if size == 1:\n        variance = variance[None, ...]\n\n    return variance\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Pareto","title":"<code>Pareto</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Pareto distribution.</p> <p>Parameters:</p> Name Type Description Default <code>x_m</code> <code>NUMERIC</code> <p>minimum value</p> required <code>alpha</code> <code>NUMERIC</code> <p>scale parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Pareto(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Pareto distribution.\n\n    Args:\n        x_m: minimum value\n        alpha: scale parameter\n\n    \"\"\"\n\n    x_m: NUMERIC\n    alpha: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.pareto(self.alpha, scale=self.x_m)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Poisson","title":"<code>Poisson</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>lam</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Poisson(DiscretePlotMixin, SliceMixin):\n    \"\"\"Poisson distribution.\n\n    Args:\n        lam: rate parameter\n\n    \"\"\"\n\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.poisson(self.lam)\n\n    def __mul__(self, other) -&gt; \"Poisson\":\n        return Poisson(lam=self.lam * other)\n\n    __rmul__ = __mul__\n\n    def __add__(self, other) -&gt; \"Poisson\":\n        return Poisson(self.lam + other.lam)\n\n    __radd__ = __add__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.ScaledInverseChiSquared","title":"<code>ScaledInverseChiSquared</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Scaled inverse chi squared distribution.</p> <p>Parameters:</p> Name Type Description Default <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required <code>sigma2</code> <code>NUMERIC</code> <p>scale parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass ScaledInverseChiSquared(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Scaled inverse chi squared distribution.\n\n    Args:\n        nu: degrees of freedom\n        sigma2: scale parameter\n\n    \"\"\"\n\n    nu: NUMERIC\n    sigma2: NUMERIC\n\n    @classmethod\n    def from_inverse_gamma(\n        cls,\n        inverse_gamma: InverseGamma,\n    ) -&gt; \"ScaledInverseChiSquared\":\n        \"\"\"Alternative constructor from inverse gamma distribution.\n\n        Args:\n            inverse_gamma: inverse gamma distribution\n\n        Returns:\n            scaled inverse chi squared distribution\n\n        \"\"\"\n        nu = inverse_gamma.alpha * 2\n        sigma2 = inverse_gamma.beta * 2 / nu\n\n        return cls(nu=nu, sigma2=sigma2)\n\n    def to_inverse_gamma(self) -&gt; InverseGamma:\n        \"\"\"Convert to inverse gamma distribution.\n\n        Returns:\n            inverse gamma distribution\n\n        \"\"\"\n        return InverseGamma(alpha=self.nu / 2, beta=self.nu * self.sigma2 / 2)\n\n    @property\n    def dist(self):\n        return stats.invgamma(a=self.nu / 2, scale=self.nu * self.sigma2 / 2)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.ScaledInverseChiSquared.from_inverse_gamma","title":"<code>from_inverse_gamma(inverse_gamma)</code>  <code>classmethod</code>","text":"<p>Alternative constructor from inverse gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>inverse_gamma</code> <code>InverseGamma</code> <p>inverse gamma distribution</p> required <p>Returns:</p> Type Description <code>ScaledInverseChiSquared</code> <p>scaled inverse chi squared distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_inverse_gamma(\n    cls,\n    inverse_gamma: InverseGamma,\n) -&gt; \"ScaledInverseChiSquared\":\n    \"\"\"Alternative constructor from inverse gamma distribution.\n\n    Args:\n        inverse_gamma: inverse gamma distribution\n\n    Returns:\n        scaled inverse chi squared distribution\n\n    \"\"\"\n    nu = inverse_gamma.alpha * 2\n    sigma2 = inverse_gamma.beta * 2 / nu\n\n    return cls(nu=nu, sigma2=sigma2)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.ScaledInverseChiSquared.to_inverse_gamma","title":"<code>to_inverse_gamma()</code>","text":"<p>Convert to inverse gamma distribution.</p> <p>Returns:</p> Type Description <code>InverseGamma</code> <p>inverse gamma distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def to_inverse_gamma(self) -&gt; InverseGamma:\n    \"\"\"Convert to inverse gamma distribution.\n\n    Returns:\n        inverse gamma distribution\n\n    \"\"\"\n    return InverseGamma(alpha=self.nu / 2, beta=self.nu * self.sigma2 / 2)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.StudentT","title":"<code>StudentT</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>StudentT distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>standard deviation</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass StudentT(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"StudentT distribution.\n\n    Args:\n        mu: mean\n        sigma: standard deviation\n        nu: degrees of freedom\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n    nu: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.t(self.nu, self.mu, self.sigma)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Uniform","title":"<code>Uniform</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>NUMERIC</code> <p>lower bound</p> required <code>high</code> <code>NUMERIC</code> <p>upper bound</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Uniform(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Uniform distribution.\n\n    Args:\n        low: lower bound\n        high: upper bound\n\n    \"\"\"\n\n    low: NUMERIC\n    high: NUMERIC\n\n    def __post_init__(self):\n        self.min_value = self.low\n        self.max_value = self.high\n\n    @property\n    def dist(self):\n        return stats.uniform(self.low, self.high)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VectorizedDist","title":"<code>VectorizedDist</code>","text":"<p>Vectorized distribution to handle scipy distributions that don't support vectorization.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>class VectorizedDist:\n    \"\"\"Vectorized distribution to handle scipy distributions that don't support vectorization.\"\"\"\n\n    def __init__(self, params: np.ndarray, dist: Any):\n        self.params = params\n        self.dist = dist\n\n    def rvs(self, size: int = 1) -&gt; np.ndarray:\n        return np.stack([self.dist(param).rvs(size=size) for param in self.params])\n\n    def mean(self) -&gt; np.ndarray:\n        return np.stack([self.dist(param).mean() for param in self.params])\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VonMises","title":"<code>VonMises</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Von Mises distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>kappa</code> <code>NUMERIC</code> <p>concentration</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass VonMises(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Von Mises distribution.\n\n    Args:\n        mu: mean\n        kappa: concentration\n\n    \"\"\"\n\n    mu: NUMERIC\n    kappa: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        self.min_value = -np.pi\n        self.max_value = np.pi\n\n    @property\n    def dist(self):\n        return stats.vonmises(loc=self.mu, kappa=self.kappa)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VonMisesKnownConcentration","title":"<code>VonMisesKnownConcentration</code>  <code>dataclass</code>","text":"<p>Von Mises known concentration distribution.</p> <p>Taken from Section 2.13.1.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>NUMERIC</code> <p>positive value</p> required <code>b</code> <code>NUMERIC</code> <p>value between 0 and 2 pi</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass VonMisesKnownConcentration:\n    \"\"\"Von Mises known concentration distribution.\n\n    Taken from &lt;a href=https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf&gt;Section 2.13.1&lt;/a&gt;.\n\n    Args:\n        a: positive value\n        b: value between 0 and 2 pi\n\n    \"\"\"\n\n    a: NUMERIC\n    b: NUMERIC\n\n    def log_likelihood(self, mu: NUMERIC, cos=np.cos, ln=np.log, i0=i0) -&gt; NUMERIC:\n        \"\"\"Approximate log likelihood.\n\n        Args:\n            mu: mean\n            cos: cosine function\n            ln: log function\n            i0: modified bessel function of order 0\n\n        Returns:\n            log likelihood\n\n        \"\"\"\n        return self.a + cos(mu - self.b) - ln(i0(self.a))\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VonMisesKnownConcentration.log_likelihood","title":"<code>log_likelihood(mu, cos=np.cos, ln=np.log, i0=i0)</code>","text":"<p>Approximate log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>cos</code> <p>cosine function</p> <code>cos</code> <code>ln</code> <p>log function</p> <code>log</code> <code>i0</code> <p>modified bessel function of order 0</p> <code>i0</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>log likelihood</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def log_likelihood(self, mu: NUMERIC, cos=np.cos, ln=np.log, i0=i0) -&gt; NUMERIC:\n    \"\"\"Approximate log likelihood.\n\n    Args:\n        mu: mean\n        cos: cosine function\n        ln: log function\n        i0: modified bessel function of order 0\n\n    Returns:\n        log likelihood\n\n    \"\"\"\n    return self.a + cos(mu - self.b) - ln(i0(self.a))\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VonMisesKnownDirectionProportional","title":"<code>VonMisesKnownDirectionProportional</code>  <code>dataclass</code>","text":"<p>Von Mises known direction proportional distribution.</p> <p>Taken from Section 2.13.2.</p> <p>Args: c: NUMERIC r: NUMERIC</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass VonMisesKnownDirectionProportional:\n    \"\"\"Von Mises known direction proportional distribution.\n\n    Taken from &lt;a href=https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf&gt;Section 2.13.2&lt;/a&gt;.\n\n    Args:\n    c: NUMERIC\n    r: NUMERIC\n    \"\"\"\n\n    c: NUMERIC\n    r: NUMERIC\n\n    def approx_log_likelihood(self, kappa: NUMERIC, ln=np.log, i0=i0) -&gt; NUMERIC:\n        \"\"\"Approximate log likelihood.\n\n        Args:\n            kappa: concentration\n            ln: log function\n            i0: modified bessel function of order 0\n\n        Returns:\n            log likelihood up to a constant\n\n        \"\"\"\n        return kappa * self.r - self.c * ln(i0(kappa))\n</code></pre>"},{"location":"distributions/#conjugate.distributions.VonMisesKnownDirectionProportional.approx_log_likelihood","title":"<code>approx_log_likelihood(kappa, ln=np.log, i0=i0)</code>","text":"<p>Approximate log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>kappa</code> <code>NUMERIC</code> <p>concentration</p> required <code>ln</code> <p>log function</p> <code>log</code> <code>i0</code> <p>modified bessel function of order 0</p> <code>i0</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>log likelihood up to a constant</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def approx_log_likelihood(self, kappa: NUMERIC, ln=np.log, i0=i0) -&gt; NUMERIC:\n    \"\"\"Approximate log likelihood.\n\n    Args:\n        kappa: concentration\n        ln: log function\n        i0: modified bessel function of order 0\n\n    Returns:\n        log likelihood up to a constant\n\n    \"\"\"\n    return kappa * self.r - self.c * ln(i0(kappa))\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Weibull","title":"<code>Weibull</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Weibull distribution.</p> <p>Parameterization from Section 2.11 of paper.</p> <p>Parameters:</p> Name Type Description Default <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>theta</code> <code>NUMERIC</code> <p>scale parameter</p> required Example <p>Recreation of the plot on Wikipedia.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom conjugate.distributions import Weibull\n\nlam = 1\nk = np.array([0.5, 1.0, 1.5, 5.0])\n\nbeta = k\ntheta = lam ** beta\n\ndistribution = Weibull(beta=beta, theta=theta)\nax = distribution.set_bounds(0, 2.5).plot_pdf(\n    label=[\"k=0.5\", \"k=1.0\", \"k=1.5\", \"k=5.0\"],\n    color=[\"blue\", \"red\", \"pink\", \"green\"],\n)\nax.legend()\n</code></pre> Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Weibull(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Weibull distribution.\n\n    Parameterization from Section 2.11 of &lt;a href=\"https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf\"&gt;paper&lt;/a&gt;.\n\n    Args:\n        beta: shape parameter\n        theta: scale parameter\n\n    Example:\n        Recreation of the plot on &lt;a href=https://en.wikipedia.org/wiki/Weibull_distribution&gt;Wikipedia&lt;/a&gt;.\n\n        ```python\n        import matplotlib.pyplot as plt\n        import numpy as np\n\n        from conjugate.distributions import Weibull\n\n        lam = 1\n        k = np.array([0.5, 1.0, 1.5, 5.0])\n\n        beta = k\n        theta = lam ** beta\n\n        distribution = Weibull(beta=beta, theta=theta)\n        ax = distribution.set_bounds(0, 2.5).plot_pdf(\n            label=[\"k=0.5\", \"k=1.0\", \"k=1.5\", \"k=5.0\"],\n            color=[\"blue\", \"red\", \"pink\", \"green\"],\n        )\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"plot-check.png\")\n        plt.close()\n        --&gt;\n\n    \"\"\"\n\n    beta: NUMERIC\n    theta: NUMERIC\n\n    @property\n    def dist(self):\n        k = self.beta\n        lam = self.theta ** (1 / self.beta)\n        return stats.weibull_min(c=k, scale=lam)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Wishart","title":"<code>Wishart</code>  <code>dataclass</code>","text":"<p>Wishart distribution.</p> <p>Parameters:</p> Name Type Description Default <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required <code>V</code> <code>NUMERIC</code> <p>scale matrix</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Wishart:\n    \"\"\"Wishart distribution.\n\n    Args:\n        nu: degrees of freedom\n        V: scale matrix\n\n    \"\"\"\n\n    nu: NUMERIC\n    V: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.wishart(df=self.nu, scale=self.V)\n</code></pre>"},{"location":"mixins/","title":"Mixins","text":"<p>Mixins to support the plotting and slicing of the distribution parameters. They are only required for creating new distributions or for understanding the internals.</p>"},{"location":"mixins/#conjugate.plot.ContinuousPlotDistMixin","title":"<code>ContinuousPlotDistMixin</code>","text":"<p>               Bases: <code>PlotDistMixin</code></p> <p>Functionality for plot_pdf method of continuous distributions.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class ContinuousPlotDistMixin(PlotDistMixin):\n    \"\"\"Functionality for plot_pdf method of continuous distributions.\"\"\"\n\n    def _plot(self, ax: Axes | None = None, cdf: bool = False, **kwargs) -&gt; Axes:\n        x = self._create_x_values()\n        x = self._reshape_x_values(x)\n\n        ax = self._settle_axis(ax=ax)\n\n        return self._create_plot_on_axis(x=x, cdf=cdf, ax=ax, **kwargs)\n\n    def plot_pdf(self, ax: Axes | None = None, **kwargs) -&gt; Axes:\n        \"\"\"Plot the PDF of distribution\n\n        Args:\n            ax: matplotlib Axes, optional\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        Raises:\n            ValueError: If the max_value is not set.\n\n        \"\"\"\n        return self._plot(ax=ax, cdf=False, **kwargs)\n\n    def plot_cdf(self, ax: Axes | None = None, **kwargs) -&gt; Axes:\n        \"\"\"Plot the CDF of distribution\n\n        Args:\n            ax: matplotlib Axes, optional\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        Raises:\n            ValueError: If the max_value is not set.\n\n        \"\"\"\n        return self._plot(ax=ax, cdf=True, **kwargs)\n\n    def _create_x_values(self) -&gt; np.ndarray:\n        return np.linspace(self.min_value, self.max_value, 100)\n\n    def _setup_labels(self, ax, cdf: bool = False) -&gt; None:\n        if isinstance(ax, PolarAxes):\n            return\n\n        ylabel = \"Density $f(x)$\" if not cdf else \"Cumulative Density $F(x)$\"\n        ax.set(xlabel=\"Domain\", ylabel=ylabel)\n\n    def _create_plot_on_axis(self, x, cdf: bool, ax: Axes, **kwargs) -&gt; Axes:\n        func = self.dist.cdf if cdf else self.dist.pdf\n        yy = func(x)\n\n        if \"label\" in kwargs:\n            label = kwargs.pop(\"label\")\n            label = resolve_label(label, yy)\n        else:\n            label = None\n\n        if \"color\" in kwargs and isinstance(kwargs[\"color\"], Iterable):\n            ax.set_prop_cycle(color=kwargs.pop(\"color\"))\n\n        ax.plot(x, yy, label=label, **kwargs)\n        self._setup_labels(ax=ax, cdf=cdf)\n        ax.set_ylim(0, None)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.ContinuousPlotDistMixin.plot_cdf","title":"<code>plot_cdf(ax=None, **kwargs)</code>","text":"<p>Plot the CDF of distribution</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the max_value is not set.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_cdf(self, ax: Axes | None = None, **kwargs) -&gt; Axes:\n    \"\"\"Plot the CDF of distribution\n\n    Args:\n        ax: matplotlib Axes, optional\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    Raises:\n        ValueError: If the max_value is not set.\n\n    \"\"\"\n    return self._plot(ax=ax, cdf=True, **kwargs)\n</code></pre>"},{"location":"mixins/#conjugate.plot.ContinuousPlotDistMixin.plot_pdf","title":"<code>plot_pdf(ax=None, **kwargs)</code>","text":"<p>Plot the PDF of distribution</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the max_value is not set.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_pdf(self, ax: Axes | None = None, **kwargs) -&gt; Axes:\n    \"\"\"Plot the PDF of distribution\n\n    Args:\n        ax: matplotlib Axes, optional\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    Raises:\n        ValueError: If the max_value is not set.\n\n    \"\"\"\n    return self._plot(ax=ax, cdf=False, **kwargs)\n</code></pre>"},{"location":"mixins/#conjugate.plot.DirichletPlotDistMixin","title":"<code>DirichletPlotDistMixin</code>","text":"<p>               Bases: <code>ContinuousPlotDistMixin</code></p> <p>Plot the pdf using samples from the dirichlet distribution.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class DirichletPlotDistMixin(ContinuousPlotDistMixin):\n    \"\"\"Plot the pdf using samples from the dirichlet distribution.\"\"\"\n\n    def plot_pdf(\n        self,\n        ax: Axes | None = None,\n        samples: int = 1_000,\n        random_state=None,\n        **kwargs,\n    ) -&gt; Axes:\n        \"\"\"Plots the pdf by sampling from the distribution.\n\n        Args:\n            ax: matplotlib Axes, optional\n            samples: number of samples to take from the distribution\n            random_state: random state to use for sampling\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        \"\"\"\n        distribution_samples = self.dist.rvs(size=samples, random_state=random_state)\n\n        ax = self._settle_axis(ax=ax)\n        xx = self._create_x_values()\n\n        labels = label_to_iterable(\n            kwargs.pop(\"label\", None), distribution_samples.shape[1]\n        )\n\n        for x, label in zip_longest(distribution_samples.T, labels):\n            kde = gaussian_kde(x)\n\n            yy = kde(xx)\n            ax.plot(xx, yy, label=label, **kwargs)\n\n        self._setup_labels(ax=ax)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.DirichletPlotDistMixin.plot_pdf","title":"<code>plot_pdf(ax=None, samples=1000, random_state=None, **kwargs)</code>","text":"<p>Plots the pdf by sampling from the distribution.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>samples</code> <code>int</code> <p>number of samples to take from the distribution</p> <code>1000</code> <code>random_state</code> <p>random state to use for sampling</p> <code>None</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_pdf(\n    self,\n    ax: Axes | None = None,\n    samples: int = 1_000,\n    random_state=None,\n    **kwargs,\n) -&gt; Axes:\n    \"\"\"Plots the pdf by sampling from the distribution.\n\n    Args:\n        ax: matplotlib Axes, optional\n        samples: number of samples to take from the distribution\n        random_state: random state to use for sampling\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    \"\"\"\n    distribution_samples = self.dist.rvs(size=samples, random_state=random_state)\n\n    ax = self._settle_axis(ax=ax)\n    xx = self._create_x_values()\n\n    labels = label_to_iterable(\n        kwargs.pop(\"label\", None), distribution_samples.shape[1]\n    )\n\n    for x, label in zip_longest(distribution_samples.T, labels):\n        kde = gaussian_kde(x)\n\n        yy = kde(xx)\n        ax.plot(xx, yy, label=label, **kwargs)\n\n    self._setup_labels(ax=ax)\n    return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.DiscretePlotMixin","title":"<code>DiscretePlotMixin</code>","text":"<p>               Bases: <code>PlotDistMixin</code></p> <p>Adding the plot_pmf method to class.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class DiscretePlotMixin(PlotDistMixin):\n    \"\"\"Adding the plot_pmf method to class.\"\"\"\n\n    def _plot(\n        self,\n        ax: Axes | None = None,\n        cdf: bool = False,\n        mark: str = \"o-\",\n        conditional: bool = False,\n        **kwargs,\n    ) -&gt; Axes:\n        x = self._create_x_values()\n        x = self._reshape_x_values(x)\n\n        ax = self._settle_axis(ax=ax)\n        return self._create_plot_on_axis(\n            x,\n            ax=ax,\n            cdf=cdf,\n            mark=mark,\n            conditional=conditional,\n            **kwargs,\n        )\n\n    def plot_pmf(\n        self,\n        ax: Axes | None = None,\n        mark: str = \"o-\",\n        conditional: bool = False,\n        **kwargs,\n    ) -&gt; Axes:\n        \"\"\"Plot the PMF of distribution\n\n        Args:\n            ax: matplotlib Axes, optional\n            mark: matplotlib line style\n            conditional: If True, plot the conditional probability given the bounds.\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        Raises:\n            ValueError: If the max_value is not set.\n\n        \"\"\"\n        return self._plot(\n            ax=ax,\n            cdf=False,\n            mark=mark,\n            conditional=conditional,\n            **kwargs,\n        )\n\n    def plot_cdf(\n        self,\n        ax: Axes | None = None,\n        mark: str = \"o-\",\n        conditional: bool = False,\n        **kwargs,\n    ) -&gt; Axes:\n        \"\"\"Plot the CDF of distribution\n\n        Args:\n            ax: matplotlib Axes, optional\n            mark: matplotlib line style\n            conditional: If True, plot the conditional probability given the bounds.\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        Raises:\n            ValueError: If the max_value is not set.\n\n        \"\"\"\n        return self._plot(ax=ax, cdf=True, mark=mark, conditional=conditional, **kwargs)\n\n    def _create_x_values(self) -&gt; np.ndarray:\n        return np.arange(self.min_value, self.max_value + 1, 1)\n\n    def _create_plot_on_axis(\n        self,\n        x,\n        ax,\n        cdf: bool,\n        mark,\n        conditional: bool = False,\n        **kwargs,\n    ) -&gt; Axes:\n        func = self.dist.cdf if cdf else self.dist.pmf\n        yy = func(x)\n\n        if conditional:\n            yy = yy / np.sum(yy)\n\n            prefix = (\n                \"Cumulative Probability $F(X \\\\leq x\" if cdf else \"Probability $f(x\"\n            )\n\n            ylabel = f\"Conditional {prefix}|{self.min_value} \\\\leq x \\\\leq {self.max_value})$\"\n        else:\n            ylabel = (\n                \"Cumulative Probability $F(X \\\\leq x)$\" if cdf else \"Probability $f(x)$\"\n            )\n\n        if \"label\" in kwargs:\n            label = kwargs.pop(\"label\")\n            label = resolve_label(label, yy)\n        else:\n            label = None\n\n        if \"color\" in kwargs and isinstance(kwargs[\"color\"], Iterable):\n            ax.set_prop_cycle(color=kwargs.pop(\"color\"))\n\n        ax.plot(x, yy, mark, label=label, **kwargs)\n\n        if self.max_value - self.min_value &lt; 15:\n            ax.set_xticks(x.ravel())\n        else:\n            ax.set_xticks(x.ravel(), minor=True)\n            ax.set_xticks(x[::5].ravel())\n\n        ax.set_xlabel(\"Domain\")\n        ax.set_ylabel(ylabel)\n        ax.set_ylim(0, None)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.DiscretePlotMixin.plot_cdf","title":"<code>plot_cdf(ax=None, mark='o-', conditional=False, **kwargs)</code>","text":"<p>Plot the CDF of distribution</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>mark</code> <code>str</code> <p>matplotlib line style</p> <code>'o-'</code> <code>conditional</code> <code>bool</code> <p>If True, plot the conditional probability given the bounds.</p> <code>False</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the max_value is not set.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_cdf(\n    self,\n    ax: Axes | None = None,\n    mark: str = \"o-\",\n    conditional: bool = False,\n    **kwargs,\n) -&gt; Axes:\n    \"\"\"Plot the CDF of distribution\n\n    Args:\n        ax: matplotlib Axes, optional\n        mark: matplotlib line style\n        conditional: If True, plot the conditional probability given the bounds.\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    Raises:\n        ValueError: If the max_value is not set.\n\n    \"\"\"\n    return self._plot(ax=ax, cdf=True, mark=mark, conditional=conditional, **kwargs)\n</code></pre>"},{"location":"mixins/#conjugate.plot.DiscretePlotMixin.plot_pmf","title":"<code>plot_pmf(ax=None, mark='o-', conditional=False, **kwargs)</code>","text":"<p>Plot the PMF of distribution</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>mark</code> <code>str</code> <p>matplotlib line style</p> <code>'o-'</code> <code>conditional</code> <code>bool</code> <p>If True, plot the conditional probability given the bounds.</p> <code>False</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the max_value is not set.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_pmf(\n    self,\n    ax: Axes | None = None,\n    mark: str = \"o-\",\n    conditional: bool = False,\n    **kwargs,\n) -&gt; Axes:\n    \"\"\"Plot the PMF of distribution\n\n    Args:\n        ax: matplotlib Axes, optional\n        mark: matplotlib line style\n        conditional: If True, plot the conditional probability given the bounds.\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    Raises:\n        ValueError: If the max_value is not set.\n\n    \"\"\"\n    return self._plot(\n        ax=ax,\n        cdf=False,\n        mark=mark,\n        conditional=conditional,\n        **kwargs,\n    )\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin","title":"<code>PlotDistMixin</code>","text":"<p>Base mixin in order to support plotting. Requires the dist attribute of the scipy distribution.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class PlotDistMixin:\n    \"\"\"Base mixin in order to support plotting. Requires the dist attribute of the scipy distribution.\"\"\"\n\n    @property\n    def dist(self) -&gt; Distribution:\n        raise NotImplementedError(\n            \"Implement this property in the subclass.\",\n        )  # pragma: no cover\n\n    @property\n    def max_value(self) -&gt; float:\n        if not hasattr(self, \"_max_value\"):\n            raise ValueError(\"Set the max value before plotting.\")\n\n        return self._max_value\n\n    @max_value.setter\n    def max_value(self, value: float) -&gt; None:\n        self._max_value = value\n\n    def set_max_value(self, value: float) -&gt; \"PlotDistMixin\":\n        self.max_value = value\n\n        return self\n\n    @property\n    def min_value(self) -&gt; float:\n        if not hasattr(self, \"_min_value\"):\n            self._min_value = 0.0\n\n        return self._min_value\n\n    @min_value.setter\n    def min_value(self, value: float) -&gt; None:\n        self._min_value = value\n\n    def set_min_value(self, value: float) -&gt; \"PlotDistMixin\":\n        \"\"\"Set the minimum value for plotting.\"\"\"\n        self.min_value = value\n\n        return self\n\n    def set_bounds(self, lower: float, upper: float) -&gt; \"PlotDistMixin\":\n        \"\"\"Set both the min and max values for plotting.\"\"\"\n        return self.set_min_value(lower).set_max_value(upper)\n\n    def _reshape_x_values(self, x: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Make sure that the values are ready for plotting.\"\"\"\n        for value in asdict(self).values():\n            if not isinstance(value, float):\n                return x[:, None]\n\n        return x\n\n    def _settle_axis(self, ax: Axes | None = None) -&gt; Axes:\n        return ax if ax is not None else plt.gca()\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin.set_bounds","title":"<code>set_bounds(lower, upper)</code>","text":"<p>Set both the min and max values for plotting.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def set_bounds(self, lower: float, upper: float) -&gt; \"PlotDistMixin\":\n    \"\"\"Set both the min and max values for plotting.\"\"\"\n    return self.set_min_value(lower).set_max_value(upper)\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin.set_min_value","title":"<code>set_min_value(value)</code>","text":"<p>Set the minimum value for plotting.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def set_min_value(self, value: float) -&gt; \"PlotDistMixin\":\n    \"\"\"Set the minimum value for plotting.\"\"\"\n    self.min_value = value\n\n    return self\n</code></pre>"},{"location":"mixins/#conjugate.plot.resolve_label","title":"<code>resolve_label(label, yy)</code>","text":"<p>https://stackoverflow.com/questions/73662931/matplotlib-plot-a-numpy-array-as-many-lines-with-a-single-label</p> Source code in <code>conjugate/plot.py</code> <pre><code>def resolve_label(label: LABEL_INPUT, yy: np.ndarray):\n    \"\"\"\n\n    https://stackoverflow.com/questions/73662931/matplotlib-plot-a-numpy-array-as-many-lines-with-a-single-label\n    \"\"\"\n    if yy.ndim == 1:\n        return label\n\n    ncols = yy.shape[1]\n    if ncols != 1:\n        return label_to_iterable(label, ncols)\n\n    return label\n</code></pre>"},{"location":"mixins/#conjugate.slice.SliceMixin","title":"<code>SliceMixin</code>","text":"<p>Mixin in order to slice the parameters</p> Source code in <code>conjugate/slice.py</code> <pre><code>class SliceMixin:\n    \"\"\"Mixin in order to slice the parameters\"\"\"\n\n    @property\n    def params(self):\n        return asdict(self)\n\n    def __getitem__(self, key):\n        def take_slice(value, key):\n            try:\n                return value[key]\n            except Exception:\n                return value\n\n        new_params = {k: take_slice(value=v, key=key) for k, v in self.params.items()}\n\n        return self.__class__(**new_params)\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>For more on these models, check out the Conjugate Prior Wikipedia Table</p>"},{"location":"models/#conjugate.models--supported-likelihoods","title":"Supported Likelihoods","text":""},{"location":"models/#conjugate.models--discrete","title":"Discrete","text":"<ul> <li>Bernoulli / Binomial</li> <li>Categorical / Multinomial</li> <li>Geometric</li> <li>Hypergeometric</li> <li>Negative Binomial</li> <li>Poisson</li> </ul>"},{"location":"models/#conjugate.models--continuous","title":"Continuous","text":"<ul> <li>Beta</li> <li>Exponential</li> <li>Gamma</li> <li>Inverse Gamma</li> <li>Linear Regression (Normal)</li> <li>Log Normal</li> <li>Multivariate Normal</li> <li>Normal</li> <li>Pareto</li> <li>Uniform</li> <li>Von Mises</li> <li>Weibull</li> </ul>"},{"location":"models/#conjugate.models--model-functions","title":"Model Functions","text":"<p>Below are the supported models:</p>"},{"location":"models/#conjugate.models.bernoulli_beta","title":"<code>bernoulli_beta(x, prior)</code>","text":"<p>Posterior distribution for a bernoulli likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>successes from a single trial</p> required <code>prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> <p>Examples:</p> <p>Information gain from a single coin flip</p> <pre><code>from conjugate.distributions import Beta\nfrom conjugate.models import bernoulli_beta\n\nprior = Beta(1, 1)\n\n# Positive outcome\nx = 1\nposterior = bernoulli_beta(\n    x=x,\n    prior=prior\n)\n\nposterior.dist.ppf([0.025, 0.975])\n# array([0.15811388, 0.98742088])\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_prior\")\n@validate_prior_type\ndef bernoulli_beta(x: NUMERIC, prior: Beta) -&gt; Beta:\n    \"\"\"Posterior distribution for a bernoulli likelihood with a beta prior.\n\n    Args:\n        x: successes from a single trial\n        prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    Examples:\n       Information gain from a single coin flip\n\n        ```python\n        from conjugate.distributions import Beta\n        from conjugate.models import bernoulli_beta\n\n        prior = Beta(1, 1)\n\n        # Positive outcome\n        x = 1\n        posterior = bernoulli_beta(\n            x=x,\n            prior=prior\n        )\n\n        posterior.dist.ppf([0.025, 0.975])\n        # array([0.15811388, 0.98742088])\n        ```\n\n    \"\"\"\n    return binomial_beta(n=1, x=x, prior=prior)\n</code></pre>"},{"location":"models/#conjugate.models.bernoulli_beta_predictive","title":"<code>bernoulli_beta_predictive(distribution)</code>","text":"<p>Predictive distribution for a bernoulli likelihood with a beta prior.</p> <p>Use for either prior or posterior predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"beta\")\n@validate_distribution_type\ndef bernoulli_beta_predictive(distribution: Beta) -&gt; BetaBinomial:\n    \"\"\"Predictive distribution for a bernoulli likelihood with a beta prior.\n\n    Use for either prior or posterior predictive distribution.\n\n    Args:\n        distribution: Beta distribution\n\n    Returns:\n        BetaBinomial predictive distribution\n\n    \"\"\"\n    return binomial_beta_predictive(n=1, distribution=distribution)\n</code></pre>"},{"location":"models/#conjugate.models.beta","title":"<code>beta(x_prod, one_minus_x_prod, n, prior)</code>","text":"<p>Posterior distribution for a Beta likelihood.</p> <p>Inference on alpha and beta</p> <p>Parameters:</p> Name Type Description Default <code>x_prod</code> <code>NUMERIC</code> <p>product of all outcomes</p> required <code>one_minus_x_prod</code> <code>NUMERIC</code> <p>product of all (1 - outcomes)</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_prod and one_minus_x_prod</p> required <code>prior</code> <code>BetaProportional</code> <p>BetaProportional prior</p> required <p>Returns:</p> Type Description <code>BetaProportional</code> <p>BetaProportional posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_proportial_prior\")\n@validate_prior_type\ndef beta(\n    x_prod: NUMERIC,\n    one_minus_x_prod: NUMERIC,\n    n: NUMERIC,\n    prior: BetaProportional,\n) -&gt; BetaProportional:\n    \"\"\"Posterior distribution for a Beta likelihood.\n\n    Inference on alpha and beta\n\n    Args:\n        x_prod: product of all outcomes\n        one_minus_x_prod: product of all (1 - outcomes)\n        n: total number of samples in x_prod and one_minus_x_prod\n        prior: BetaProportional prior\n\n    Returns:\n        BetaProportional posterior distribution\n\n    \"\"\"\n    p_post = prior.p * x_prod\n    q_post = prior.q * one_minus_x_prod\n    k_post = prior.k + n\n\n    return BetaProportional(p=p_post, q=q_post, k=k_post)\n</code></pre>"},{"location":"models/#conjugate.models.binomial_beta","title":"<code>binomial_beta(n, x, prior)</code>","text":"<p>Posterior distribution for a binomial likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>total number of trials</p> required <code>x</code> <code>NUMERIC</code> <p>successes from that trials</p> required <code>prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> <p>Examples:</p> <p>A / B test example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta\n\nimpressions = np.array([100, 250])\nclicks = np.array([10, 35])\n\nprior = Beta(1, 1)\n\nposterior = binomial_beta(\n    n=impressions,\n    x=clicks,\n    prior=prior\n)\n\nax = plt.subplot(111)\nposterior.set_bounds(0, 0.5).plot_pdf(ax=ax, label=[\"A\", \"B\"])\nprior.set_bounds(0, 0.5).plot_pdf(ax=ax, label=\"prior\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_prior\")\n@validate_prior_type\ndef binomial_beta(n: NUMERIC, x: NUMERIC, prior: Beta) -&gt; Beta:\n    \"\"\"Posterior distribution for a binomial likelihood with a beta prior.\n\n    Args:\n        n: total number of trials\n        x: successes from that trials\n        prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    Examples:\n        A / B test example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Beta\n        from conjugate.models import binomial_beta\n\n        impressions = np.array([100, 250])\n        clicks = np.array([10, 35])\n\n        prior = Beta(1, 1)\n\n        posterior = binomial_beta(\n            n=impressions,\n            x=clicks,\n            prior=prior\n        )\n\n        ax = plt.subplot(111)\n        posterior.set_bounds(0, 0.5).plot_pdf(ax=ax, label=[\"A\", \"B\"])\n        prior.set_bounds(0, 0.5).plot_pdf(ax=ax, label=\"prior\")\n        ax.legend()\n        ```\n\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/binomial_beta.png\")\n        plt.close()\n        --&gt;\n\n        ![binomial_beta](./images/docstrings/binomial_beta.png)\n\n    \"\"\"\n    alpha_post, beta_post = get_binomial_beta_posterior_params(\n        prior.alpha, prior.beta, n, x\n    )\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.binomial_beta_predictive","title":"<code>binomial_beta_predictive(n, distribution)</code>","text":"<p>Posterior predictive distribution for a binomial likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>distribution</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial predictive distribution</p> <p>Examples:</p> <p>A / B test example with 100 new impressions</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta, binomial_beta_predictive\n\nimpressions = np.array([100, 250])\nclicks = np.array([10, 35])\n\nprior = Beta(1, 1)\nposterior = binomial_beta(\n    n=impressions,\n    x=clicks,\n    prior=prior\n)\nposterior_predictive = binomial_beta_predictive(\n    n=100,\n    distribution=posterior\n)\n\n\nax = plt.subplot(111)\nax.set_title(\"Posterior Predictive Distribution with 100 new impressions\")\nposterior_predictive.set_bounds(0, 50).plot_pmf(\n    ax=ax,\n    label=[\"A\", \"B\"],\n)\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"beta\")\n@validate_distribution_type\ndef binomial_beta_predictive(n: NUMERIC, distribution: Beta) -&gt; BetaBinomial:\n    \"\"\"Posterior predictive distribution for a binomial likelihood with a beta prior.\n\n    Args:\n        n: number of trials\n        distribution: Beta distribution\n\n    Returns:\n        BetaBinomial predictive distribution\n\n    Examples:\n        A / B test example with 100 new impressions\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Beta\n        from conjugate.models import binomial_beta, binomial_beta_predictive\n\n        impressions = np.array([100, 250])\n        clicks = np.array([10, 35])\n\n        prior = Beta(1, 1)\n        posterior = binomial_beta(\n            n=impressions,\n            x=clicks,\n            prior=prior\n        )\n        posterior_predictive = binomial_beta_predictive(\n            n=100,\n            distribution=posterior\n        )\n\n\n        ax = plt.subplot(111)\n        ax.set_title(\"Posterior Predictive Distribution with 100 new impressions\")\n        posterior_predictive.set_bounds(0, 50).plot_pmf(\n            ax=ax,\n            label=[\"A\", \"B\"],\n        )\n        ```\n\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/binomial_beta_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![binomial_beta_predictive](./images/docstrings/binomial_beta_predictive.png)\n    \"\"\"\n    return BetaBinomial(n=n, alpha=distribution.alpha, beta=distribution.beta)\n</code></pre>"},{"location":"models/#conjugate.models.categorical_dirichlet","title":"<code>categorical_dirichlet(x, prior)</code>","text":"<p>Posterior distribution of Categorical model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>counts</p> required <code>prior</code> <code>Dirichlet</code> <p>Dirichlet prior on the counts</p> required <p>Returns:</p> Type Description <code>Dirichlet</code> <p>Dirichlet posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"dirichlet_prior\")\n@validate_prior_type\ndef categorical_dirichlet(x: NUMERIC, prior: Dirichlet) -&gt; Dirichlet:\n    \"\"\"Posterior distribution of Categorical model with Dirichlet prior.\n\n    Args:\n        x: counts\n        prior: Dirichlet prior on the counts\n\n    Returns:\n        Dirichlet posterior distribution\n\n    \"\"\"\n    alpha_post = get_dirichlet_posterior_params(prior.alpha, x)\n\n    return Dirichlet(alpha=alpha_post)\n</code></pre>"},{"location":"models/#conjugate.models.categorical_dirichlet_predictive","title":"<code>categorical_dirichlet_predictive(distribution, n=1)</code>","text":"<p>Predictive distribution of Categorical model with Dirichlet distribution.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Dirichlet</code> <p>Dirichlet distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>DirichletMultinomial</code> <p>DirichletMultinomial distribution related to predictive</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"dirichlet\")\n@validate_distribution_type\ndef categorical_dirichlet_predictive(\n    distribution: Dirichlet,\n    n: NUMERIC = 1,\n) -&gt; DirichletMultinomial:\n    \"\"\"Predictive distribution of Categorical model with Dirichlet distribution.\n\n    Args:\n        distribution: Dirichlet distribution\n        n: Number of trials for each sample, defaults to 1.\n\n    Returns:\n        DirichletMultinomial distribution related to predictive\n\n    \"\"\"\n\n    return DirichletMultinomial(n=n, alpha=distribution.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.exponential_gamma","title":"<code>exponential_gamma(x_total, n, prior)</code>","text":"<p>Posterior distribution for an exponential likelihood with a gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_prior\")\n@validate_prior_type\ndef exponential_gamma(x_total: NUMERIC, n: NUMERIC, prior: Gamma) -&gt; Gamma:\n    \"\"\"Posterior distribution for an exponential likelihood with a gamma prior.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    \"\"\"\n    alpha_post, beta_post = get_exponential_gamma_posterior_params(\n        alpha=prior.alpha, beta=prior.beta, x_total=x_total, n=n\n    )\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.exponential_gamma_predictive","title":"<code>exponential_gamma_predictive(distribution)</code>","text":"<p>Predictive distribution for an exponential likelihood with a gamma distribution</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Gamma</code> <p>Gamma distribution</p> required <p>Returns:</p> Type Description <code>Lomax</code> <p>Lomax distribution related to predictive</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Exponential, Gamma\nfrom conjugate.models import exponential_gamma, exponential_gamma_predictive\n\ntrue = Exponential(1)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Gamma(1, 1)\n\nposterior = exponential_gamma(\n    n=n_samples,\n    x_total=data.sum(),\n    prior=prior\n)\n\nprior_predictive = exponential_gamma_predictive(distribution=prior)\nposterior_predictive = exponential_gamma_predictive(distribution=posterior)\n\nax = plt.subplot(111)\nprior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior predictive\")\ntrue.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"true distribution\")\nposterior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior predictive\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"gamma\")\n@validate_distribution_type\ndef exponential_gamma_predictive(distribution: Gamma) -&gt; Lomax:\n    \"\"\"Predictive distribution for an exponential likelihood with a gamma distribution\n\n    Args:\n        distribution: Gamma distribution\n\n    Returns:\n        Lomax distribution related to predictive\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Exponential, Gamma\n        from conjugate.models import exponential_gamma, exponential_gamma_predictive\n\n        true = Exponential(1)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Gamma(1, 1)\n\n        posterior = exponential_gamma(\n            n=n_samples,\n            x_total=data.sum(),\n            prior=prior\n        )\n\n        prior_predictive = exponential_gamma_predictive(distribution=prior)\n        posterior_predictive = exponential_gamma_predictive(distribution=posterior)\n\n        ax = plt.subplot(111)\n        prior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior predictive\")\n        true.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"true distribution\")\n        posterior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior predictive\")\n        ax.legend()\n        ```\n\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/exponential_gamma_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![exponential_gamma_predictive](./images/docstrings/exponential_gamma_predictive.png)\n    \"\"\"\n    return Lomax(alpha=distribution.beta, lam=distribution.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.gamma","title":"<code>gamma(x_total, x_prod, n, prior)</code>","text":"<p>Posterior distribution for a gamma likelihood.</p> <p>Inference on alpha and beta</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>x_prod</code> <code>NUMERIC</code> <p>product of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total and x_prod</p> required <code>prior</code> <code>GammaProportional</code> <p>GammaProportional prior</p> required <p>Returns:</p> Type Description <code>GammaProportional</code> <p>GammaProportional posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_proportial_prior\")\n@validate_prior_type\ndef gamma(\n    x_total: NUMERIC,\n    x_prod: NUMERIC,\n    n: NUMERIC,\n    prior: GammaProportional,\n) -&gt; GammaProportional:\n    \"\"\"Posterior distribution for a gamma likelihood.\n\n    Inference on alpha and beta\n\n    Args:\n        x_total: sum of all outcomes\n        x_prod: product of all outcomes\n        n: total number of samples in x_total and x_prod\n        prior: GammaProportional prior\n\n    Returns:\n        GammaProportional posterior distribution\n\n    \"\"\"\n    p_post = prior.p * x_prod\n    q_post = prior.q + x_total\n    r_post = prior.r + n\n    s_post = prior.s + n\n\n    return GammaProportional(p=p_post, q=q_post, r=r_post, s=s_post)\n</code></pre>"},{"location":"models/#conjugate.models.gamma_known_rate","title":"<code>gamma_known_rate(x_prod, n, beta, prior)</code>","text":"<p>Posterior distribution for a gamma likelihood.</p> <p>The rate beta is assumed to be known.</p> <p>Parameters:</p> Name Type Description Default <code>x_prod</code> <code>NUMERIC</code> <p>product of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_prod</p> required <code>beta</code> <code>NUMERIC</code> <p>known rate parameter</p> required <p>Returns:</p> Type Description <code>GammaKnownRateProportional</code> <p>GammaKnownRateProportional posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_known_rate_proportial_prior\")\n@validate_prior_type\ndef gamma_known_rate(\n    x_prod: NUMERIC,\n    n: NUMERIC,\n    beta: NUMERIC,\n    prior: GammaKnownRateProportional,\n) -&gt; GammaKnownRateProportional:\n    \"\"\"Posterior distribution for a gamma likelihood.\n\n    The rate beta is assumed to be known.\n\n    Args:\n        x_prod: product of all outcomes\n        n: total number of samples in x_prod\n        beta: known rate parameter\n\n    Returns:\n        GammaKnownRateProportional posterior distribution\n\n    \"\"\"\n    a_post = prior.a * x_prod\n    b_post = prior.b + n\n    c_post = prior.c + n\n\n    return GammaKnownRateProportional(a=a_post, b=b_post, c=c_post)\n</code></pre>"},{"location":"models/#conjugate.models.gamma_known_shape","title":"<code>gamma_known_shape(x_total, n, alpha, prior)</code>","text":"<p>Gamma likelihood with a gamma prior.</p> <p>The shape parameter of the likelihood is assumed to be known.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>alpha</code> <code>NUMERIC</code> <p>known shape parameter</p> required <code>prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Gamma\nfrom conjugate.models import gamma_known_shape\n\nknown_shape = 2\nunknown_rate = 5\ntrue = Gamma(known_shape, unknown_rate)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Gamma(1, 1)\n\nposterior = gamma_known_shape(\n    n=n_samples,\n    x_total=data.sum(),\n    alpha=known_shape,\n    prior=prior,\n)\n\nbound = 10\nax = plt.subplot(111)\nposterior.set_bounds(0, bound).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(0, bound).plot_pdf(ax=ax, label=\"prior\")\nax.axvline(unknown_rate, color=\"black\", linestyle=\"--\", label=\"true rate\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_prior\")\n@validate_prior_type\ndef gamma_known_shape(\n    x_total: NUMERIC,\n    n: NUMERIC,\n    alpha: NUMERIC,\n    prior: Gamma,\n) -&gt; Gamma:\n    \"\"\"Gamma likelihood with a gamma prior.\n\n    The shape parameter of the likelihood is assumed to be known.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        alpha: known shape parameter\n        prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Gamma\n        from conjugate.models import gamma_known_shape\n\n        known_shape = 2\n        unknown_rate = 5\n        true = Gamma(known_shape, unknown_rate)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Gamma(1, 1)\n\n        posterior = gamma_known_shape(\n            n=n_samples,\n            x_total=data.sum(),\n            alpha=known_shape,\n            prior=prior,\n        )\n\n        bound = 10\n        ax = plt.subplot(111)\n        posterior.set_bounds(0, bound).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(0, bound).plot_pdf(ax=ax, label=\"prior\")\n        ax.axvline(unknown_rate, color=\"black\", linestyle=\"--\", label=\"true rate\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/gamma_known_shape.png\")\n        plt.close()\n        --&gt;\n\n        ![gamma_known_shape](./images/docstrings/gamma_known_shape.png)\n\n    \"\"\"\n    alpha_post = prior.alpha + n * alpha\n    beta_post = prior.beta + x_total\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.gamma_known_shape_predictive","title":"<code>gamma_known_shape_predictive(distribution, alpha)</code>","text":"<p>Predictive distribution for a gamma likelihood with a gamma distribution</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Gamma</code> <p>Gamma distribution</p> required <code>alpha</code> <code>NUMERIC</code> <p>known shape parameter</p> required <p>Returns:</p> Type Description <code>CompoundGamma</code> <p>CompoundGamma distribution related to predictive</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"gamma\")\n@validate_distribution_type\ndef gamma_known_shape_predictive(distribution: Gamma, alpha: NUMERIC) -&gt; CompoundGamma:\n    \"\"\"Predictive distribution for a gamma likelihood with a gamma distribution\n\n    Args:\n        distribution: Gamma distribution\n        alpha: known shape parameter\n\n    Returns:\n        CompoundGamma distribution related to predictive\n\n    \"\"\"\n    return CompoundGamma(alpha=alpha, beta=distribution.alpha, lam=distribution.beta)\n</code></pre>"},{"location":"models/#conjugate.models.geometric_beta","title":"<code>geometric_beta(x_total, n, prior, one_start=True)</code>","text":"<p>Posterior distribution for a geometric likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <p>sum of all trials outcomes</p> required <code>n</code> <p>total number of trials</p> required <code>prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <code>one_start</code> <code>bool</code> <p>whether to outcomes start at 1, defaults to True. False is 0 start. one_start is equivalent to number of Bernoulli trails before the first success.</p> <code>True</code> <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> <p>Examples:</p> <p>Number of usages until user has good experience</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import geometric_beta\n\ndata = np.array([3, 1, 1, 3, 2, 1])\n\nprior = Beta(1, 1)\nposterior = geometric_beta(\n    x_total=data.sum(),\n    n=data.size,\n    prior=prior\n)\n\nax = plt.subplot(111)\nposterior.set_bounds(0, 1).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(0, 1).plot_pdf(ax=ax, label=\"prior\")\nax.legend()\nax.set(xlabel=\"chance of good experience\")\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_prior\")\n@validate_prior_type\ndef geometric_beta(x_total, n, prior: Beta, one_start: bool = True) -&gt; Beta:\n    \"\"\"Posterior distribution for a geometric likelihood with a beta prior.\n\n    Args:\n        x_total: sum of all trials outcomes\n        n: total number of trials\n        prior: Beta distribution prior\n        one_start: whether to outcomes start at 1, defaults to True. False is 0 start.\n            one_start is equivalent to number of Bernoulli trails before\n            the first success.\n\n    Returns:\n        Beta distribution posterior\n\n    Examples:\n        Number of usages until user has good experience\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Beta\n        from conjugate.models import geometric_beta\n\n        data = np.array([3, 1, 1, 3, 2, 1])\n\n        prior = Beta(1, 1)\n        posterior = geometric_beta(\n            x_total=data.sum(),\n            n=data.size,\n            prior=prior\n        )\n\n        ax = plt.subplot(111)\n        posterior.set_bounds(0, 1).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(0, 1).plot_pdf(ax=ax, label=\"prior\")\n        ax.legend()\n        ax.set(xlabel=\"chance of good experience\")\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/geometric_beta.png\")\n        plt.close()\n        --&gt;\n\n        ![geometric_beta](./images/docstrings/geometric_beta.png)\n\n    \"\"\"\n    alpha_post = prior.alpha + n\n    beta_post = prior.beta + x_total\n\n    if one_start:\n        beta_post = beta_post - n\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.geometric_beta_predictive","title":"<code>geometric_beta_predictive(distribution, one_start=True)</code>","text":"<p>Predictive distribution for a geometric likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Beta</code> <p>Beta distribution</p> required <code>one_start</code> <code>bool</code> <p>whether to outcomes start at 1, defaults to True. False is 0 start. one_start is equivalent to number of Bernoulli trails before the first success.</p> <code>True</code> <p>Returns:</p> Type Description <code>BetaGeometric</code> <p>BetaGeometric predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_distribution_type\ndef geometric_beta_predictive(\n    distribution: Beta,\n    one_start: bool = True,\n) -&gt; BetaGeometric:\n    \"\"\"Predictive distribution for a geometric likelihood with a beta prior.\n\n    Args:\n        distribution: Beta distribution\n        one_start: whether to outcomes start at 1, defaults to True. False is 0 start.\n            one_start is equivalent to number of Bernoulli trails before\n            the first success.\n\n    Returns:\n        BetaGeometric predictive distribution\n\n    \"\"\"\n\n    return BetaGeometric(\n        alpha=distribution.alpha,\n        beta=distribution.beta,\n        one_start=one_start,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.hypergeometric_beta_binomial","title":"<code>hypergeometric_beta_binomial(x_total, n, prior)</code>","text":"<p>Hypergeometric likelihood with a BetaBinomial prior.</p> <p>The total population size is N and is known. Encode it in the BetaBinomial     prior as n=N</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all trials outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of trials</p> required <code>prior</code> <code>BetaBinomial</code> <p>BetaBinomial prior n is the known N / total population size</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_binomial_prior\")\n@validate_prior_type\ndef hypergeometric_beta_binomial(\n    x_total: NUMERIC,\n    n: NUMERIC,\n    prior: BetaBinomial,\n) -&gt; BetaBinomial:\n    \"\"\"Hypergeometric likelihood with a BetaBinomial prior.\n\n    The total population size is N and is known. Encode it in the BetaBinomial\n        prior as n=N\n\n    Args:\n        x_total: sum of all trials outcomes\n        n: total number of trials\n        prior: BetaBinomial prior\n            n is the known N / total population size\n\n    Returns:\n        BetaBinomial posterior distribution\n\n    \"\"\"\n    n = prior.n\n    alpha_post = prior.alpha + x_total\n    beta_post = prior.beta + (n - x_total)\n\n    return BetaBinomial(n=n, alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.inverse_gamma_known_rate","title":"<code>inverse_gamma_known_rate(reciprocal_x_total, n, alpha, prior)</code>","text":"<p>Inverse Gamma likelihood with a known rate and unknown inverse scale.</p> <p>Parameters:</p> Name Type Description Default <code>reciprocal_x_total</code> <code>NUMERIC</code> <p>sum of all outcomes reciprocals</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>alpha</code> <code>NUMERIC</code> <p>known rate parameter</p> required <code>prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_prior_type\ndef inverse_gamma_known_rate(\n    reciprocal_x_total: NUMERIC,\n    n: NUMERIC,\n    alpha: NUMERIC,\n    prior: Gamma,\n) -&gt; Gamma:\n    \"\"\"Inverse Gamma likelihood with a known rate and unknown inverse scale.\n\n    Args:\n        reciprocal_x_total: sum of all outcomes reciprocals\n        n: total number of samples in x_total\n        alpha: known rate parameter\n        prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    \"\"\"\n    alpha_post = prior.alpha + n * alpha\n    beta_post = prior.beta + reciprocal_x_total\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.linear_regression","title":"<code>linear_regression(X, y, prior, inv=np.linalg.inv)</code>","text":"<p>Posterior distribution for a linear regression model with a normal inverse gamma prior.</p> <p>Derivation taken from this blog here.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>y</code> <code>NUMERIC</code> <p>response vector</p> required <code>prior</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma prior</p> required <code>inv</code> <p>function to invert matrix, defaults to np.linalg.inv</p> <code>inv</code> <p>Returns:</p> Type Description <code>NormalInverseGamma</code> <p>NormalInverseGamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_inverse_gamma_prior\")\n@validate_prior_type\ndef linear_regression(\n    X: NUMERIC,\n    y: NUMERIC,\n    prior: NormalInverseGamma,\n    inv=np.linalg.inv,\n) -&gt; NormalInverseGamma:\n    \"\"\"Posterior distribution for a linear regression model with a normal inverse gamma prior.\n\n    Derivation taken from this blog [here](https://gregorygundersen.com/blog/2020/02/04/bayesian-linear-regression/).\n\n    Args:\n        X: design matrix\n        y: response vector\n        prior: NormalInverseGamma prior\n        inv: function to invert matrix, defaults to np.linalg.inv\n\n    Returns:\n        NormalInverseGamma posterior distribution\n\n    \"\"\"\n    N = X.shape[0]\n\n    delta = inv(prior.delta_inverse)\n\n    delta_post = (X.T @ X) + delta\n    delta_post_inverse = inv(delta_post)\n\n    mu_post = (\n        # (B, B)\n        delta_post_inverse\n        # (B, 1)\n        # (B, B) * (B, 1) +  (B, N) * (N, 1)\n        @ (delta @ prior.mu + X.T @ y)\n    )\n\n    alpha_post = prior.alpha + (0.5 * N)\n    beta_post = prior.beta + (\n        0.5\n        * (\n            (y.T @ y)\n            # (1, B) * (B, B) * (B, 1)\n            + (prior.mu.T @ delta @ prior.mu)\n            # (1, B) * (B, B) * (B, 1)\n            - (mu_post.T @ delta_post @ mu_post)\n        )\n    )\n\n    return NormalInverseGamma(\n        mu=mu_post, delta_inverse=delta_post_inverse, alpha=alpha_post, beta=beta_post\n    )\n</code></pre>"},{"location":"models/#conjugate.models.linear_regression_predictive","title":"<code>linear_regression_predictive(distribution, X, eye=np.eye)</code>","text":"<p>Predictive distribution for a linear regression model with a normal inverse gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma posterior</p> required <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>eye</code> <p>function to get identity matrix, defaults to np.eye</p> <code>eye</code> <p>Returns:</p> Type Description <code>MultivariateStudentT</code> <p>MultivariateStudentT predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"normal_inverse_gamma\")\n@validate_distribution_type\ndef linear_regression_predictive(\n    distribution: NormalInverseGamma,\n    X: NUMERIC,\n    eye=np.eye,\n) -&gt; MultivariateStudentT:\n    \"\"\"Predictive distribution for a linear regression model with a normal inverse gamma prior.\n\n    Args:\n        distribution: NormalInverseGamma posterior\n        X: design matrix\n        eye: function to get identity matrix, defaults to np.eye\n\n    Returns:\n        MultivariateStudentT predictive distribution\n\n    \"\"\"\n    mu = X @ distribution.mu\n    sigma = (distribution.beta / distribution.alpha) * (\n        eye(X.shape[0]) + (X @ distribution.delta_inverse @ X.T)\n    )\n    nu = 2 * distribution.alpha\n\n    return MultivariateStudentT(\n        mu=mu,\n        sigma=sigma,\n        nu=nu,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.log_normal","title":"<code>log_normal(ln_x_total, ln_x2_total, n, prior)</code>","text":"<p>Log normal likelihood.</p> <p>By taking the log of the data, we can use the normal inverse gamma posterior.</p> <p>Reference: Section 1.2.1</p> <p>Parameters:</p> Name Type Description Default <code>ln_x_total</code> <code>NUMERIC</code> <p>sum of the log of all outcomes</p> required <code>ln_x2_total</code> <code>NUMERIC</code> <p>sum of the log of all outcomes squared</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in ln_x_total and ln_x2_total</p> required <code>prior</code> <code>NormalInverseGamma | NormalGamma</code> <p>NormalInverseGamma or NormalGamma prior</p> required <p>Returns:</p> Type Description <code>NormalInverseGamma | NormalGamma</code> <p>NormalInverseGamma or NormalGamma posterior distribution</p> Example <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseGamma, LogNormal\nfrom conjugate.models import log_normal_normal_inverse_gamma\n\ntrue_mu = 0\ntrue_sigma = 2.5\ntrue = LogNormal(true_mu, true_sigma)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nln_data = np.log(data)\n\nprior = NormalInverseGamma(mu=1, nu=1, alpha=1, beta=1)\nposterior = log_normal_normal_inverse_gamma(\n    ln_x_total=ln_data.sum(),\n    ln_x2_total=(ln_data**2).sum(),\n    n=n_samples,\n    prior=prior\n)\n\nfig, axes = plt.subplots(ncols=2)\nmean, variance = posterior.sample_mean(4000, return_variance=True, random_state=42)\n\nax = axes[0]\nax.hist(mean, bins=20)\nax.axvline(true_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\n\nax = axes[1]\nax.hist(variance, bins=20)\nax.axvline(true_sigma**2, color=\"black\", linestyle=\"--\", label=\"true sigma^2\")\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_inverse_wishart_prior\")\n@validate_prior_type\ndef log_normal(\n    ln_x_total: NUMERIC,\n    ln_x2_total: NUMERIC,\n    n: NUMERIC,\n    prior: NormalInverseGamma | NormalGamma,\n) -&gt; NormalInverseGamma | NormalGamma:\n    \"\"\"Log normal likelihood.\n\n    By taking the log of the data, we can use the normal inverse gamma posterior.\n\n    Reference: &lt;a href=https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf&gt;Section 1.2.1&lt;/a&gt;\n\n    Args:\n        ln_x_total: sum of the log of all outcomes\n        ln_x2_total: sum of the log of all outcomes squared\n        n: total number of samples in ln_x_total and ln_x2_total\n        prior: NormalInverseGamma or NormalGamma prior\n\n    Returns:\n        NormalInverseGamma or NormalGamma posterior distribution\n\n    Example:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import NormalInverseGamma, LogNormal\n        from conjugate.models import log_normal_normal_inverse_gamma\n\n        true_mu = 0\n        true_sigma = 2.5\n        true = LogNormal(true_mu, true_sigma)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        ln_data = np.log(data)\n\n        prior = NormalInverseGamma(mu=1, nu=1, alpha=1, beta=1)\n        posterior = log_normal_normal_inverse_gamma(\n            ln_x_total=ln_data.sum(),\n            ln_x2_total=(ln_data**2).sum(),\n            n=n_samples,\n            prior=prior\n        )\n\n        fig, axes = plt.subplots(ncols=2)\n        mean, variance = posterior.sample_mean(4000, return_variance=True, random_state=42)\n\n        ax = axes[0]\n        ax.hist(mean, bins=20)\n        ax.axvline(true_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\n\n        ax = axes[1]\n        ax.hist(variance, bins=20)\n        ax.axvline(true_sigma**2, color=\"black\", linestyle=\"--\", label=\"true sigma^2\")\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/log_normal_normal_inverse_gamma.png\")\n        plt.close()\n        --&gt;\n\n        ![log_normal_normal_inverse_gamma](./images/docstrings/log_normal_normal_inverse_gamma.png)\n    \"\"\"\n\n    return normal(\n        x_total=ln_x_total,\n        x2_total=ln_x2_total,\n        n=n,\n        prior=prior,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.multinomial_dirichlet","title":"<code>multinomial_dirichlet(x, prior)</code>","text":"<p>Posterior distribution of Multinomial model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>counts</p> required <code>prior</code> <code>Dirichlet</code> <p>Dirichlet prior on the counts</p> required <p>Returns:</p> Type Description <code>Dirichlet</code> <p>Dirichlet posterior distribution</p> <p>Examples:</p> <p>Personal preference for ice cream flavors</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Dirichlet\nfrom conjugate.models import multinomial_dirichlet\n\nkinds = [\"chocolate\", \"vanilla\", \"strawberry\"]\ndata = np.array([\n    [5, 2, 1],\n    [3, 1, 0],\n    [3, 2, 0],\n])\n\nprior = Dirichlet([1, 1, 1])\nposterior = multinomial_dirichlet(\n    x=data.sum(axis=0),\n    prior=prior\n)\n\nax = plt.subplot(111)\nposterior.plot_pdf(ax=ax, label=kinds)\nax.legend()\nax.set(xlabel=\"Flavor Preference\")\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"dirichlet_prior\")\n@validate_prior_type\ndef multinomial_dirichlet(x: NUMERIC, prior: Dirichlet) -&gt; Dirichlet:\n    \"\"\"Posterior distribution of Multinomial model with Dirichlet prior.\n\n    Args:\n        x: counts\n        prior: Dirichlet prior on the counts\n\n    Returns:\n        Dirichlet posterior distribution\n\n    Examples:\n        Personal preference for ice cream flavors\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Dirichlet\n        from conjugate.models import multinomial_dirichlet\n\n        kinds = [\"chocolate\", \"vanilla\", \"strawberry\"]\n        data = np.array([\n            [5, 2, 1],\n            [3, 1, 0],\n            [3, 2, 0],\n        ])\n\n        prior = Dirichlet([1, 1, 1])\n        posterior = multinomial_dirichlet(\n            x=data.sum(axis=0),\n            prior=prior\n        )\n\n        ax = plt.subplot(111)\n        posterior.plot_pdf(ax=ax, label=kinds)\n        ax.legend()\n        ax.set(xlabel=\"Flavor Preference\")\n        ```\n\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/multinomial_dirichlet.png\")\n        plt.close()\n        --&gt;\n\n        ![multinomial_dirichlet](./images/docstrings/multinomial_dirichlet.png)\n\n    \"\"\"\n    alpha_post = get_dirichlet_posterior_params(prior.alpha, x)\n\n    return Dirichlet(alpha=alpha_post)\n</code></pre>"},{"location":"models/#conjugate.models.multinomial_dirichlet_predictive","title":"<code>multinomial_dirichlet_predictive(distribution, n=1)</code>","text":"<p>Predictive distribution of Multinomial model with Dirichlet distribution.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Dirichlet</code> <p>Dirichlet distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>DirichletMultinomial</code> <p>DirichletMultinomial distribution related to predictive</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"dirichlet\")\n@validate_distribution_type\ndef multinomial_dirichlet_predictive(\n    distribution: Dirichlet,\n    n: NUMERIC = 1,\n) -&gt; DirichletMultinomial:\n    \"\"\"Predictive distribution of Multinomial model with Dirichlet distribution.\n\n    Args:\n        distribution: Dirichlet distribution\n        n: Number of trials for each sample, defaults to 1.\n\n    Returns:\n        DirichletMultinomial distribution related to predictive\n\n    \"\"\"\n\n    return DirichletMultinomial(n=n, alpha=distribution.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal","title":"<code>multivariate_normal(X, prior, outer=np.outer)</code>","text":"<p>Multivariate normal likelihood with normal inverse wishart prior.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>mu</code> <p>known mean</p> required <code>prior</code> <code>NormalInverseWishart</code> <p>NormalInverseWishart prior</p> required <code>outer</code> <p>function to take outer product, defaults to np.outer</p> <code>outer</code> <p>Returns:</p> Type Description <code>NormalInverseWishart</code> <p>NormalInverseWishart posterior distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseWishart\nfrom conjugate.models import multivariate_normal\n\ntrue_mean = np.array([1, 5])\ntrue_cov = np.array([\n    [1, 0.5],\n    [0.5, 1],\n])\n\nn_samples = 100\nrng = np.random.default_rng(42)\ndata = rng.multivariate_normal(\n    mean=true_mean,\n    cov=true_cov,\n    size=n_samples,\n)\n\nprior = NormalInverseWishart(\n    mu=np.array([0, 0]),\n    kappa=1,\n    nu=3,\n    psi=np.array([\n        [1, 0],\n        [0, 1],\n    ]),\n)\n\nposterior = multivariate_normal(\n    X=data,\n    prior=prior,\n)\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_inverse_wishart_prior\")\n@validate_prior_type\ndef multivariate_normal(\n    X: NUMERIC,\n    prior: NormalInverseWishart,\n    outer=np.outer,\n) -&gt; NormalInverseWishart:\n    \"\"\"Multivariate normal likelihood with normal inverse wishart prior.\n\n    Args:\n        X: design matrix\n        mu: known mean\n        prior: NormalInverseWishart prior\n        outer: function to take outer product, defaults to np.outer\n\n    Returns:\n        NormalInverseWishart posterior distribution\n\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import NormalInverseWishart\n        from conjugate.models import multivariate_normal\n\n        true_mean = np.array([1, 5])\n        true_cov = np.array([\n            [1, 0.5],\n            [0.5, 1],\n        ])\n\n        n_samples = 100\n        rng = np.random.default_rng(42)\n        data = rng.multivariate_normal(\n            mean=true_mean,\n            cov=true_cov,\n            size=n_samples,\n        )\n\n        prior = NormalInverseWishart(\n            mu=np.array([0, 0]),\n            kappa=1,\n            nu=3,\n            psi=np.array([\n                [1, 0],\n                [0, 1],\n            ]),\n        )\n\n        posterior = multivariate_normal(\n            X=data,\n            prior=prior,\n        )\n        ```\n    \"\"\"\n    n = X.shape[0]\n    X_mean = X.mean(axis=0)\n    C = (X - X_mean).T @ (X - X_mean)\n\n    mu_post = (prior.mu * prior.kappa + n * X_mean) / (prior.kappa + n)\n\n    kappa_post = prior.kappa + n\n    nu_post = prior.nu + n\n\n    mean_difference = X_mean - prior.mu\n    psi_post = (\n        prior.psi\n        + C\n        + outer(mean_difference, mean_difference) * n * prior.kappa / kappa_post\n    )\n\n    return NormalInverseWishart(\n        mu=mu_post,\n        kappa=kappa_post,\n        nu=nu_post,\n        psi=psi_post,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_known_covariance","title":"<code>multivariate_normal_known_covariance(n, x_bar, cov, prior, inv=np.linalg.inv)</code>","text":"<p>Multivariate normal likelihood with known covariance and multivariate normal prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>x_bar</code> <code>NUMERIC</code> <p>mean of samples</p> required <code>cov</code> <code>NUMERIC</code> <p>known covariance</p> required <code>prior</code> <code>MultivariateNormal</code> <p>MultivariateNormal prior for the mean</p> required <code>inv</code> <p>function to invert matrix, defaults to np.linalg.inv</p> <code>inv</code> <p>Returns:</p> Type Description <code>MultivariateNormal</code> <p>MultivariateNormal posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_prior_type\ndef multivariate_normal_known_covariance(\n    n: NUMERIC,\n    x_bar: NUMERIC,\n    cov: NUMERIC,\n    prior: MultivariateNormal,\n    inv=np.linalg.inv,\n) -&gt; MultivariateNormal:\n    \"\"\"Multivariate normal likelihood with known covariance and multivariate normal prior.\n\n    Args:\n        n: number of samples\n        x_bar: mean of samples\n        cov: known covariance\n        prior: MultivariateNormal prior for the mean\n        inv: function to invert matrix, defaults to np.linalg.inv\n\n    Returns:\n        MultivariateNormal posterior distribution\n\n    \"\"\"\n    mu_bar_0 = prior.mu\n    precision_0 = inv(prior.cov)\n\n    precision = inv(cov)\n\n    mu_post, precision_post = _multivariate_normal_known_precision(\n        n=n,\n        x_bar_0=mu_bar_0,\n        precision_0=precision_0,\n        x_bar=x_bar,\n        precision=precision,\n    )\n\n    return MultivariateNormal(mu=mu_post, cov=inv(precision_post))\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_known_covariance_predictive","title":"<code>multivariate_normal_known_covariance_predictive(distribution, cov)</code>","text":"<p>Predictive distribution for a multivariate normal likelihood with known covariance and a multivariate normal prior.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>MultivariateNormal</code> <p>MultivariateNormal distribution</p> required <code>cov</code> <code>NUMERIC</code> <p>known covariance</p> required <p>Returns:</p> Type Description <code>MultivariateNormal</code> <p>MultivariateNormal predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_distribution_type\ndef multivariate_normal_known_covariance_predictive(\n    distribution: MultivariateNormal,\n    cov: NUMERIC,\n) -&gt; MultivariateNormal:\n    \"\"\"Predictive distribution for a multivariate normal likelihood with known covariance and a multivariate normal prior.\n\n    Args:\n        distribution: MultivariateNormal distribution\n        cov: known covariance\n\n    Returns:\n        MultivariateNormal predictive distribution\n\n    \"\"\"\n    mu_pred = distribution.mu\n    cov_pred = distribution.cov + cov\n    return MultivariateNormal(mu=mu_pred, cov=cov_pred)\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_known_mean","title":"<code>multivariate_normal_known_mean(X, mu, prior)</code>","text":"<p>Multivariate normal likelihood with known mean and inverse wishart prior.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>mu</code> <code>NUMERIC</code> <p>known mean</p> required <code>prior</code> <code>InverseWishart</code> <p>InverseWishart prior</p> required <p>Returns:</p> Type Description <code>InverseWishart</code> <p>InverseWishart posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"inverse_wishart_prior\")\n@validate_prior_type\ndef multivariate_normal_known_mean(\n    X: NUMERIC,\n    mu: NUMERIC,\n    prior: InverseWishart,\n) -&gt; InverseWishart:\n    \"\"\"Multivariate normal likelihood with known mean and inverse wishart prior.\n\n    Args:\n        X: design matrix\n        mu: known mean\n        prior: InverseWishart prior\n\n    Returns:\n        InverseWishart posterior distribution\n\n    \"\"\"\n    nu_post = prior.nu + X.shape[0]\n    psi_post = prior.psi + (X - mu).T @ (X - mu)\n\n    return InverseWishart(\n        nu=nu_post,\n        psi=psi_post,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_known_precision","title":"<code>multivariate_normal_known_precision(n, x_bar, precision, prior, inv=np.linalg.inv)</code>","text":"<p>Multivariate normal likelihood with known precision and multivariate normal prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>x_bar</code> <code>NUMERIC</code> <p>mean of samples</p> required <code>precision</code> <code>NUMERIC</code> <p>known precision</p> required <code>prior</code> <code>MultivariateNormal</code> <p>MultivariateNormal prior for the mean</p> required <code>inv</code> <p>function to invert matrix, defaults to np.linalg.inv</p> <code>inv</code> <p>Returns:</p> Type Description <code>MultivariateNormal</code> <p>MultivariateNormal posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_prior_type\ndef multivariate_normal_known_precision(\n    n: NUMERIC,\n    x_bar: NUMERIC,\n    precision: NUMERIC,\n    prior: MultivariateNormal,\n    inv=np.linalg.inv,\n) -&gt; MultivariateNormal:\n    \"\"\"Multivariate normal likelihood with known precision and multivariate normal prior.\n\n    Args:\n        n: number of samples\n        x_bar: mean of samples\n        precision: known precision\n        prior: MultivariateNormal prior for the mean\n        inv: function to invert matrix, defaults to np.linalg.inv\n\n    Returns:\n        MultivariateNormal posterior distribution\n\n    \"\"\"\n    mu_0 = prior.mu\n    precision_0 = inv(prior.cov)\n\n    mu_post, precision_post = _multivariate_normal_known_precision(\n        n=n,\n        x_bar_0=mu_0,\n        precision_0=precision_0,\n        x_bar=x_bar,\n        precision=precision,\n    )\n\n    return MultivariateNormal(mu=mu_post, cov=inv(precision_post))\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_known_precision_predictive","title":"<code>multivariate_normal_known_precision_predictive(distribution, precision, inv=np.linalg.inv)</code>","text":"<p>Predictive distribution for a multivariate normal likelihood with known precision and a multivariate normal prior.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>MultivariateNormal</code> <p>MultivariateNormal distribution</p> required <code>precision</code> <code>NUMERIC</code> <p>known precision</p> required <code>inv</code> <code>Callable</code> <p>function to invert matrix, defaults to np.linalg.inv</p> <code>inv</code> <p>Returns:</p> Type Description <code>MultivariateNormal</code> <p>MultivariateNormal predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_distribution_type\ndef multivariate_normal_known_precision_predictive(\n    distribution: MultivariateNormal,\n    precision: NUMERIC,\n    inv: Callable = np.linalg.inv,\n) -&gt; MultivariateNormal:\n    \"\"\"Predictive distribution for a multivariate normal likelihood with known precision and a multivariate normal prior.\n\n    Args:\n        distribution: MultivariateNormal distribution\n        precision: known precision\n        inv: function to invert matrix, defaults to np.linalg.inv\n\n    Returns:\n        MultivariateNormal predictive distribution\n\n    \"\"\"\n    mu_pred = distribution.mu\n    cov_pred = distribution.cov + inv(precision)\n    return MultivariateNormal(mu=mu_pred, cov=cov_pred)\n</code></pre>"},{"location":"models/#conjugate.models.multivariate_normal_predictive","title":"<code>multivariate_normal_predictive(distribution)</code>","text":"<p>Multivariate normal likelihood with normal inverse wishart distribution.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>NormalInverseWishart</code> <p>NormalInverseWishart distribution</p> required <p>Returns:</p> Type Description <code>MultivariateStudentT</code> <p>MultivariateStudentT predictive distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseWishart, MultivariateNormal\nfrom conjugate.models import multivariate_normal, multivariate_normal_predictive\n\nmu_1 = 10\nmu_2 = 5\nsigma_1 = 2.5\nsigma_2 = 1.5\nrho = -0.65\ntrue_mean = np.array([mu_1, mu_2])\ntrue_cov = np.array([\n    [sigma_1 ** 2, rho * sigma_1 * sigma_2],\n    [rho * sigma_1 * sigma_2, sigma_2 ** 2],\n])\ntrue = MultivariateNormal(true_mean, true_cov)\n\nn_samples = 100\nrng = np.random.default_rng(42)\ndata = true.dist.rvs(size=n_samples, random_state=rng)\n\nprior = NormalInverseWishart(\n    mu=np.array([0, 0]),\n    kappa=1,\n    nu=2,\n    psi=np.array([\n        [5 ** 2, 0],\n        [0, 5 ** 2],\n    ]),\n)\n\nposterior = multivariate_normal(\n    X=data,\n    prior=prior,\n)\nprior_predictive = multivariate_normal_predictive(distribution=prior)\nposterior_predictive = multivariate_normal_predictive(distribution=posterior)\n\nax = plt.subplot(111)\n\nxmax = mu_1 + 3 * sigma_1\nymax = mu_2 + 3 * sigma_2\nx, y = np.mgrid[-xmax:xmax:.1, -ymax:ymax:.1]\npos = np.dstack((x, y))\nz = true.dist.pdf(pos)\n# z = np.where(z &lt; 0.005, np.nan, z)\ncontours = ax.contour(x, y, z, alpha=0.55, color=\"black\")\n\nfor label, dist in zip([\"prior\", \"posterior\"], [prior_predictive, posterior_predictive]):\n    X = dist.dist.rvs(size=1000)\n    ax.scatter(X[:, 0], X[:, 1], alpha=0.15, label=f\"{label} predictive\")\n\nax.axvline(0, color=\"black\", linestyle=\"--\")\nax.axhline(0, color=\"black\", linestyle=\"--\")\nax.scatter(data[:, 0], data[:, 1], label=\"data\", alpha=0.5)\nax.scatter(mu_1, mu_2, color=\"black\", marker=\"x\", label=\"true mean\")\n\nax.set(\n    xlabel=\"x1\",\n    ylabel=\"x2\",\n    title=f\"Posterior predictive after {n_samples} samples\",\n    xlim=(-xmax, xmax),\n    ylim=(-ymax, ymax),\n)\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"normal_inverse_wishart\")\n@validate_distribution_type\ndef multivariate_normal_predictive(\n    distribution: NormalInverseWishart,\n) -&gt; MultivariateStudentT:\n    \"\"\"Multivariate normal likelihood with normal inverse wishart distribution.\n\n    Args:\n        distribution: NormalInverseWishart distribution\n\n    Returns:\n        MultivariateStudentT predictive distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import NormalInverseWishart, MultivariateNormal\n        from conjugate.models import multivariate_normal, multivariate_normal_predictive\n\n        mu_1 = 10\n        mu_2 = 5\n        sigma_1 = 2.5\n        sigma_2 = 1.5\n        rho = -0.65\n        true_mean = np.array([mu_1, mu_2])\n        true_cov = np.array([\n            [sigma_1 ** 2, rho * sigma_1 * sigma_2],\n            [rho * sigma_1 * sigma_2, sigma_2 ** 2],\n        ])\n        true = MultivariateNormal(true_mean, true_cov)\n\n        n_samples = 100\n        rng = np.random.default_rng(42)\n        data = true.dist.rvs(size=n_samples, random_state=rng)\n\n        prior = NormalInverseWishart(\n            mu=np.array([0, 0]),\n            kappa=1,\n            nu=2,\n            psi=np.array([\n                [5 ** 2, 0],\n                [0, 5 ** 2],\n            ]),\n        )\n\n        posterior = multivariate_normal(\n            X=data,\n            prior=prior,\n        )\n        prior_predictive = multivariate_normal_predictive(distribution=prior)\n        posterior_predictive = multivariate_normal_predictive(distribution=posterior)\n\n        ax = plt.subplot(111)\n\n        xmax = mu_1 + 3 * sigma_1\n        ymax = mu_2 + 3 * sigma_2\n        x, y = np.mgrid[-xmax:xmax:.1, -ymax:ymax:.1]\n        pos = np.dstack((x, y))\n        z = true.dist.pdf(pos)\n        # z = np.where(z &lt; 0.005, np.nan, z)\n        contours = ax.contour(x, y, z, alpha=0.55, color=\"black\")\n\n        for label, dist in zip([\"prior\", \"posterior\"], [prior_predictive, posterior_predictive]):\n            X = dist.dist.rvs(size=1000)\n            ax.scatter(X[:, 0], X[:, 1], alpha=0.15, label=f\"{label} predictive\")\n\n        ax.axvline(0, color=\"black\", linestyle=\"--\")\n        ax.axhline(0, color=\"black\", linestyle=\"--\")\n        ax.scatter(data[:, 0], data[:, 1], label=\"data\", alpha=0.5)\n        ax.scatter(mu_1, mu_2, color=\"black\", marker=\"x\", label=\"true mean\")\n\n        ax.set(\n            xlabel=\"x1\",\n            ylabel=\"x2\",\n            title=f\"Posterior predictive after {n_samples} samples\",\n            xlim=(-xmax, xmax),\n            ylim=(-ymax, ymax),\n        )\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/multivariate_normal_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![multivariate_normal_predictive](./images/docstrings/multivariate_normal_predictive.png)\n    \"\"\"\n\n    p = distribution.psi.shape[0]\n    mu = distribution.mu\n    nu = distribution.nu - p + 1\n    sigma = (\n        (distribution.kappa + 1)\n        * distribution.psi\n        / (distribution.kappa * (distribution.nu - p + 1))\n    )\n\n    return MultivariateStudentT(mu=mu, sigma=sigma, nu=nu)\n</code></pre>"},{"location":"models/#conjugate.models.negative_binomial_beta","title":"<code>negative_binomial_beta(r, n, x, prior)</code>","text":"<p>Posterior distribution for a negative binomial likelihood with a beta prior.</p> <p>Assumed known number of failures r</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>NUMERIC</code> <p>number of failures</p> required <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>x</code> <code>NUMERIC</code> <p>number of successes</p> required <code>prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"beta_prior\")\n@validate_prior_type\ndef negative_binomial_beta(r: NUMERIC, n: NUMERIC, x: NUMERIC, prior: Beta) -&gt; Beta:\n    \"\"\"Posterior distribution for a negative binomial likelihood with a beta prior.\n\n    Assumed known number of failures r\n\n    Args:\n        r: number of failures\n        n: number of trials\n        x: number of successes\n        prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    \"\"\"\n    alpha_post = prior.alpha + (r * n)\n    beta_post = prior.beta + x\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.negative_binomial_beta_predictive","title":"<code>negative_binomial_beta_predictive(r, distribution)</code>","text":"<p>Predictive distribution for a negative binomial likelihood with a beta prior</p> <p>Assumed known number of failures r</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>NUMERIC</code> <p>number of failures</p> required <code>distribution</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaNegativeBinomial</code> <p>BetaNegativeBinomial predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"beta\")\n@validate_distribution_type\ndef negative_binomial_beta_predictive(\n    r: NUMERIC,\n    distribution: Beta,\n) -&gt; BetaNegativeBinomial:\n    \"\"\"Predictive distribution for a negative binomial likelihood with a beta prior\n\n    Assumed known number of failures r\n\n    Args:\n        r: number of failures\n        distribution: Beta distribution\n\n    Returns:\n        BetaNegativeBinomial predictive distribution\n\n    \"\"\"\n    return BetaNegativeBinomial(n=r, alpha=distribution.alpha, beta=distribution.beta)\n</code></pre>"},{"location":"models/#conjugate.models.normal","title":"<code>normal(x_total, x2_total, n, prior)</code>","text":"<p>Posterior distribution for a normal likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>x2_total</code> <code>NUMERIC</code> <p>sum of all outcomes squared</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total and x2_total</p> required <code>prior</code> <code>NormalInverseGamma | NormalGamma</code> <p>NormalInverseGamma or NormalGamma prior</p> required <p>Returns:</p> Type Description <code>NormalInverseGamma | NormalGamma</code> <p>NormalInverseGamma or NormalGamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_prior_type\ndef normal(\n    x_total: NUMERIC,\n    x2_total: NUMERIC,\n    n: NUMERIC,\n    prior: NormalInverseGamma | NormalGamma,\n) -&gt; NormalInverseGamma | NormalGamma:\n    \"\"\"Posterior distribution for a normal likelihood.\n\n    Args:\n        x_total: sum of all outcomes\n        x2_total: sum of all outcomes squared\n        n: total number of samples in x_total and x2_total\n        prior: NormalInverseGamma or NormalGamma prior\n\n    Returns:\n        NormalInverseGamma or NormalGamma posterior distribution\n\n    \"\"\"\n    if isinstance(prior, NormalInverseGamma) and prior.nu is None:\n        raise ValueError(\"nu must be provided for the prior\")\n\n    mu_post, nu_post, alpha_post, beta_post = _normal(\n        x_total=x_total,\n        x2_total=x2_total,\n        n=n,\n        mu_0=prior.mu,\n        nu=prior.lam if isinstance(prior, NormalGamma) else prior.nu,  # type: ignore\n        alpha=prior.alpha,\n        beta=prior.beta,\n    )\n\n    kwargs = (\n        {\n            \"mu\": mu_post,\n            \"lam\": nu_post,\n            \"alpha\": alpha_post,\n            \"beta\": beta_post,\n        }\n        if isinstance(prior, NormalGamma)\n        else {\n            \"mu\": mu_post,\n            \"nu\": nu_post,\n            \"alpha\": alpha_post,\n            \"beta\": beta_post,\n        }\n    )\n\n    return prior.__class__(**kwargs)\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_mean","title":"<code>normal_known_mean(x_total, x2_total, n, mu, prior)</code>","text":"<p>Posterior distribution for a normal likelihood with a known mean and a variance prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>x2_total</code> <code>NUMERIC</code> <p>sum of all outcomes squared</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>mu</code> <code>NUMERIC</code> <p>known mean</p> required <code>prior</code> <code>InverseGamma | ScaledInverseChiSquared</code> <p>InverseGamma or ScaledInverseChiSquared prior for variance</p> required <p>Returns:</p> Type Description <code>InverseGamma | ScaledInverseChiSquared</code> <p>InverseGamma or ScaledInverseChiSquared posterior for variance</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"inverse_gamma_prior\")\n@validate_prior_type\ndef normal_known_mean(\n    x_total: NUMERIC,\n    x2_total: NUMERIC,\n    n: NUMERIC,\n    mu: NUMERIC,\n    prior: InverseGamma | ScaledInverseChiSquared,\n) -&gt; InverseGamma | ScaledInverseChiSquared:\n    \"\"\"Posterior distribution for a normal likelihood with a known mean and a variance prior.\n\n    Args:\n        x_total: sum of all outcomes\n        x2_total: sum of all outcomes squared\n        n: total number of samples in x_total\n        mu: known mean\n        prior: InverseGamma or ScaledInverseChiSquared prior for variance\n\n    Returns:\n        InverseGamma or ScaledInverseChiSquared posterior for variance\n\n    \"\"\"\n    inverse_gamma_input = isinstance(prior, InverseGamma)\n    prior = prior if inverse_gamma_input else prior.to_inverse_gamma()\n\n    posterior = _normal_known_mean_inverse_gamma_prior(\n        x_total=x_total,\n        x2_total=x2_total,\n        n=n,\n        mu=mu,\n        prior=prior,\n    )\n\n    if not inverse_gamma_input:\n        return ScaledInverseChiSquared.from_inverse_gamma(posterior)\n\n    return posterior\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_mean_predictive","title":"<code>normal_known_mean_predictive(mu, distribution)</code>","text":"<p>Predictive distribution for a normal likelihood with a known mean and a variance prior.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>known mean</p> required <code>distribution</code> <code>InverseGamma | ScaledInverseChiSquared</code> <p>InverseGamma or ScaledInverseChiSquared prior</p> required <p>Returns:</p> Type Description <code>StudentT</code> <p>StudentT predictive distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Normal, InverseGamma\nfrom conjugate.models import normal_known_mean, normal_known_mean_predictive\n\nunknown_var = 2.5\nknown_mu = 0\ntrue = Normal(known_mu, unknown_var**0.5)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = InverseGamma(1, 1)\n\nposterior = normal_known_mean(\n    n=n_samples,\n    x_total=data.sum(),\n    x2_total=(data**2).sum(),\n    mu=known_mu,\n    prior=prior\n)\n\nbound = 5\nax = plt.subplot(111)\nprior_predictive = normal_known_mean_predictive(\n    mu=known_mu,\n    distribution=prior,\n)\nprior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\ntrue.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\nposterior_predictive = normal_known_mean_predictive(\n    mu=known_mu,\n    distribution=posterior,\n)\nposterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"inverse_gamma\")\n@validate_distribution_type\ndef normal_known_mean_predictive(\n    mu: NUMERIC,\n    distribution: InverseGamma | ScaledInverseChiSquared,\n) -&gt; StudentT:\n    \"\"\"Predictive distribution for a normal likelihood with a known mean and a variance prior.\n\n    Args:\n        mu: known mean\n        distribution: InverseGamma or ScaledInverseChiSquared prior\n\n    Returns:\n        StudentT predictive distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Normal, InverseGamma\n        from conjugate.models import normal_known_mean, normal_known_mean_predictive\n\n        unknown_var = 2.5\n        known_mu = 0\n        true = Normal(known_mu, unknown_var**0.5)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = InverseGamma(1, 1)\n\n        posterior = normal_known_mean(\n            n=n_samples,\n            x_total=data.sum(),\n            x2_total=(data**2).sum(),\n            mu=known_mu,\n            prior=prior\n        )\n\n        bound = 5\n        ax = plt.subplot(111)\n        prior_predictive = normal_known_mean_predictive(\n            mu=known_mu,\n            distribution=prior,\n        )\n        prior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\n        true.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\n        posterior_predictive = normal_known_mean_predictive(\n            mu=known_mu,\n            distribution=posterior,\n        )\n        posterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/normal_known_mean_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![normal_known_mean_predictive](./images/docstrings/normal_known_mean_predictive.png)\n\n    \"\"\"\n    if isinstance(distribution, ScaledInverseChiSquared):\n        distribution = distribution.to_inverse_gamma()\n\n    return StudentT(\n        mu=mu,\n        sigma=(distribution.beta / distribution.alpha) ** 0.5,\n        nu=2 * distribution.alpha,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_precision","title":"<code>normal_known_precision(x_total, n, precision, prior)</code>","text":"<p>Posterior distribution for a normal likelihood with known precision and a normal prior on mean.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>precision</code> <code>NUMERIC</code> <p>known precision</p> required <code>prior</code> <code>Normal</code> <p>Normal prior for mean</p> required <p>Returns:</p> Type Description <code>Normal</code> <p>Normal posterior distribution for the mean</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Normal\nfrom conjugate.models import normal_known_precision\n\nunknown_mu = 0\nknown_precision = 0.5\ntrue = Normal.from_mean_and_precision(unknown_mu, known_precision**0.5)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Normal(0, 10)\n\nposterior = normal_known_precision(\n    n=n_samples,\n    x_total=data.sum(),\n    precision=known_precision,\n    prior=prior\n)\n\nbound = 5\nax = plt.subplot(111)\nposterior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior\")\nax.axvline(unknown_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_prior\")\n@validate_prior_type\ndef normal_known_precision(\n    x_total: NUMERIC,\n    n: NUMERIC,\n    precision: NUMERIC,\n    prior: Normal,\n) -&gt; Normal:\n    \"\"\"Posterior distribution for a normal likelihood with known precision and a normal prior on mean.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        precision: known precision\n        prior: Normal prior for mean\n\n    Returns:\n        Normal posterior distribution for the mean\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Normal\n        from conjugate.models import normal_known_precision\n\n        unknown_mu = 0\n        known_precision = 0.5\n        true = Normal.from_mean_and_precision(unknown_mu, known_precision**0.5)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Normal(0, 10)\n\n        posterior = normal_known_precision(\n            n=n_samples,\n            x_total=data.sum(),\n            precision=known_precision,\n            prior=prior\n        )\n\n        bound = 5\n        ax = plt.subplot(111)\n        posterior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior\")\n        ax.axvline(unknown_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/normal_known_precision.png\")\n        plt.close()\n        --&gt;\n\n        ![normal_known_precision](./images/docstrings/normal_known_precision.png)\n\n    \"\"\"\n    return normal_known_variance(\n        x_total=x_total,\n        n=n,\n        var=1 / precision,\n        prior=prior,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_precision_predictive","title":"<code>normal_known_precision_predictive(precision, distribution)</code>","text":"<p>Predictive distribution for a normal likelihood with known precision and a normal prior on mean.</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>NUMERIC</code> <p>known precision</p> required <code>distribution</code> <code>Normal</code> <p>Normal posterior distribution for the mean</p> required <p>Returns:</p> Type Description <code>Normal</code> <p>Normal predictive distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Normal\nfrom conjugate.models import normal_known_precision, normal_known_precision_predictive\n\nunknown_mu = 0\nknown_precision = 0.5\ntrue = Normal.from_mean_and_precision(unknown_mu, known_precision)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Normal(0, 10)\n\nposterior = normal_known_precision(\n    n=n_samples,\n    x_total=data.sum(),\n    precision=known_precision,\n    prior=prior\n)\n\nprior_predictive = normal_known_precision_predictive(\n    precision=known_precision,\n    distribution=prior,\n)\nposterior_predictive = normal_known_precision_predictive(\n    precision=known_precision,\n    distribution=posterior,\n)\n\nbound = 5\nax = plt.subplot(111)\ntrue.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\nposterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\nprior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"normal\")\n@validate_distribution_type\ndef normal_known_precision_predictive(\n    precision: NUMERIC,\n    distribution: Normal,\n) -&gt; Normal:\n    \"\"\"Predictive distribution for a normal likelihood with known precision and a normal prior on mean.\n\n    Args:\n        precision: known precision\n        distribution: Normal posterior distribution for the mean\n\n    Returns:\n        Normal predictive distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Normal\n        from conjugate.models import normal_known_precision, normal_known_precision_predictive\n\n        unknown_mu = 0\n        known_precision = 0.5\n        true = Normal.from_mean_and_precision(unknown_mu, known_precision)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Normal(0, 10)\n\n        posterior = normal_known_precision(\n            n=n_samples,\n            x_total=data.sum(),\n            precision=known_precision,\n            prior=prior\n        )\n\n        prior_predictive = normal_known_precision_predictive(\n            precision=known_precision,\n            distribution=prior,\n        )\n        posterior_predictive = normal_known_precision_predictive(\n            precision=known_precision,\n            distribution=posterior,\n        )\n\n        bound = 5\n        ax = plt.subplot(111)\n        true.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\n        posterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\n        prior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/normal_known_precision_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![normal_known_precision_predictive](./images/docstrings/normal_known_precision_predictive.png)\n\n    \"\"\"\n    return normal_known_variance_predictive(\n        var=1 / precision,\n        distribution=distribution,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_variance","title":"<code>normal_known_variance(x_total, n, var, prior)</code>","text":"<p>Posterior distribution for a normal likelihood with known variance and a normal prior on mean.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>var</code> <code>NUMERIC</code> <p>known variance</p> required <code>prior</code> <code>Normal</code> <p>Normal prior for mean</p> required <p>Returns:</p> Type Description <code>Normal</code> <p>Normal posterior distribution for the mean</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Normal\nfrom conjugate.models import normal_known_variance\n\nunknown_mu = 0\nknown_var = 2.5\ntrue = Normal(unknown_mu, known_var**0.5)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Normal(0, 10)\n\nposterior = normal_known_variance(\n    n=n_samples,\n    x_total=data.sum(),\n    var=known_var,\n    prior=prior,\n)\n\nbound = 5\nax = plt.subplot(111)\nposterior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior\")\nax.axvline(unknown_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_prior\")\n@validate_prior_type\ndef normal_known_variance(\n    x_total: NUMERIC,\n    n: NUMERIC,\n    var: NUMERIC,\n    prior: Normal,\n) -&gt; Normal:\n    \"\"\"Posterior distribution for a normal likelihood with known variance and a normal prior on mean.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        var: known variance\n        prior: Normal prior for mean\n\n    Returns:\n        Normal posterior distribution for the mean\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Normal\n        from conjugate.models import normal_known_variance\n\n        unknown_mu = 0\n        known_var = 2.5\n        true = Normal(unknown_mu, known_var**0.5)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Normal(0, 10)\n\n        posterior = normal_known_variance(\n            n=n_samples,\n            x_total=data.sum(),\n            var=known_var,\n            prior=prior,\n        )\n\n        bound = 5\n        ax = plt.subplot(111)\n        posterior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior\")\n        ax.axvline(unknown_mu, color=\"black\", linestyle=\"--\", label=\"true mu\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/normal_known_variance.png\")\n        plt.close()\n        --&gt;\n\n        ![normal_known_variance](./images/docstrings/normal_known_variance.png)\n\n    \"\"\"\n    mu_post = ((prior.mu / prior.sigma**2) + (x_total / var)) / (\n        (1 / prior.sigma**2) + (n / var)\n    )\n\n    var_post = 1 / ((1 / prior.sigma**2) + (n / var))\n\n    return Normal(mu=mu_post, sigma=var_post**0.5)\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_variance_predictive","title":"<code>normal_known_variance_predictive(var, distribution)</code>","text":"<p>Predictive distribution for a normal likelihood with known variance and a normal distribution on mean.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>NUMERIC</code> <p>known variance</p> required <code>distribution</code> <code>Normal</code> <p>Normal distribution for the mean</p> required <p>Returns:</p> Type Description <code>Normal</code> <p>Normal predictive distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Normal\nfrom conjugate.models import normal_known_variance, normal_known_variance_predictive\n\nunknown_mu = 0\nknown_var = 2.5\ntrue = Normal(unknown_mu, known_var**0.5)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Normal(0, 10)\n\nposterior = normal_known_variance(\n    n=n_samples,\n    x_total=data.sum(),\n    var=known_var,\n    prior=prior\n)\n\nprior_predictive = normal_known_variance_predictive(\n    var=known_var,\n    distribution=prior,\n)\nposterior_predictive = normal_known_variance_predictive(\n    var=known_var,\n    distribution=posterior,\n)\n\nbound = 5\nax = plt.subplot(111)\ntrue.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\nposterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\nprior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"normal\")\n@validate_distribution_type\ndef normal_known_variance_predictive(var: NUMERIC, distribution: Normal) -&gt; Normal:\n    \"\"\"Predictive distribution for a normal likelihood with known variance and a normal distribution on mean.\n\n    Args:\n        var: known variance\n        distribution: Normal distribution for the mean\n\n    Returns:\n        Normal predictive distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Normal\n        from conjugate.models import normal_known_variance, normal_known_variance_predictive\n\n        unknown_mu = 0\n        known_var = 2.5\n        true = Normal(unknown_mu, known_var**0.5)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Normal(0, 10)\n\n        posterior = normal_known_variance(\n            n=n_samples,\n            x_total=data.sum(),\n            var=known_var,\n            prior=prior\n        )\n\n        prior_predictive = normal_known_variance_predictive(\n            var=known_var,\n            distribution=prior,\n        )\n        posterior_predictive = normal_known_variance_predictive(\n            var=known_var,\n            distribution=posterior,\n        )\n\n        bound = 5\n        ax = plt.subplot(111)\n        true.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"true distribution\")\n        posterior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"posterior predictive\")\n        prior_predictive.set_bounds(-bound, bound).plot_pdf(ax=ax, label=\"prior predictive\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/normal_known_variance_predictive.png\")\n        plt.close()\n        --&gt;\n\n        ![normal_known_variance_predictive](./images/docstrings/normal_known_variance_predictive.png)\n\n    \"\"\"\n    var_posterior_predictive = var + distribution.sigma**2\n    return Normal(mu=distribution.mu, sigma=var_posterior_predictive**0.5)\n</code></pre>"},{"location":"models/#conjugate.models.normal_normal_inverse_gamma","title":"<code>normal_normal_inverse_gamma(x_total, x2_total, n, prior)</code>","text":"<p>Posterior distribution for a normal likelihood with a normal inverse gamma prior.</p> <p>Derivation from paper here.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>x2_total</code> <code>NUMERIC</code> <p>sum of all outcomes squared</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total and x2_total</p> required <code>prior</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma prior</p> required <p>Returns:</p> Type Description <code>NormalInverseGamma</code> <p>NormalInverseGamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"normal_inverse_gamma_prior\")\n@validate_prior_type\ndef normal_normal_inverse_gamma(\n    x_total: NUMERIC,\n    x2_total: NUMERIC,\n    n: NUMERIC,\n    prior: NormalInverseGamma,\n) -&gt; NormalInverseGamma:\n    \"\"\"Posterior distribution for a normal likelihood with a normal inverse gamma prior.\n\n    Derivation from paper [here](https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf).\n\n    Args:\n        x_total: sum of all outcomes\n        x2_total: sum of all outcomes squared\n        n: total number of samples in x_total and x2_total\n        prior: NormalInverseGamma prior\n\n    Returns:\n        NormalInverseGamma posterior distribution\n\n    \"\"\"\n    warnings.warn(\n        \"This function is deprecated. Use 'normal' instead.\",\n        DeprecationWarning,\n        stacklevel=1,\n    )\n\n    return normal(x_total=x_total, x2_total=x2_total, n=n, prior=prior)  # type: ignore\n</code></pre>"},{"location":"models/#conjugate.models.normal_normal_inverse_gamma_predictive","title":"<code>normal_normal_inverse_gamma_predictive(distribution)</code>","text":"<p>Predictive distribution for Normal likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma distribution</p> required <p>Returns:</p> Type Description <code>StudentT</code> <p>StudentT predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"normal_inverse_gamma\")\n@validate_distribution_type\ndef normal_normal_inverse_gamma_predictive(\n    distribution: NormalInverseGamma,\n) -&gt; StudentT:\n    \"\"\"Predictive distribution for Normal likelihood.\n\n    Args:\n        distribution: NormalInverseGamma distribution\n\n    Returns:\n        StudentT predictive distribution\n\n    \"\"\"\n    warnings.warn(\n        \"This function is deprecated. Use 'normal_predictive' instead.\",\n        DeprecationWarning,\n        stacklevel=1,\n    )\n    return normal_predictive(distribution=distribution)\n</code></pre>"},{"location":"models/#conjugate.models.normal_predictive","title":"<code>normal_predictive(distribution)</code>","text":"<p>Predictive distribution for Normal likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>NormalInverseGamma | NormalGamma</code> <p>NormalInverseGamma or NormalGamma distribution</p> required <p>Returns:</p> Type Description <code>StudentT</code> <p>StudentT predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_distribution_type\ndef normal_predictive(\n    distribution: NormalInverseGamma | NormalGamma,\n) -&gt; StudentT:\n    \"\"\"Predictive distribution for Normal likelihood.\n\n    Args:\n        distribution: NormalInverseGamma or NormalGamma distribution\n\n    Returns:\n        StudentT predictive distribution\n\n    \"\"\"\n    nu = (\n        distribution.nu\n        if isinstance(distribution, NormalInverseGamma)\n        else distribution.lam\n    )\n    var = distribution.beta * (nu + 1) / (nu * distribution.alpha)\n    return StudentT(\n        mu=distribution.mu,\n        sigma=var**0.5,\n        nu=2 * distribution.alpha,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.pareto_gamma","title":"<code>pareto_gamma(n, ln_x_total, x_m, prior, ln=np.log)</code>","text":"<p>Posterior distribution for a pareto likelihood with a gamma prior.</p> <p>The parameter x_m is assumed to be known.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>ln_x_total</code> <code>NUMERIC</code> <p>sum of the log of all outcomes</p> required <code>x_m</code> <code>NUMERIC</code> <p>The known minimum value</p> required <code>prior</code> <code>Gamma</code> <p>Gamma prior</p> required <code>ln</code> <p>function to take the natural log, defaults to np.log</p> <code>log</code> <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Pareto, Gamma\nfrom conjugate.models import pareto_gamma\n\nx_m_known = 1\ntrue = Pareto(x_m_known, 1)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Gamma(1, 1)\n\nposterior = pareto_gamma(\n    n=n_samples,\n    ln_x_total=np.log(data).sum(),\n    x_m=x_m_known,\n    prior=prior,\n)\n\nax = plt.subplot(111)\nposterior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x_m_known, color=\"black\", linestyle=\"--\", label=\"true x_m\")\nax.legend()\n</code></pre> <p></p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_prior\")\n@validate_prior_type\ndef pareto_gamma(\n    n: NUMERIC,\n    ln_x_total: NUMERIC,\n    x_m: NUMERIC,\n    prior: Gamma,\n    ln=np.log,\n) -&gt; Gamma:\n    \"\"\"Posterior distribution for a pareto likelihood with a gamma prior.\n\n    The parameter x_m is assumed to be known.\n\n    Args:\n        n: number of samples\n        ln_x_total: sum of the log of all outcomes\n        x_m: The known minimum value\n        prior: Gamma prior\n        ln: function to take the natural log, defaults to np.log\n\n    Returns:\n        Gamma posterior distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Pareto, Gamma\n        from conjugate.models import pareto_gamma\n\n        x_m_known = 1\n        true = Pareto(x_m_known, 1)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Gamma(1, 1)\n\n        posterior = pareto_gamma(\n            n=n_samples,\n            ln_x_total=np.log(data).sum(),\n            x_m=x_m_known,\n            prior=prior,\n        )\n\n        ax = plt.subplot(111)\n        posterior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior\")\n        ax.axvline(x_m_known, color=\"black\", linestyle=\"--\", label=\"true x_m\")\n        ax.legend()\n        ```\n        &lt;!--\n        plt.savefig(\"./docs/images/docstrings/pareto_gamma.png\")\n        plt.close()\n        --&gt;\n\n        ![pareto_gamma](./images/docstrings/pareto_gamma.png)\n\n    \"\"\"\n    alpha_post = prior.alpha + n\n    beta_post = prior.beta + ln_x_total - n * ln(x_m)\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.poisson_gamma","title":"<code>poisson_gamma(x_total, n, prior)</code>","text":"<p>Posterior distribution for a poisson likelihood with a gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"gamma_prior\")\n@validate_prior_type\ndef poisson_gamma(x_total: NUMERIC, n: NUMERIC, prior: Gamma) -&gt; Gamma:\n    \"\"\"Posterior distribution for a poisson likelihood with a gamma prior.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    \"\"\"\n    alpha_post, beta_post = get_poisson_gamma_posterior_params(\n        alpha=prior.alpha, beta=prior.beta, x_total=x_total, n=n\n    )\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.poisson_gamma_predictive","title":"<code>poisson_gamma_predictive(distribution, n=1)</code>","text":"<p>Predictive distribution for a poisson likelihood with a gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>Gamma</code> <p>Gamma distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1. Can be used to scale the distributions to a different unit of time.</p> <code>1</code> <p>Returns:</p> Type Description <code>NegativeBinomial</code> <p>NegativeBinomial distribution related to predictive</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_distribution_parameter(\"gamma\")\n@validate_distribution_type\ndef poisson_gamma_predictive(distribution: Gamma, n: NUMERIC = 1) -&gt; NegativeBinomial:\n    \"\"\"Predictive distribution for a poisson likelihood with a gamma distribution.\n\n    Args:\n        distribution: Gamma distribution\n        n: Number of trials for each sample, defaults to 1.\n            Can be used to scale the distributions to a different unit of time.\n\n    Returns:\n        NegativeBinomial distribution related to predictive\n\n    \"\"\"\n    n = n * distribution.alpha\n    p = distribution.beta / (1 + distribution.beta)\n\n    return NegativeBinomial(n=n, p=p)\n</code></pre>"},{"location":"models/#conjugate.models.uniform_pareto","title":"<code>uniform_pareto(x_max, n, prior, max_fn=np.maximum)</code>","text":"<p>Posterior distribution for a uniform likelihood with a pareto prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_max</code> <code>NUMERIC</code> <p>maximum value</p> required <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>prior</code> <code>Pareto</code> <p>Pareto prior</p> required <code>max_fn</code> <p>elementwise max function, defaults to np.maximum</p> <code>maximum</code> <p>Returns:</p> Type Description <code>Pareto</code> <p>Pareto posterior distribution</p> <p>Examples:</p> <p>Get the posterior for this model with simulated data:</p> <pre><code>from conjugate.distributions import Uniform, Pareto\nfrom conjugate.models import uniform_pareto\n\ntrue_max = 5\ntrue = Uniform(0, true_max)\n\nn_samples = 10\ndata = true.dist.rvs(size=n_samples)\n\nprior = Pareto(1, 1)\n\nposterior = uniform_pareto(\n    x_max=data.max(),\n    n=n_samples,\n    prior=prior\n)\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"pareto_prior\")\n@validate_prior_type\ndef uniform_pareto(\n    x_max: NUMERIC,\n    n: NUMERIC,\n    prior: Pareto,\n    max_fn=np.maximum,\n) -&gt; Pareto:\n    \"\"\"Posterior distribution for a uniform likelihood with a pareto prior.\n\n    Args:\n        x_max: maximum value\n        n: number of samples\n        prior: Pareto prior\n        max_fn: elementwise max function, defaults to np.maximum\n\n    Returns:\n        Pareto posterior distribution\n\n    Examples:\n        Get the posterior for this model with simulated data:\n\n        ```python\n        from conjugate.distributions import Uniform, Pareto\n        from conjugate.models import uniform_pareto\n\n        true_max = 5\n        true = Uniform(0, true_max)\n\n        n_samples = 10\n        data = true.dist.rvs(size=n_samples)\n\n        prior = Pareto(1, 1)\n\n        posterior = uniform_pareto(\n            x_max=data.max(),\n            n=n_samples,\n            prior=prior\n        )\n        ```\n\n    \"\"\"\n    alpha_post = prior.alpha + n\n    x_m_post = max_fn(prior.x_m, x_max)\n\n    return Pareto(x_m=x_m_post, alpha=alpha_post)\n</code></pre>"},{"location":"models/#conjugate.models.von_mises_known_concentration","title":"<code>von_mises_known_concentration(cos_total, sin_total, n, kappa, prior, sin=np.sin, cos=np.cos, arctan2=np.arctan2)</code>","text":"<p>VonMises likelihood with known concentration parameter.</p> <p>Taken from Section 2.13.1.</p> <p>Parameters:</p> Name Type Description Default <code>cos_total</code> <code>NUMERIC</code> <p>sum of all cosines</p> required <code>sin_total</code> <code>NUMERIC</code> <p>sum of all sines</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in cos_total and sin_total</p> required <code>kappa</code> <code>NUMERIC</code> <p>known concentration parameter</p> required <code>prior</code> <code>VonMisesKnownConcentration</code> <p>VonMisesKnownConcentration prior</p> required <p>Returns:</p> Type Description <code>VonMisesKnownConcentration</code> <p>VonMisesKnownConcentration posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"von_mises_known_concentration_prior\")\n@validate_prior_type\ndef von_mises_known_concentration(\n    cos_total: NUMERIC,\n    sin_total: NUMERIC,\n    n: NUMERIC,\n    kappa: NUMERIC,\n    prior: VonMisesKnownConcentration,\n    sin=np.sin,\n    cos=np.cos,\n    arctan2=np.arctan2,\n) -&gt; VonMisesKnownConcentration:\n    \"\"\"VonMises likelihood with known concentration parameter.\n\n    Taken from &lt;a href=https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf&gt;Section 2.13.1&lt;/a&gt;.\n\n    Args:\n        cos_total: sum of all cosines\n        sin_total: sum of all sines\n        n: total number of samples in cos_total and sin_total\n        kappa: known concentration parameter\n        prior: VonMisesKnownConcentration prior\n\n    Returns:\n        VonMisesKnownConcentration posterior distribution\n\n    \"\"\"\n    sin_total_post = prior.a * sin(prior.b) + sin_total\n    a_post = kappa * sin_total_post\n\n    b_post = arctan2(sin_total_post, prior.a * cos(prior.b) + cos_total)\n\n    return VonMisesKnownConcentration(a=a_post, b=b_post)\n</code></pre>"},{"location":"models/#conjugate.models.von_mises_known_direction","title":"<code>von_mises_known_direction(centered_cos_total, n, prior)</code>","text":"<p>VonMises likelihood with known direction parameter.</p> <p>Taken from Section 2.13.2</p> <p>Parameters:</p> Name Type Description Default <code>centered_cos_total</code> <code>NUMERIC</code> <p>sum of all centered cosines. sum cos(x - known direction))</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in centered_cos_total</p> required <code>prior</code> <code>VonMisesKnownDirectionProportional</code> <p>VonMisesKnownDirectionProportional prior</p> required Source code in <code>conjugate/models.py</code> <pre><code>@deprecate_prior_parameter(\"von_mises_known_direction_proportial_prior\")\n@validate_prior_type\ndef von_mises_known_direction(\n    centered_cos_total: NUMERIC,\n    n: NUMERIC,\n    prior: VonMisesKnownDirectionProportional,\n) -&gt; VonMisesKnownDirectionProportional:\n    \"\"\"VonMises likelihood with known direction parameter.\n\n    Taken from &lt;a href=https://web.archive.org/web/20090529203101/http://www.people.cornell.edu/pages/df36/CONJINTRnew%20TEX.pdf&gt;Section 2.13.2&lt;/a&gt;\n\n    Args:\n        centered_cos_total: sum of all centered cosines. sum cos(x - known direction))\n        n: total number of samples in centered_cos_total\n        prior: VonMisesKnownDirectionProportional prior\n\n    \"\"\"\n\n    return VonMisesKnownDirectionProportional(\n        c=prior.c + n,\n        r=prior.r + centered_cos_total,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.weibull_inverse_gamma_known_shape","title":"<code>weibull_inverse_gamma_known_shape(n, x_beta_total, prior)</code>","text":"<p>Posterior distribution for a Weibull likelihood with an inverse gamma prior on shape.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>total number of samples</p> required <code>x_beta_total</code> <code>NUMERIC</code> <p>sum of all x^beta</p> required <code>prior</code> <code>InverseGamma</code> <p>InverseGamma prior</p> required <p>Returns:</p> Type Description <code>InverseGamma</code> <p>InverseGamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>@validate_prior_type\ndef weibull_inverse_gamma_known_shape(\n    n: NUMERIC,\n    x_beta_total: NUMERIC,\n    prior: InverseGamma,\n) -&gt; InverseGamma:\n    \"\"\"Posterior distribution for a Weibull likelihood with an inverse gamma prior on shape.\n\n    Args:\n        n: total number of samples\n        x_beta_total: sum of all x^beta\n        prior: InverseGamma prior\n\n    Returns:\n        InverseGamma posterior distribution\n\n    \"\"\"\n    alpha_post = prior.alpha + n\n    beta_post = prior.beta + x_beta_total\n\n    return InverseGamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"examples/bayesian-update/","title":"Bayesian Update","text":"<p>Easy to use Bayesian inference incrementally by setting the posterior to the prior for the next set of data points. </p> <p>Abstractly, something like this: </p> <pre><code>prior = ...\n\nfor batch_size in batch_sizes:\n    data = sample(n=batch_size)\n\n    posterior = model(data, prior=prior)\n\n    prior = posterior\n</code></pre> <p>Below are some concrete examples</p>"},{"location":"examples/bayesian-update/#normal-distribution","title":"Normal Distribution","text":"<p>We can use the normal model with <code>NormalInverseGamma</code> distribution as prior</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseGamma\nfrom conjugate.models import normal\n\ndef create_sampler(mu, sigma, rng): \n    \"\"\"Generate a sampler from a normal distribution with mean `mu` and standard deviation `sigma`.\"\"\"\n    def sample(n: int): \n        return rng.normal(loc=mu, scale=sigma, size=n)\n\n    return sample\n\n\nmu = 5.0\nsigma = 2.5\nrng = np.random.default_rng(0)\nsample = create_sampler(mu=mu, sigma=sigma, rng=rng)\n\n\nprior = NormalInverseGamma(\n    mu=0, \n    alpha=1, beta=1, \n    nu=1, \n)\n\ncumsum = 0\nbatch_sizes = [5, 10, 25]\nax = plt.gca()\nfor batch_size in batch_sizes:\n    data = sample(n=batch_size)\n\n    posterior = normal(\n        x_total=data.sum(), \n        x2_total=(data ** 2).sum(), \n        n=batch_size, \n        prior=prior\n    )\n\n    beta_samples, variance_samples = posterior.sample_beta(size=1000, return_variance=True, random_state=rng)\n\n    cumsum += batch_size\n    label = f\"n={cumsum}\"\n    ax.scatter(variance_samples ** 0.5, beta_samples, alpha=0.25, label=label)\n\n    prior = posterior \n\nax.scatter(sigma, mu, color=\"black\", label=\"true\")\nax.set(\n    xlabel=\"$\\sigma$\", \n    ylabel=\"$\\mu$\", \n    xlim=(0, None), \n    ylim=(0, None), \n    title=\"Updated posterior samples of $\\mu$ and $\\sigma$\"\n)\nax.legend()\n\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/bayesian-update/#binomial-distribution","title":"Binomial Distribution","text":"<p>With a Binomial model, we can assume as Beta prior</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta\n\ndef create_sampler(p, rng): \n    def sampler(n: int): \n        return rng.binomial(n=n, p=p)\n\n    return sampler\n\nprior = Beta(1, 1)\n\np = 0.75\nrng = np.random.default_rng(0)\nsample = create_sampler(p=p, rng=rng)\n\nax = plt.gca()\ncumsum = 0\nbatch_sizes = [5, 25, 50]\nfor batch_size in batch_sizes: \n    x = sample(n=batch_size)\n\n    posterior = binomial_beta(\n        x=x, \n        n=batch_size, \n        prior=prior, \n    )\n\n    cumsum += batch_size\n    label = f\"n={cumsum}\"\n\n    posterior.plot_pdf(ax=ax, label=label)\n\n    prior = posterior\n\nax.axvline(p, label=\"true p\", color=\"black\", ymax=0.05)\nax.set(\n    xlabel=\"p\", \n    ylim=(None, 10), \n)\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/binomial/","title":"Binomial Model","text":""},{"location":"examples/binomial/#import-modules","title":"Import modules","text":"<p>Import the required distributions: </p> <ul> <li><code>Binomial</code>: The assumed model likelihood</li> <li><code>Beta</code>: Prior for <code>Binomial</code> distribution</li> <li><code>BetaBinomial</code>: The posterior predictive distribution</li> </ul> <p>and the functions: </p> <ul> <li><code>binomial_beta</code>: get the posterior distribution from data and prior</li> <li><code>binomial_beta_predictive</code>: get the posterior predictive</li> </ul> <pre><code>from conjugate.distributions import Beta, Binomial, BetaBinomial\nfrom conjugate.models import binomial_beta, binomial_beta_predictive\n\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"examples/binomial/#observed-data","title":"Observed Data","text":"<p>Generate some data from the assumed likelihood</p> <pre><code>N = 10\ntrue_dist = Binomial(n=N, p=0.5)\n\n# Observed Data\nX = true_dist.dist.rvs(size=1, random_state=42)\n</code></pre>"},{"location":"examples/binomial/#bayesian-inference","title":"Bayesian Inference","text":"<p>Get the posterior and posterior predictive distributions</p> <pre><code># Conjugate prior\nprior = Beta(alpha=1, beta=1)\nposterior: Beta = binomial_beta(n=N, x=X, prior=prior)\n\n# Comparison\nprior_predictive: BetaBinomial = binomial_beta_predictive(\n    n=N, \n    distribution=prior, \n)\nposterior_predictive: BetaBinomial = binomial_beta_predictive(\n    n=N, \n    distribution=posterior, \n)\n</code></pre>"},{"location":"examples/binomial/#additional-analysis","title":"Additional Analysis","text":"<p>Perform any analysis on the distributions</p> <pre><code># Figure \nfig, axes = plt.subplots(ncols=2, nrows=1, figsize=(8, 4))\n\nax: plt.Axes = axes[0]\nposterior.plot_pdf(ax=ax, label=\"posterior\")\nprior.plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x=X/N, color=\"black\", ymax=0.05, label=\"MLE\")\nax.axvline(x=true_dist.p, color=\"black\", ymax=0.05, linestyle=\"--\", label=\"True\")\nax.set_title(\"Success Rate\")\nax.legend()\n\nax: plt.Axes = axes[1]\ntrue_dist.plot_pmf(ax=ax, label=\"true distribution\", color=\"C2\")\nposterior_predictive.plot_pmf(ax=ax, label=\"posterior predictive\")\nprior_predictive.plot_pmf(ax=ax, label=\"prior predictive\")\nax.axvline(x=X, color=\"black\", ymax=0.05, label=\"Sample\")\nax.set_title(\"Number of Successes\")\nax.legend()\n\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/bootstrap/","title":"Bootstrap Comparison","text":"<p>In this example, we will compare the bootstrap method with the use of a Bayesian model.</p> <p>Bootstrap is statistical method which relies on resampling of the  data in order to estimate the uncertainty of a given statistic. </p> <p>In order to do this comparison, the <code>pandas-bootstrap</code> package will be used.</p> <p>The statistic in this example will be the maximum value of 10 samples.</p>"},{"location":"examples/bootstrap/#setup","title":"Setup","text":"<p>Imports and setup of random number generator. Here, we will assume that the data comes from a Poisson distribution with an unknown rate parameter.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport bootstrap\n\nfrom conjugate.distributions import (\n    Gamma, \n    NegativeBinomial,\n    Poisson, \n)\nfrom conjugate.models import (\n    poisson_gamma, \n    poisson_gamma_predictive,\n)\n\nseed = sum(map(ord, \"Bootstrap comparison\"))\nrng = np.random.default_rng(seed)\n\ntrue_lambda = 1.5\ntrue_distribution = Poisson(true_lambda)\n\ndef create_data_generator(true_distribution, rng): \n    def generate_data(size) -&gt; pd.Series:\n        return pd.Series(true_distribution.dist.rvs(size=size, random_state=rng))\n    return generate_data\n\n\ngenerate_data = create_data_generator(true_distribution, rng)\n</code></pre>"},{"location":"examples/bootstrap/#bootstrap-method","title":"Bootstrap method","text":"<p>In order to generate the statistic for the bootstrap method, we just need to create function that gets the maximum value of the desired sample size. </p> <p>The <code>boot</code> attribute of the <code>pandas.Series</code> is an object from <code>pandas-bootstrap</code> to facilitate the bootstrap process. Read more about it in the  documentation here.</p> <pre><code>n_new = 10\nsamples = 5_000\n\ndef stat(data: pd.Series, n: int) -&gt; int:\n    return data.sample(frac=1).iloc[:n].max()\n\ndef create_bootstrap_stat(n_new: int, samples: int):\n    def bootstrap_stat(data: pd.Series) -&gt; pd.Series: \n        return data.boot.get_samples(stat, n=n_new, B=samples)\n    return bootstrap_stat\n\nbootstrap_stat = create_bootstrap_stat(n_new, samples)\n</code></pre>"},{"location":"examples/bootstrap/#conjugate-model","title":"Conjugate model","text":"<p>For the Bayesian model, we will use a Gamma prior as that is the conjugate prior for the Poisson distribution.</p> <pre><code>def get_posterior_predictive(data: pd.Series, prior: Gamma) -&gt; NegativeBinomial:\n    x_total = data.sum()\n    n = len(data)\n    posterior = poisson_gamma(x_total=x_total, n=n, prior=prior)\n    return poisson_gamma_predictive(distribution=posterior)\n\ndef create_conjugate_stat(n_new: int, samples: int, prior: Gamma): \n    def conjugate_stat(data: pd.Series) -&gt; pd.Series: \n        posterior_predictive = get_posterior_predictive(data, prior)\n        return pd.Series(\n            posterior_predictive\n            .dist\n            .rvs((n_new, samples))\n            .max(axis=0)\n        )\n    return conjugate_stat\n\nprior = Gamma(1, 1)\nconjugate_stat = create_conjugate_stat(n_new=n_new, samples=samples, prior=prior)\n</code></pre>"},{"location":"examples/bootstrap/#comparison","title":"Comparison","text":"<p>Compare the two methods across different sample sizes by plotting the PDF of the maximum value of 10 samples.</p> <pre><code>ns = [5, 25, 50, 100]\n\nnrows = 2\nncols = 2\nfig, axes = plt.subplots(\n    nrows=nrows, \n    ncols=ncols, \n    figsize=(ncols * 5, nrows * 5),\n    sharex=True, \n    sharey=True,\n)\n\ndef plot_processing(samples: pd.Series, max_value: int) -&gt; pd.Series:\n    return (\n        samples\n        .value_counts(normalize=True)\n        .reindex(range(0, max_value), fill_value=0)\n    )\n\nmax_value = 8\n\ntrue_samples = pd.Series(\n    true_distribution.dist.rvs((n_new, samples)).max(axis=0),\n)\ntrue_pdf = true_samples.pipe(plot_processing, max_value=max_value)\n\nfor ax, n in zip(axes.ravel(), ns):\n    data = generate_data(size=n)\n\n    bootstrap_samples = data.pipe(bootstrap_stat)\n    conjugate_samples = data.pipe(conjugate_stat)\n\n    true_pdf.plot(ax=ax, label=\"True\", color=\"black\", linestyle=\"--\")\n    bootstrap_samples.pipe(plot_processing, max_value=max_value).plot(ax=ax, label=\"Bootstrap\")\n    conjugate_samples.pipe(plot_processing, max_value=max_value).plot(ax=ax, label=\"Model\")\n\n    ax.legend()\n    ax.set(title=f\"{n = } samples\")\n</code></pre> <p></p> <p>The plot shows the stability of the Bayesian model compared to the bootstrap method as well as the strength that Bayes methods have in low sample size scenarios.</p>"},{"location":"examples/generalized-inputs/","title":"Generalized Numerical Inputs","text":"<p>Conjugate models work with anything that works like numbers. </p>"},{"location":"examples/generalized-inputs/#polars","title":"Polars","text":"<p>For instance, Bayesian models with the Polars package: </p> <pre><code>import polars as pl\n\n# Data\ndf = pl.DataFrame({\n    \"total\": [10, 20, 50],\n    \"successes\": [5, 10, 25]\n})\n\n# Conjugate prior\nprior = Beta(alpha=1, beta=1)\nposterior = binomial_beta(n=df[\"total\"], x=df[\"successes\"], prior=prior)\n\nax = posterior.plot_pdf(label=df[\"total\"])\nax.legend(title=\"sample size\")\n</code></pre> <p></p>"},{"location":"examples/generalized-inputs/#models-with-sql","title":"Models with SQL","text":"<p>For instance, Bayesian models in SQL using the SQL Builder, PyPika</p> <pre><code>from pypika import Field \n\n# Columns from table in database\nN = Field(\"total\")\nX = Field(\"successes\")\n\n# Conjugate prior\nprior = Beta(alpha=1, beta=1)\nposterior = binomial_beta(n=N, x=X, prior=prior)\n\nprint(\"Posterior alpha:\", posterior.alpha)\nprint(\"Posterior beta:\", posterior.beta)\n# Posterior alpha: 1+\"successes\"\n# Posterior beta: 1+\"total\"-\"successes\"\n\n# Priors can be fields too\nalpha = Field(\"previous_successes\") - 1\nbeta = Field(\"previous_failures\") - 1\n\nprior = Beta(alpha=alpha, beta=beta)\nposterior = binomial_beta(n=N, x=X, prior=prior)\n\nprint(\"Posterior alpha:\", posterior.alpha)\nprint(\"Posterior beta:\", posterior.beta)\n# Posterior alpha: \"previous_successes\"-1+\"successes\"\n# Posterior beta: \"previous_failures\"-1+\"total\"-\"successes\"\n</code></pre>"},{"location":"examples/generalized-inputs/#pymc","title":"PyMC","text":"<p>Using PyMC distributions for sampling with additional uncertainty</p> <pre><code>import pymc as pm \n\nalpha = pm.Gamma.dist(alpha=1, beta=20)\nbeta = pm.Gamma.dist(alpha=1, beta=20)\n\n# Observed Data\nN = 10\nX = 4\n\n# Conjugate prior \nprior = Beta(alpha=alpha, beta=beta)\nposterior = binomial_beta(n=N, x=X, prior=prior)\n\n# Reconstruct the posterior distribution with PyMC\nprior_dist = pm.Beta.dist(alpha=prior.alpha, beta=prior.beta)\nposterior_dist = pm.Beta.dist(alpha=posterior.alpha, beta=posterior.beta)\n\nsamples = pm.draw([alpha, beta, prior_dist, posterior_dist], draws=1000)\n</code></pre>"},{"location":"examples/indexing/","title":"Indexing Parameters","text":"<p>The distributions can be indexed for subsets. </p> <pre><code>beta = np.arange(1, 10)\nprior = Beta(alpha=1, beta=beta)\n\nidx = [0, 5, -1]\nprior_subset = prior[idx]\nprior_subset.plot_pdf(label = lambda i: f\"prior {i}\")\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/linear-regression/","title":"Linear Regression","text":"<p>We can fit linear regression that includes a predictive distribution for new data using a conjugate prior. This example only has one covariate, but the same approach can be used for multiple covariates.</p>"},{"location":"examples/linear-regression/#simulate-data","title":"Simulate Data","text":"<p>We are going to simulate data from a linear regression model. The true intercept is 3.5, the true slope is -2.0, and the true variance is 2.5.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseGamma, MultivariateStudentT\nfrom conjugate.models import linear_regression, linear_regression_predictive\n\nintercept = 3.5\nslope = -2.0\nsigma = 2.5\n\nrng = np.random.default_rng(0)\n\nx_lim = 3\nn_points = 100\nx = np.linspace(-x_lim, x_lim, n_points)\ny = intercept + slope * x + rng.normal(scale=sigma, size=n_points)\n</code></pre>"},{"location":"examples/linear-regression/#define-prior-and-find-posterior","title":"Define Prior and Find Posterior","text":"<p>There needs to be a prior for the intercept, slope, and the variance. </p> <pre><code>prior = NormalInverseGamma(\n    mu=np.array([0, 0]),\n    delta_inverse=np.array([[1, 0], [0, 1]]),\n    alpha=1,\n    beta=1,\n)\n\ndef create_X(x: np.ndarray) -&gt; np.ndarray:\n    return np.stack([np.ones_like(x), x]).T\n\nX = create_X(x)\nposterior: NormalInverseGamma = linear_regression(\n    X=X,\n    y=y,\n    prior=prior,\n)\n</code></pre>"},{"location":"examples/linear-regression/#posterior-predictive-for-new-data","title":"Posterior Predictive for New Data","text":"<p>The multivariate student-t distribution is used for the posterior predictive distribution. We have to draw samples from it since the scipy implementation does not have a <code>ppf</code> method.</p> <pre><code># New Data\nx_lim_new = 1.5 * x_lim\nx_new = np.linspace(-x_lim_new, x_lim_new, 20)\nX_new = create_X(x_new)\npp: MultivariateStudentT = linear_regression_predictive(distribution=posterior, X=X_new)\n\nsamples = pp.dist.rvs(5_000).T\ndf_samples = pd.DataFrame(samples, index=x_new)\n</code></pre>"},{"location":"examples/linear-regression/#plot-results","title":"Plot Results","text":"<p>We can see that the posterior predictive distribution begins to widen as we move away from the data. </p> <p>Overall, the posterior predictive distribution is a good fit for the data. The true line is within the 95% posterior predictive interval.</p> <pre><code>def plot_abline(intercept: float, slope: float, ax: plt.Axes = None, **kwargs):\n    \"\"\"Plot a line from slope and intercept\"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    x_vals = np.array(ax.get_xlim())\n    y_vals = intercept + slope * x_vals\n    ax.plot(x_vals, y_vals, **kwargs)\n\n\ndef plot_lines(ax: plt.Axes, samples: np.ndarray, label: str, color: str, alpha: float):\n    for i, betas in enumerate(samples):\n        label = label if i == 0 else None\n        plot_abline(betas[0], betas[1], ax=ax, color=color, alpha=alpha, label=label)\n\n\nfig, ax = plt.subplots()\nax.set_xlim(-x_lim, x_lim)\nax.set_ylim(y.min(), y.max())\n\nax.scatter(x, y, label=\"data\")\n\nplot_lines(\n    ax=ax,\n    samples=prior.sample_beta(size=100, random_state=rng),\n    label=\"prior\",\n    color=\"blue\",\n    alpha=0.05,\n)\nplot_lines(\n    ax=ax,\n    samples=posterior.sample_beta(size=100, random_state=rng),\n    label=\"posterior\",\n    color=\"black\",\n    alpha=0.2,\n)\n\nplot_abline(intercept, slope, ax=ax, label=\"true\", color=\"red\")\n\nax.set(xlabel=\"x\", ylabel=\"y\", title=\"Linear regression with conjugate prior\")\n\n# New Data\nax.plot(x_new, pp.mu, color=\"green\", label=\"posterior predictive mean\")\ndf_quantile = df_samples.T.quantile([0.025, 0.975]).T\nax.fill_between(\n    x_new,\n    df_quantile[0.025],\n    df_quantile[0.975],\n    alpha=0.2,\n    color=\"green\",\n    label=\"95% posterior predictive interval\",\n)\nax.legend()\nax.set(xlim=(-x_lim_new, x_lim_new))\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/plotting/","title":"Plotting Distributions","text":"<p>All the distributions can be plotted using the <code>plot_pdf</code> and <code>plot_pmf</code> methods. The <code>plot_pdf</code> method is used for continuous distributions and the <code>plot_pmf</code> method is used for discrete distributions.</p> <p>Similarly, all distributions have a <code>plot_cdf</code> method for plotting the cumulative distribution function.   </p> <p>There is limited support for some distributions like the <code>Dirichlet</code> or those without a <code>dist</code> scipy.</p> <pre><code>from conjugate.distributions import Beta, Gamma, Normal\n\nimport matplotlib.pyplot as plt\n\nbeta = Beta(1, 1)\ngamma = Gamma(1, 1)\nnormal = Normal(0, 1)\n\nbound = 3\n\ndists = [beta, gamma, normal]\nlabels = [\"beta\", \"gamma\", \"normal\"]\n\nax = plt.gca()\nfor label, dist in zip(labels, dists):\n    dist.set_bounds(-bound, bound).plot_pdf(label=label)\n\nax.legend()\n</code></pre> <p></p> <p>Switch out <code>plot_pdf</code> for <code>plot_cdf</code> to plot the cumulative distribution function:</p> <pre><code>ax = plt.gca()\nfor label, dist in zip(labels, dists):\n    dist.set_bounds(-bound, bound).plot_cdf(label=label)\n\nax.legend()\n</code></pre> <p></p> <p>The plotting is also supported for vectorized inputs.</p>"},{"location":"examples/sampling-distributions/","title":"Sampling from Distributions","text":"<p>Use the <code>rvs</code> method of the scipy distribution stored in <code>dist</code> attribute</p> <pre><code>distribution.dist.rvs(...)\n</code></pre>"},{"location":"examples/sampling-distributions/#scalar-parameters","title":"Scalar parameters","text":"<p>If the parameters are scalars, then just pass the number of samples to the <code>rvs</code> method!</p> <pre><code>from conjugate.distributions import Exponential\n\nlam = 3.5\ntrue_distribution = Exponential(lam=lam)\n\nn_samples = 10\nsamples = true_distribution.dist.rvs(n_samples)\n</code></pre>"},{"location":"examples/sampling-distributions/#vector-parameter","title":"Vector parameter","text":"<p>If the parameter is a vector, then there will be a broadcast issue from the scipy  distribution.</p> <pre><code>import numpy as np\n\nlam = np.array([\n    [1, 2], \n    [0.5, 5], \n])\n\ntrue_distribution = Exponential(lam=lam)\n\nn_samples = 100\ntry: \n    true_distribution.dist.rvs(n_samples)\nexcept ValueError: \n    print(\"The number of samples doesn't broadcast with the shape of parameters!\")\n</code></pre> <p>However, this is easy to fix by prepending the number of samples to the shape of  the model parameter shape</p> <pre><code>size = (n_samples, *lam.shape)\nsamples = true_distribution.dist.rvs(size=size, random_state=rng)\n</code></pre>"},{"location":"examples/sampling-distributions/#vector-parameters","title":"Vector parameters","text":"<p>If there are many parameters in your model, then use the <code>np.broadcast_shapes</code>  function in order to get the correct shape before sampling </p> <pre><code>from conjugate.distributions import Normal\n\nmu = np.array([1, 2, 3])\nsigma = np.array([2.5, 5])[:, None]\n\ntrue_distribution = Normal(mu=mu, sigma=sigma)\n\nshape = np.broadcast_shapes(mu.shape, sigma.shape)\nsize = (n_samples, *shape)\nsamples = true_distribution.dist.rvs(size=size, random_state=rng)\n</code></pre>"},{"location":"examples/scaling-distributions/","title":"Scaling Distributions","text":"<p>Some of the distributions can be scaled by a constant factor or added together. For instance, operations with Poisson distribution represent the number of events in a given time interval. </p> <pre><code>from conjugate.distributions import Poisson\n\nimport matplotlib.pyplot as plt\n\ndaily_rate = 0.25\ndaily_pois = Poisson(lam=daily_rate)\n\ntwo_day_pois = daily_pois + daily_pois\nweekly_pois = 7 * daily_pois\n\nmax_value = 7\nax = plt.gca()\ndists = [daily_pois, two_day_pois, weekly_pois]\nbase_labels = [\"daily\", \"two day\", \"weekly\"]\nfor dist, base_label in zip(dists, base_labels):\n    label = f\"{base_label} rate={dist.lam}\"\n    dist.set_max_value(max_value).plot_pmf(ax=ax, label=label)\n\nax.legend()\nplt.show()\n</code></pre> <p></p> <p>The normal distribution also supports scaling making use of the fact that the variance of a scaled normal distribution is the square of the scaling factor. </p> <pre><code>from conjugate.distributions import Normal\n\nimport matplotlib.pyplot as plt\n\nnorm = Normal(mu=0, sigma=1)\nnorm_times_2 = norm * 2\n\nbound = 6\nax = norm.set_bounds(-bound, bound).plot_pdf(label=f\"normal (std = {norm.sigma:.2f})\")\nnorm_times_2.set_bounds(-bound, bound).plot_pdf(ax=ax, label=f\"normal * 2 (std = {norm_times_2.sigma:.2f})\")\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/scipy-connection/","title":"Connection to SciPy Distributions","text":"<p>Many distributions have the <code>dist</code> attribute which is a scipy.stats distribution object. From there, the methods from scipy.stats to get the pdf, cdf, etc can be leveraged.</p> <pre><code>from conjugate.distribution import Beta \n\nbeta = Beta(1, 1)\nscipy_dist = beta.dist \n\nprint(scipy_dist.mean())\n# 0.5\nprint(scipy_dist.ppf([0.025, 0.975]))\n# [0.025 0.975]\n\nsamples = scipy_dist.rvs(100)\n</code></pre>"},{"location":"examples/sql/","title":"Bayesian Models with SQL","text":"<p>Because <code>conjugate-models</code> works with general numerical inputs, we can use Bayesian models in SQL with the SQL builder, <code>PyPika</code>.</p> <p>For the example, we will estimate use normal model to estimate the  total sales amount by group. </p> <p>The example table is called <code>events</code> and we will assume a normal model for the  column <code>sales</code> for each value of the column <code>group</code>.</p> <p>We can create the sufficient statistics needed for <code>normal_normal_inverse_gamma</code> directly with the SQL builder.</p> <pre><code>from pypika import Query, Table, functions as fn\n\nevent_table = Table(\"events\")\n\nsales = event_table.sales\nsales_squared = sales**2\n\n# Sufficient statistics\nx_total = fn.Sum(sales)\nx2_total = fn.Sum(sales_squared)\nn = fn.Count(\"*\")\n\n# Start a query for a groupby\nquery = (\n    Query.from_(event_table)\n    .groupby(event_table.group)\n    .select(\n        event_table.group,\n    )\n)\n</code></pre> <p>Perform the Bayesian inference as usual, but using the variables reflecting the columns. </p> <pre><code>from conjugate.distributions import NormalInverseGamma\nfrom conjugate.models import (\n    normal,\n    normal_predictive,\n)\n\n# Bayesian Inference\nprior = NormalInverseGamma(mu=0, nu=1 / 10, alpha=1 / 10, beta=1)\nposterior = normal(\n    x_total=x_total,\n    x2_total=x2_total,\n    n=n,\n    prior=prior,\n)\nposterior_predictive = normal_predictive(distribution=posterior)\n</code></pre> <p>Then add the columns we want from the inference</p> <pre><code># Add the posterior predictive estimate\nquery = query.select(\n    posterior_predictive.mu.as_(\"mu\"),\n    posterior_predictive.sigma.as_(\"sigma\"),\n    posterior_predictive.nu.as_(\"nu\"),\n)\n</code></pre> <p>Which results in this query: </p> <pre><code>SELECT \"group\",\n       (0.0+COUNT(*)*SUM(\"sales\")/COUNT(*))/(0.1+COUNT(*)) \"mu\",\n       POW((1+0.5*(0.0+SUM(POW(\"sales\", 2))-POW((0.0+COUNT(*)*SUM(\"sales\")/COUNT(*))/(0.1+COUNT(*)), 2)*(0.1+COUNT(*))))*(0.1+COUNT(*)+1)/((0.1+COUNT(*))*(0.1+COUNT(*)/2)), 0.5) \"sigma\",\n       2*(0.1+COUNT(*)/2) \"nu\"\nFROM \"events\"\nGROUP BY \"group\"\n</code></pre>"},{"location":"examples/thompson/","title":"Thompson Sampling","text":"<p>Thompson sampling is a way to choose action in exploration-exploitation problems which makes use of posterior distributions for the variable of interest.</p>"},{"location":"examples/thompson/#minimize-waiting-time","title":"Minimize Waiting Time","text":"<p>We will assume an exponential distribution wait time for each group with an unknown average wait time for each group. </p> <p>The conjugate prior of the exponential distribution is a gamma distribution.</p> <p>The goal is to find the group with the minimum wait time.</p> <pre><code>from conjugate.distributions import Gamma, Exponential\nfrom conjugate.models import exponential_gamma\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nlam = np.array([0.5, 0.55, 0.6, 0.8, 1])\nn_groups = len(lam)\n\ntrue_dist = Exponential(lam=lam)\n</code></pre> <p>We will create some helper functions to abstract: </p> <ul> <li>sampling from the true distribution of a group</li> <li>create the statistics required for Bayesian update of exponential gamma model</li> <li>single step in the Thompson sampling process</li> </ul> <pre><code>def sample_true_distribution(\n    group_to_sample: int, \n    rng, \n    true_dist: Exponential = true_dist,\n) -&gt; float:\n    return true_dist[group_to_sample].dist.rvs(random_state=rng)\n\n\ndef bayesian_update_stats(\n    group_sampled: int, \n    group_sample: float, \n    n_groups: int = n_groups,\n) -&gt; tuple[np.ndarray, np.ndarray]: \n    x = np.zeros(n_groups)\n    n = np.zeros(n_groups)\n\n    x[group_sampled] = group_sample\n    n[group_sampled] = 1\n\n    return x, n\n\n\ndef thompson_step(estimate: Gamma, rng) -&gt; Gamma: \n    sample = estimate.dist.rvs(random_state=rng)\n\n    group_to_sample = np.argmin(sample)\n\n    group_sample = sample_true_distribution(group_to_sample, rng=rng)\n    x, n = bayesian_update_stats(group_to_sample, group_sample)\n\n    return exponential_gamma(x, n, prior=estimate)\n</code></pre> <p>After defining a prior / initial estimate for each of the distributions, we can use a for loop in order to perform the Thompson sampling and progressively update this estimate.</p> <pre><code>alpha = beta = np.ones(n_groups)\nestimate = Gamma(alpha, beta)\n\nrng = np.random.default_rng(42)\n\ntotal_samples = 250\nfor _ in range(total_samples): \n    estimate = thompson_step(estimate=estimate, rng=rng)\n</code></pre> <p>We can see that the group with the lowest wait time was actually exploited the most!</p> <pre><code>fig, axes = plt.subplots(ncols=2)\nfig.suptitle(\"Thompson Sampling using conjugate-models\")\n\nax = axes[0]\nestimate.set_max_value(2).plot_pdf(label=lam, ax=ax)\nax.legend(title=\"True Mean\")\nax.set(\n    xlabel=\"Mean Wait Time\", \n    title=\"Posterior Distribution by Group\",\n)\n\nax = axes[1]\nn_times_sampled = estimate.beta - 1\nax.scatter(lam, n_times_sampled / total_samples)\nax.set(\n    xlabel=\"True Mean Wait Time\", \n    ylabel=\"% of times sampled\", \n    ylim=(0, None),\n    title=\"Exploitation of Best Group\", \n)\n# Format yaxis as percentage\nax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.0%}\"))\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/unsupported-distributions/","title":"Unsupported Posterior Predictive Distributions","text":"<p>Suppose we want to use the geometric model with a beta prior which doesn't have a  supported distribution for the posterior predictive. </p> <pre><code>from conjugate.distributions import Beta\nfrom conjugate.models import geometric_beta\n\nprior = Beta(1, 1)\nposterior: Beta = geometric_beta(x_total=12, n=10, prior=prior)\n</code></pre> <p>We can get posterior predictive samples by: </p> <ol> <li>Sample from the posterior distribution</li> <li>Sample from the model distribution using posterior samples</li> </ol>"},{"location":"examples/unsupported-distributions/#1-using-conjugate-models","title":"1. Using <code>conjugate-models</code>","text":"<p>This is easy to do with this package. </p> <p>Since the distributions are vectorized, just: </p> <ol> <li>Get the number of samples from the posterior </li> <li>Take a single sample from the model distribution</li> </ol> <pre><code>from conjugate.distributions import Geometric\n\nn_samples = 1_000\nposterior_samples = posterior.dist.rvs(size=n_samples)\nposterior_predictive_samples = Geometric(p=posterior_samples).dist.rvs()\n</code></pre>"},{"location":"examples/unsupported-distributions/#2-using-pymc","title":"2. Using <code>pymc</code>","text":"<p>Another route would be using PyMC then use the <code>draw</code> function. </p> <pre><code>import pymc as pm\n\nposterior_dist = pm.Beta.dist(alpha=posterior.alpha, beta=posterior.beta)\ngeometric_posterior_predictive = pm.Geometric.dist(posterior_dist)\n\nn_samples = 1_000\nposterior_predictive_samples = pm.draw(geometric_posterior_predictive, draws=n_samples)\n</code></pre>"},{"location":"examples/vectorized-inputs/","title":"Vectorized Inputs","text":"<p>All data and priors will allow for vectorized assuming the shapes work for broadcasting. </p> <p>The plotting also supports arrays of results</p> <pre><code>import numpy as np\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta\n\nimport matplotlib.pyplot as plt\n\n# Data\nN = 10\nx = 4\n\n# Analytics \nprior = Beta(alpha=1, beta=np.array([1, 10]))\nposterior = binomial_beta(n=N, x=x, prior=prior)\n\n# Figure\ncolors = [\"blue\", \"red\"]\nax = prior.plot_pdf(label=lambda i: f\"prior {i}\", color=colors, linestyle=\"--\")\nposterior.plot_pdf(ax=ax, label=lambda i: f\"posterior {i}\", color=colors)\nax.axvline(x=x / N, ymax=0.05, color=\"black\", linestyle=\"--\", label=\"MLE\")\nax.legend()\nplt.show()\n</code></pre> <p></p>"}]}