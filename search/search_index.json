{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Conjugate Models","text":"<p>Bayesian conjugate models in Python</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install conjugate-models\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Connection to Scipy Distributions with <code>dist</code> attribute</li> <li>Built in Plotting with <code>plot_pdf</code> and <code>plot_pmf</code> methods</li> <li>Vectorized Operations for parameters and data</li> <li>Indexing Parameters for subsetting and slicing</li> <li>Generalized Numerical Inputs for inputs other than builtins and numpy arrays</li> <li>Unsupported Distributions for sampling from unsupported distributions</li> </ul>"},{"location":"#supported-models","title":"Supported Models","text":"<p>Many likelihoods are supported including</p> <ul> <li><code>Bernoulli</code> / <code>Binomial</code></li> <li><code>Categorical</code> / <code>Multinomial</code></li> <li><code>Poisson</code></li> <li><code>Normal</code> (including linear regression)</li> <li>and many more</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":"<ol> <li>Define prior distribution from <code>distributions</code> module</li> <li>Pass data and prior into model from <code>models</code> modules</li> <li>Analytics with posterior and posterior predictive distributions</li> </ol> <pre><code>from conjugate.distributions import Beta, BetaBinomial\nfrom conjugate.models import binomial_beta, binomial_beta_posterior_predictive\n\n# Observed Data\nX = 4\nN = 10\n\n# Analytics\nprior = Beta(1, 1)\nprior_predictive: BetaBinomial = binomial_beta_posterior_predictive(n=N, beta=prior)\n\nposterior: Beta = binomial_beta(n=N, x=X, beta_prior=prior)\nposterior_predictive: BetaBinomial = binomial_beta_posterior_predictive(n=N, beta=posterior) \n\n# Figure\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(ncols=2)\n\nax = axes[0]\nax = posterior.plot_pdf(ax=ax, label=\"posterior\")\nprior.plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x=X/N, color=\"black\", ymax=0.05, label=\"MLE\")\nax.set_title(\"Success Rate\")\nax.legend()\n\nax = axes[1]\nposterior_predictive.plot_pmf(ax=ax, label=\"posterior predictive\")\nprior_predictive.plot_pmf(ax=ax, label=\"prior predictive\")\nax.axvline(x=X, color=\"black\", ymax=0.05, label=\"Sample\")\nax.set_title(\"Number of Successes\")\nax.legend()\nplt.show()\n</code></pre>"},{"location":"#too-simple","title":"Too Simple?","text":"<p>Simple model, sure. Useful model, potentially.</p> <p>Constant probability of success, <code>p</code>, for <code>n</code> trials.</p> <pre><code>rng = np.random.default_rng(42)\n\n# Observed Data\nn_times = 75\np = np.repeat(0.5, n_times)\nsamples = rng.binomial(n=1, p=p, size=n_times)\n\n# Model\nn = np.arange(n_times) + 1\nprior = Beta(alpha=1, beta=1)\nposterior = binomial_beta(n=n, x=samples.cumsum(), beta_prior=prior)\n\n# Figure\nplt.plot(n, p, color=\"black\", label=\"true p\", linestyle=\"--\")\nplt.scatter(n, samples, color=\"black\", label=\"observed samples\")\nplt.plot(n, posterior.dist.mean(), color=\"red\", label=\"posterior mean\")\n# fill between the 95% credible interval\nplt.fill_between(\n    n, \n    posterior.dist.ppf(0.025),\n    posterior.dist.ppf(0.975),\n    color=\"red\",\n    alpha=0.2,\n    label=\"95% credible interval\",\n)\npadding = 0.025\nplt.ylim(0 - padding, 1 + padding)\nplt.xlim(1, n_times)\nplt.legend(loc=\"best\")\nplt.xlabel(\"Number of trials\")\nplt.ylabel(\"Probability\")\nplt.show()\n</code></pre> <p></p> <p>Even with a moving probability, this simple to implement model can be useful.</p> <pre><code>...\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\np_raw = rng.normal(loc=0, scale=0.2, size=n_times).cumsum()\np = sigmoid(p_raw)\n\n...\n</code></pre> <p></p>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Conjugate Priors</li> </ul>"},{"location":"distributions/","title":"Distributions","text":"<p>These are the supported distributions based on the conjugate models.</p> <p>Many have the <code>dist</code> attribute which is a scipy.stats distribution object. From there,  you can use the methods from scipy.stats to get the pdf, cdf, etc.</p> <p>Distributions can be plotted using the <code>plot_pmf</code> or <code>plot_pdf</code> methods of the distribution.</p> <pre><code>from conjugate.distribution import Beta \n\nbeta = Beta(1, 1)\nscipy_dist = beta.dist \n\nprint(scipy_dist.mean())\n# 0.5\nprint(scipy_dist.ppf([0.025, 0.975]))\n# [0.025 0.975]\n\nsamples = scipy_dist.rvs(100)\n\nbeta.plot_pmf(label=\"beta distribution\")\n</code></pre> <p>Distributions like Poisson can be added with other Poissons or multiplied by numerical values in order to scale rate. For instance, </p> <pre><code>daily_rate = 0.25\ndaily_pois = Poisson(lam=daily_rate)\n\ntwo_day_pois = daily_pois + daily_pois\nweekly_pois = 7 * daily_pois\n</code></pre> <p>Below are the currently supported distributions</p>"},{"location":"distributions/#conjugate.distributions.Beta","title":"<code>Beta</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Beta distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Beta(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Beta distribution.\n\n    Args:\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        self.max_value = 1.0\n\n    @classmethod\n    def from_mean(cls, mean: NUMERIC, alpha: NUMERIC) -&gt; \"Beta\":\n        \"\"\"Alternative constructor from mean and alpha.\"\"\"\n        beta = get_beta_param_from_mean_and_alpha(mean=mean, alpha=alpha)\n        return cls(alpha=alpha, beta=beta)\n\n    @classmethod\n    def from_successes_and_failures(\n        cls, successes: NUMERIC, failures: NUMERIC\n    ) -&gt; \"Beta\":\n        \"\"\"Alternative constructor based on hyperparameter interpretation.\"\"\"\n        alpha = successes + 1\n        beta = failures + 1\n        return cls(alpha=alpha, beta=beta)\n\n    @property\n    def dist(self):\n        return stats.beta(self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Beta.from_mean","title":"<code>from_mean(mean, alpha)</code>  <code>classmethod</code>","text":"<p>Alternative constructor from mean and alpha.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_mean(cls, mean: NUMERIC, alpha: NUMERIC) -&gt; \"Beta\":\n    \"\"\"Alternative constructor from mean and alpha.\"\"\"\n    beta = get_beta_param_from_mean_and_alpha(mean=mean, alpha=alpha)\n    return cls(alpha=alpha, beta=beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Beta.from_successes_and_failures","title":"<code>from_successes_and_failures(successes, failures)</code>  <code>classmethod</code>","text":"<p>Alternative constructor based on hyperparameter interpretation.</p> Source code in <code>conjugate/distributions.py</code> <pre><code>@classmethod\ndef from_successes_and_failures(\n    cls, successes: NUMERIC, failures: NUMERIC\n) -&gt; \"Beta\":\n    \"\"\"Alternative constructor based on hyperparameter interpretation.\"\"\"\n    alpha = successes + 1\n    beta = failures + 1\n    return cls(alpha=alpha, beta=beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaBinomial","title":"<code>BetaBinomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Beta binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Beta binomial distribution.\n\n    Args:\n        n: number of trials\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    n: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        return stats.betabinom(self.n, self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.BetaNegativeBinomial","title":"<code>BetaNegativeBinomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Beta negative binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of successes</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass BetaNegativeBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Beta negative binomial distribution.\n\n    Args:\n        n: number of successes\n        alpha: shape parameter\n        beta: shape parameter\n\n    \"\"\"\n\n    n: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        if version.parse(scipy_version).release &lt; version.parse(\"1.12.0\").release:\n            msg = \"BetaNegativeBinomial.dist requires scipy &gt;= 1.12.0\"\n            raise NotImplementedError(msg)\n\n        return stats.betanbinom(self.n, self.alpha, self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Binomial","title":"<code>Binomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Binomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Binomial distribution.\n\n    Args:\n        n: number of trials\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    def __post_init__(self):\n        if isinstance(self.n, np.ndarray):\n            self.max_value = self.n.max()\n        else:\n            self.max_value = self.n\n\n    @property\n    def dist(self):\n        return stats.binom(n=self.n, p=self.p)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Dirichlet","title":"<code>Dirichlet</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DirichletPlotDistMixin</code></p> <p>Dirichlet distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Dirichlet(DirichletPlotDistMixin):\n    \"\"\"Dirichlet distribution.\n\n    Args:\n        alpha: shape parameter\n\n    \"\"\"\n\n    alpha: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        self.max_value = 1.0\n\n    @property\n    def dist(self):\n        if self.alpha.ndim == 1:\n            return stats.dirichlet(self.alpha)\n\n        return VectorizedDist(self.alpha, dist=stats.dirichlet)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.DirichletMultinomial","title":"<code>DirichletMultinomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>SliceMixin</code></p> <p>Dirichlet multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass DirichletMultinomial(SliceMixin):\n    \"\"\"Dirichlet multinomial distribution.\n\n    Args:\n        alpha: shape parameter\n        n: number of trials\n\n    \"\"\"\n\n    alpha: NUMERIC\n    n: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.dirichlet_multinomial(self.alpha, self.n)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Exponential","title":"<code>Exponential</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>lam</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Exponential(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Exponential distribution.\n\n    Args:\n        lam: rate parameter\n\n    \"\"\"\n\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.expon(scale=self.lam)\n\n    def __mul__(self, other):\n        return Gamma(alpha=other, beta=1 / self.lam)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Gamma","title":"<code>Gamma</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Gamma distribution.</p> <p>Gamma Distribution Scipy Docmentation</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape parameter</p> required <code>beta</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Gamma(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Gamma distribution.\n\n    &lt;a href=https://en.wikipedia.org/wiki/Gamma_distribution&gt;Gamma Distribution&lt;/a&gt;\n    &lt;a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html&gt;Scipy Docmentation&lt;/a&gt;\n\n    Args:\n        alpha: shape parameter\n        beta: rate parameter\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.gamma(a=self.alpha, scale=1 / self.beta)\n\n    def __mul__(self, other):\n        return Gamma(alpha=self.alpha * other, beta=self.beta)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Geometric","title":"<code>Geometric</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Geometric distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Geometric(DiscretePlotMixin, SliceMixin):\n    \"\"\"Geometric distribution.\n\n    Args:\n        p: probability of success\n\n    \"\"\"\n\n    p: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.geom(self.p)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Hypergeometric","title":"<code>Hypergeometric</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Hypergeometric distribution.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>NUMERIC</code> <p>population size</p> required <code>k</code> <code>NUMERIC</code> <p>number of successes in the population</p> required <code>n</code> <code>NUMERIC</code> <p>number of draws</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Hypergeometric(DiscretePlotMixin, SliceMixin):\n    \"\"\"Hypergeometric distribution.\n\n    Args:\n        N: population size\n        k: number of successes in the population\n        n: number of draws\n\n    \"\"\"\n\n    N: NUMERIC\n    k: NUMERIC\n    n: NUMERIC\n\n    def __post_init__(self) -&gt; None:\n        if isinstance(self.N, np.ndarray):\n            self.max_value = self.N.max()\n        else:\n            self.max_value = self.N\n\n    @property\n    def dist(self):\n        return stats.hypergeom(self.N, self.k, self.n)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.InverseGamma","title":"<code>InverseGamma</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>InverseGamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass InverseGamma(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"InverseGamma distribution.\n\n    Args:\n        alpha: shape\n        beta: scale\n\n    \"\"\"\n\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.invgamma(a=self.alpha, scale=self.beta)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Lomax","title":"<code>Lomax</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Lomax distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>lam</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Lomax(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Lomax distribution.\n\n    Args:\n        alpha: shape\n        lam: scale\n\n    \"\"\"\n\n    alpha: NUMERIC\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.lomax(c=self.alpha, scale=self.lam)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Multinomial","title":"<code>Multinomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>SliceMixin</code></p> <p>Multinomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Multinomial(SliceMixin):\n    \"\"\"Multinomial distribution.\n\n    Args:\n        n: number of trials\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.multinomial(n=self.n, p=self.p)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.MultivariateStudentT","title":"<code>MultivariateStudentT</code>  <code>dataclass</code>","text":"<p>MultivariateStudentT distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>covariance matrix</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass MultivariateStudentT:\n    \"\"\"MultivariateStudentT distribution.\n\n    Args:\n        mu: mean\n        sigma: covariance matrix\n        nu: degrees of freedom\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n    nu: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.multivariate_t(loc=self.mu, shape=self.sigma, df=self.nu)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NegativeBinomial","title":"<code>NegativeBinomial</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Negative binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of successes</p> required <code>p</code> <code>NUMERIC</code> <p>probability of success</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NegativeBinomial(DiscretePlotMixin, SliceMixin):\n    \"\"\"Negative binomial distribution.\n\n    Args:\n        n: number of successes\n        p: probability of success\n\n    \"\"\"\n\n    n: NUMERIC\n    p: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.nbinom(n=self.n, p=self.p)\n\n    def __mul__(self, other):\n        return NegativeBinomial(n=self.n * other, p=self.p)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Normal","title":"<code>Normal</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>standard deviation</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Normal(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Normal distribution.\n\n    Args:\n        mu: mean\n        sigma: standard deviation\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.norm(self.mu, self.sigma)\n\n    def __mul__(self, other):\n        sigma = ((self.sigma**2) * other) ** 0.5\n        return Normal(mu=self.mu * other, sigma=sigma)\n\n    __rmul__ = __mul__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma","title":"<code>NormalInverseGamma</code>  <code>dataclass</code>","text":"<p>Normal inverse gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>delta_inverse</code> <code>NUMERIC</code> <p>covariance matrix</p> required <code>alpha</code> <code>NUMERIC</code> <p>shape</p> required <code>beta</code> <code>NUMERIC</code> <p>scale</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass NormalInverseGamma:\n    \"\"\"Normal inverse gamma distribution.\n\n    Args:\n        mu: mean\n        delta_inverse: covariance matrix\n        alpha: shape\n        beta: scale\n\n    \"\"\"\n\n    mu: NUMERIC\n    delta_inverse: NUMERIC\n    alpha: NUMERIC\n    beta: NUMERIC\n\n    @classmethod\n    def from_inverse_gamma(\n        cls, mu: NUMERIC, delta_inverse: NUMERIC, inverse_gamma: InverseGamma\n    ) -&gt; \"NormalInverseGamma\":\n        return cls(\n            mu=mu,\n            delta_inverse=delta_inverse,\n            alpha=inverse_gamma.alpha,\n            beta=inverse_gamma.beta,\n        )\n\n    @property\n    def inverse_gamma(self) -&gt; InverseGamma:\n        return InverseGamma(alpha=self.alpha, beta=self.beta)\n\n    def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n        \"\"\"Sample variance from the inverse gamma distribution.\n\n        Args:\n            size: number of samples\n            random_state: random state\n\n        Returns:\n            samples from the inverse gamma distribution\n\n        \"\"\"\n        return self.inverse_gamma.dist.rvs(size=size, random_state=random_state)\n\n    def sample_beta(\n        self, size: int, return_variance: bool = False, random_state=None\n    ) -&gt; Union[NUMERIC, Tuple[NUMERIC, NUMERIC]]:\n        \"\"\"Sample beta from the normal distribution.\n\n        Args:\n            size: number of samples\n            return_variance: whether to return variance as well\n            random_state: random state\n\n        Returns:\n            samples from the normal distribution and optionally variance\n\n        \"\"\"\n        variance = self.sample_variance(size=size, random_state=random_state)\n\n        beta = np.stack(\n            [\n                stats.multivariate_normal(self.mu, v * self.delta_inverse).rvs(\n                    size=1, random_state=random_state\n                )\n                for v in variance\n            ]\n        )\n\n        if return_variance:\n            return beta, variance\n\n        return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma.sample_beta","title":"<code>sample_beta(size, return_variance=False, random_state=None)</code>","text":"<p>Sample beta from the normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>return_variance</code> <code>bool</code> <p>whether to return variance as well</p> <code>False</code> <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[NUMERIC, Tuple[NUMERIC, NUMERIC]]</code> <p>samples from the normal distribution and optionally variance</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_beta(\n    self, size: int, return_variance: bool = False, random_state=None\n) -&gt; Union[NUMERIC, Tuple[NUMERIC, NUMERIC]]:\n    \"\"\"Sample beta from the normal distribution.\n\n    Args:\n        size: number of samples\n        return_variance: whether to return variance as well\n        random_state: random state\n\n    Returns:\n        samples from the normal distribution and optionally variance\n\n    \"\"\"\n    variance = self.sample_variance(size=size, random_state=random_state)\n\n    beta = np.stack(\n        [\n            stats.multivariate_normal(self.mu, v * self.delta_inverse).rvs(\n                size=1, random_state=random_state\n            )\n            for v in variance\n        ]\n    )\n\n    if return_variance:\n        return beta, variance\n\n    return beta\n</code></pre>"},{"location":"distributions/#conjugate.distributions.NormalInverseGamma.sample_variance","title":"<code>sample_variance(size, random_state=None)</code>","text":"<p>Sample variance from the inverse gamma distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>number of samples</p> required <code>random_state</code> <p>random state</p> <code>None</code> <p>Returns:</p> Type Description <code>NUMERIC</code> <p>samples from the inverse gamma distribution</p> Source code in <code>conjugate/distributions.py</code> <pre><code>def sample_variance(self, size: int, random_state=None) -&gt; NUMERIC:\n    \"\"\"Sample variance from the inverse gamma distribution.\n\n    Args:\n        size: number of samples\n        random_state: random state\n\n    Returns:\n        samples from the inverse gamma distribution\n\n    \"\"\"\n    return self.inverse_gamma.dist.rvs(size=size, random_state=random_state)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Pareto","title":"<code>Pareto</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Pareto distribution.</p> <p>Parameters:</p> Name Type Description Default <code>x_m</code> <code>NUMERIC</code> <p>minimum value</p> required <code>alpha</code> <code>NUMERIC</code> <p>scale parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Pareto(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Pareto distribution.\n\n    Args:\n        x_m: minimum value\n        alpha: scale parameter\n\n    \"\"\"\n\n    x_m: NUMERIC\n    alpha: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.pareto(self.alpha, scale=self.x_m)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Poisson","title":"<code>Poisson</code>  <code>dataclass</code>","text":"<p>             Bases: <code>DiscretePlotMixin</code>, <code>SliceMixin</code></p> <p>Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>lam</code> <code>NUMERIC</code> <p>rate parameter</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Poisson(DiscretePlotMixin, SliceMixin):\n    \"\"\"Poisson distribution.\n\n    Args:\n        lam: rate parameter\n\n    \"\"\"\n\n    lam: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.poisson(self.lam)\n\n    def __mul__(self, other) -&gt; \"Poisson\":\n        return Poisson(lam=self.lam * other)\n\n    __rmul__ = __mul__\n\n    def __add__(self, other) -&gt; \"Poisson\":\n        return Poisson(self.lam + other.lam)\n\n    __radd__ = __add__\n</code></pre>"},{"location":"distributions/#conjugate.distributions.StudentT","title":"<code>StudentT</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>StudentT distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>mean</p> required <code>sigma</code> <code>NUMERIC</code> <p>standard deviation</p> required <code>nu</code> <code>NUMERIC</code> <p>degrees of freedom</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass StudentT(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"StudentT distribution.\n\n    Args:\n        mu: mean\n        sigma: standard deviation\n        nu: degrees of freedom\n\n    \"\"\"\n\n    mu: NUMERIC\n    sigma: NUMERIC\n    nu: NUMERIC\n\n    @property\n    def dist(self):\n        return stats.t(self.nu, self.mu, self.sigma)\n</code></pre>"},{"location":"distributions/#conjugate.distributions.Uniform","title":"<code>Uniform</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code>, <code>SliceMixin</code></p> <p>Uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>NUMERIC</code> <p>lower bound</p> required <code>high</code> <code>NUMERIC</code> <p>upper bound</p> required Source code in <code>conjugate/distributions.py</code> <pre><code>@dataclass\nclass Uniform(ContinuousPlotDistMixin, SliceMixin):\n    \"\"\"Uniform distribution.\n\n    Args:\n        low: lower bound\n        high: upper bound\n\n    \"\"\"\n\n    low: NUMERIC\n    high: NUMERIC\n\n    def __post_init__(self):\n        self.min_value = self.low\n        self.max_value = self.high\n\n    @property\n    def dist(self):\n        return stats.uniform(self.low, self.high)\n</code></pre>"},{"location":"mixins/","title":"Mixins","text":"<p>Two sets of mixins to support the plotting and slicing of the distribution parameters</p>"},{"location":"mixins/#conjugate.plot.ContinuousPlotDistMixin","title":"<code>ContinuousPlotDistMixin</code>","text":"<p>             Bases: <code>PlotDistMixin</code></p> <p>Functionality for plot_pdf method of continuous distributions.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class ContinuousPlotDistMixin(PlotDistMixin):\n    \"\"\"Functionality for plot_pdf method of continuous distributions.\"\"\"\n\n    def plot_pdf(self, ax: Optional[plt.Axes] = None, **kwargs) -&gt; plt.Axes:\n        \"\"\"Plot the pdf of distribution\n\n        Args:\n            ax: matplotlib Axes, optional\n            **kwargs: Additonal kwargs to pass to matplotlib\n\n        Returns:\n            new or modified Axes\n\n        \"\"\"\n        ax = self._settle_axis(ax=ax)\n\n        x = self._create_x_values()\n        x = self._reshape_x_values(x)\n\n        return self._create_plot_on_axis(x, ax, **kwargs)\n\n    def _create_x_values(self) -&gt; np.ndarray:\n        return np.linspace(self.min_value, self.max_value, 100)\n\n    def _setup_labels(self, ax) -&gt; None:\n        ax.set_xlabel(\"Domain\")\n        ax.set_ylabel(\"Density $f(x)$\")\n\n    def _create_plot_on_axis(self, x, ax, **kwargs) -&gt; plt.Axes:\n        yy = self.dist.pdf(x)\n        if \"label\" in kwargs:\n            label = kwargs.pop(\"label\")\n            label = resolve_label(label, yy)\n        else:\n            label = None\n\n        ax.plot(x, yy, label=label, **kwargs)\n        self._setup_labels(ax=ax)\n        ax.set_ylim(0, None)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.ContinuousPlotDistMixin.plot_pdf","title":"<code>plot_pdf(ax=None, **kwargs)</code>","text":"<p>Plot the pdf of distribution</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>matplotlib Axes, optional</p> <code>None</code> <code>**kwargs</code> <p>Additonal kwargs to pass to matplotlib</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>new or modified Axes</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_pdf(self, ax: Optional[plt.Axes] = None, **kwargs) -&gt; plt.Axes:\n    \"\"\"Plot the pdf of distribution\n\n    Args:\n        ax: matplotlib Axes, optional\n        **kwargs: Additonal kwargs to pass to matplotlib\n\n    Returns:\n        new or modified Axes\n\n    \"\"\"\n    ax = self._settle_axis(ax=ax)\n\n    x = self._create_x_values()\n    x = self._reshape_x_values(x)\n\n    return self._create_plot_on_axis(x, ax, **kwargs)\n</code></pre>"},{"location":"mixins/#conjugate.plot.DirichletPlotDistMixin","title":"<code>DirichletPlotDistMixin</code>","text":"<p>             Bases: <code>ContinuousPlotDistMixin</code></p> <p>Plot the pdf using samples from the dirichlet distribution.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class DirichletPlotDistMixin(ContinuousPlotDistMixin):\n    \"\"\"Plot the pdf using samples from the dirichlet distribution.\"\"\"\n\n    def plot_pdf(\n        self, ax: Optional[plt.Axes] = None, samples: int = 1_000, **kwargs\n    ) -&gt; plt.Axes:\n        \"\"\"Plots the pdf\"\"\"\n        distribution_samples = self.dist.rvs(size=samples)\n\n        ax = self._settle_axis(ax=ax)\n        xx = self._create_x_values()\n\n        for x in distribution_samples.T:\n            kde = gaussian_kde(x)\n\n            yy = kde(xx)\n\n            ax.plot(xx, yy, **kwargs)\n\n        self._setup_labels(ax=ax)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.DirichletPlotDistMixin.plot_pdf","title":"<code>plot_pdf(ax=None, samples=1000, **kwargs)</code>","text":"<p>Plots the pdf</p> Source code in <code>conjugate/plot.py</code> <pre><code>def plot_pdf(\n    self, ax: Optional[plt.Axes] = None, samples: int = 1_000, **kwargs\n) -&gt; plt.Axes:\n    \"\"\"Plots the pdf\"\"\"\n    distribution_samples = self.dist.rvs(size=samples)\n\n    ax = self._settle_axis(ax=ax)\n    xx = self._create_x_values()\n\n    for x in distribution_samples.T:\n        kde = gaussian_kde(x)\n\n        yy = kde(xx)\n\n        ax.plot(xx, yy, **kwargs)\n\n    self._setup_labels(ax=ax)\n    return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.DiscretePlotMixin","title":"<code>DiscretePlotMixin</code>","text":"<p>             Bases: <code>PlotDistMixin</code></p> <p>Adding the plot_pmf method to class.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class DiscretePlotMixin(PlotDistMixin):\n    \"\"\"Adding the plot_pmf method to class.\"\"\"\n\n    def plot_pmf(\n        self, ax: Optional[plt.Axes] = None, mark: str = \"o-\", **kwargs\n    ) -&gt; plt.Axes:\n        ax = self._settle_axis(ax=ax)\n\n        x = self._create_x_values()\n        x = self._reshape_x_values(x)\n\n        return self._create_plot_on_axis(x, ax, mark, **kwargs)\n\n    def _create_x_values(self) -&gt; np.ndarray:\n        return np.arange(self.min_value, self.max_value + 1, 1)\n\n    def _create_plot_on_axis(\n        self, x, ax, mark, conditional: bool = False, **kwargs\n    ) -&gt; plt.Axes:\n        yy = self.dist.pmf(x)\n        if conditional:\n            yy = yy / np.sum(yy)\n            ylabel = f\"Conditional Probability $f(x|{self.min_value} \\\\leq x \\\\leq {self.max_value})$\"\n        else:\n            ylabel = \"Probability $f(x)$\"\n\n        if \"label\" in kwargs:\n            label = kwargs.pop(\"label\")\n            label = resolve_label(label, yy)\n        else:\n            label = None\n\n        ax.plot(x, yy, mark, label=label, **kwargs)\n\n        if self.max_value - self.min_value &lt; 15:\n            ax.set_xticks(x.ravel())\n        else:\n            ax.set_xticks(x.ravel(), minor=True)\n            ax.set_xticks(x[::5].ravel())\n\n        ax.set_xlabel(\"Domain\")\n        ax.set_ylabel(ylabel)\n        ax.set_ylim(0, None)\n        return ax\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin","title":"<code>PlotDistMixin</code>","text":"<p>Base mixin in order to support plotting. Requires the dist attribute of the scipy distribution.</p> Source code in <code>conjugate/plot.py</code> <pre><code>class PlotDistMixin:\n    \"\"\"Base mixin in order to support plotting. Requires the dist attribute of the scipy distribution.\"\"\"\n\n    @property\n    def dist(self) -&gt; Distribution:\n        raise NotImplementedError(\"Implement this property in the subclass.\")\n\n    @property\n    def max_value(self) -&gt; float:\n        if not hasattr(self, \"_max_value\"):\n            raise ValueError(\"Set the max value before plotting.\")\n\n        return self._max_value\n\n    @max_value.setter\n    def max_value(self, value: float) -&gt; None:\n        self._max_value = value\n\n    def set_max_value(self, value: float) -&gt; \"PlotDistMixin\":\n        self.max_value = value\n\n        return self\n\n    @property\n    def min_value(self) -&gt; float:\n        if not hasattr(self, \"_min_value\"):\n            self._min_value = 0.0\n\n        return self._min_value\n\n    @min_value.setter\n    def min_value(self, value: float) -&gt; None:\n        self._min_value = value\n\n    def set_min_value(self, value: float) -&gt; \"PlotDistMixin\":\n        \"\"\"Set the minimum value for plotting.\"\"\"\n        self.min_value = value\n\n        return self\n\n    def set_bounds(self, lower: float, upper: float) -&gt; \"PlotDistMixin\":\n        \"\"\"Set both the min and max values for plotting.\"\"\"\n        return self.set_min_value(lower).set_max_value(upper)\n\n    def _reshape_x_values(self, x: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Make sure that the values are ready for plotting.\"\"\"\n        for value in asdict(self).values():\n            if not isinstance(value, float):\n                return x[:, None]\n\n        return x\n\n    def _settle_axis(self, ax: Optional[plt.Axes] = None) -&gt; plt.Axes:\n        return ax if ax is not None else plt.gca()\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin.set_bounds","title":"<code>set_bounds(lower, upper)</code>","text":"<p>Set both the min and max values for plotting.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def set_bounds(self, lower: float, upper: float) -&gt; \"PlotDistMixin\":\n    \"\"\"Set both the min and max values for plotting.\"\"\"\n    return self.set_min_value(lower).set_max_value(upper)\n</code></pre>"},{"location":"mixins/#conjugate.plot.PlotDistMixin.set_min_value","title":"<code>set_min_value(value)</code>","text":"<p>Set the minimum value for plotting.</p> Source code in <code>conjugate/plot.py</code> <pre><code>def set_min_value(self, value: float) -&gt; \"PlotDistMixin\":\n    \"\"\"Set the minimum value for plotting.\"\"\"\n    self.min_value = value\n\n    return self\n</code></pre>"},{"location":"mixins/#conjugate.plot.resolve_label","title":"<code>resolve_label(label, yy)</code>","text":"<p>https://stackoverflow.com/questions/73662931/matplotlib-plot-a-numpy-array-as-many-lines-with-a-single-label</p> Source code in <code>conjugate/plot.py</code> <pre><code>def resolve_label(label: LABEL_INPUT, yy: np.ndarray):\n    \"\"\"\n\n    https://stackoverflow.com/questions/73662931/matplotlib-plot-a-numpy-array-as-many-lines-with-a-single-label\n    \"\"\"\n    if yy.ndim == 1:\n        return label\n\n    ncols = yy.shape[1]\n    if ncols != 1:\n        if isinstance(label, str):\n            return [f\"{label} {i}\" for i in range(1, ncols + 1)]\n\n        if callable(label):\n            return [label(i) for i in range(ncols)]\n\n        if isinstance(label, Iterable):\n            return label\n\n        raise ValueError(\"Label must be a string, iterable, or callable.\")\n\n    return label\n</code></pre>"},{"location":"mixins/#conjugate.slice.SliceMixin","title":"<code>SliceMixin</code>","text":"<p>Mixin in order to slice the parameters</p> Source code in <code>conjugate/slice.py</code> <pre><code>class SliceMixin:\n    \"\"\"Mixin in order to slice the parameters\"\"\"\n\n    def __getitem__(self, key):\n        params = asdict(self)\n\n        def slice(value, key):\n            try:\n                return value[key]\n            except Exception:\n                return value\n\n        new_params = {k: slice(value=v, key=key) for k, v in params.items()}\n\n        return self.__class__(**new_params)\n</code></pre>"},{"location":"models/","title":"Models","text":"<p>For more on these models, check out the Conjugate Prior Wikipedia Table</p> <p>Below are the supported models</p>"},{"location":"models/#conjugate.models.bernoulli_beta","title":"<code>bernoulli_beta(x, beta_prior)</code>","text":"<p>Posterior distribution for a bernoulli likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>sucesses from that trials</p> required <code>beta_prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> Source code in <code>conjugate/models.py</code> <pre><code>def bernoulli_beta(x: NUMERIC, beta_prior: Beta) -&gt; Beta:\n    \"\"\"Posterior distribution for a bernoulli likelihood with a beta prior.\n\n    Args:\n        x: sucesses from that trials\n        beta_prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    \"\"\"\n    return binomial_beta(n=1, x=x, beta_prior=beta_prior)\n</code></pre>"},{"location":"models/#conjugate.models.bernoulli_beta_posterior_predictive","title":"<code>bernoulli_beta_posterior_predictive(beta)</code>","text":"<p>Posterior predictive distribution for a bernoulli likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>beta</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial posterior predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def bernoulli_beta_posterior_predictive(beta: Beta) -&gt; BetaBinomial:\n    \"\"\"Posterior predictive distribution for a bernoulli likelihood with a beta prior.\n\n    Args:\n        beta: Beta distribution\n\n    Returns:\n        BetaBinomial posterior predictive distribution\n\n    \"\"\"\n    return binomial_beta_posterior_predictive(n=1, beta=beta)\n</code></pre>"},{"location":"models/#conjugate.models.binomial_beta","title":"<code>binomial_beta(n, x, beta_prior)</code>","text":"<p>Posterior distribution for a binomial likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>total number of trials</p> required <code>x</code> <code>NUMERIC</code> <p>sucesses from that trials</p> required <code>beta_prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> Source code in <code>conjugate/models.py</code> <pre><code>def binomial_beta(n: NUMERIC, x: NUMERIC, beta_prior: Beta) -&gt; Beta:\n    \"\"\"Posterior distribution for a binomial likelihood with a beta prior.\n\n    Args:\n        n: total number of trials\n        x: sucesses from that trials\n        beta_prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    \"\"\"\n    alpha_post, beta_post = get_binomial_beta_posterior_params(\n        beta_prior.alpha, beta_prior.beta, n, x\n    )\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.binomial_beta_posterior_predictive","title":"<code>binomial_beta_posterior_predictive(n, beta)</code>","text":"<p>Posterior predictive distribution for a binomial likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>beta</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial posterior predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def binomial_beta_posterior_predictive(n: NUMERIC, beta: Beta) -&gt; BetaBinomial:\n    \"\"\"Posterior predictive distribution for a binomial likelihood with a beta prior.\n\n    Args:\n        n: number of trials\n        beta: Beta distribution\n\n    Returns:\n        BetaBinomial posterior predictive distribution\n\n    \"\"\"\n    return BetaBinomial(n=n, alpha=beta.alpha, beta=beta.beta)\n</code></pre>"},{"location":"models/#conjugate.models.categorical_dirichlet","title":"<code>categorical_dirichlet(x, dirichlet_prior)</code>","text":"<p>Posterior distribution of Categorical model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>counts</p> required <code>dirichlet_prior</code> <code>Dirichlet</code> <p>Dirichlet prior on the counts</p> required <p>Returns:</p> Type Description <code>Dirichlet</code> <p>Dirichlet posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def categorical_dirichlet(x: NUMERIC, dirichlet_prior: Dirichlet) -&gt; Dirichlet:\n    \"\"\"Posterior distribution of Categorical model with Dirichlet prior.\n\n    Args:\n        x: counts\n        dirichlet_prior: Dirichlet prior on the counts\n\n    Returns:\n        Dirichlet posterior distribution\n\n    \"\"\"\n    alpha_post = get_dirichlet_posterior_params(dirichlet_prior.alpha, x)\n\n    return Dirichlet(alpha=alpha_post)\n</code></pre>"},{"location":"models/#conjugate.models.categorical_dirichlet_posterior_predictive","title":"<code>categorical_dirichlet_posterior_predictive(dirichlet, n=1)</code>","text":"<p>Posterior predictive distribution of Categorical model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>dirichlet</code> <code>Dirichlet</code> <p>Dirichlet distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1.</p> <code>1</code> Source code in <code>conjugate/models.py</code> <pre><code>def categorical_dirichlet_posterior_predictive(\n    dirichlet: Dirichlet, n: NUMERIC = 1\n) -&gt; DirichletMultinomial:\n    \"\"\"Posterior predictive distribution of Categorical model with Dirichlet prior.\n\n    Args:\n        dirichlet: Dirichlet distribution\n        n: Number of trials for each sample, defaults to 1.\n\n    \"\"\"\n\n    return DirichletMultinomial(n=n, alpha=dirichlet.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.exponential_gamma","title":"<code>exponential_gamma(x_total, n, gamma_prior)</code>","text":"<p>Posterior distribution for an exponential likelihood with a gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>gamma_prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def exponential_gamma(x_total: NUMERIC, n: NUMERIC, gamma_prior: Gamma) -&gt; Gamma:\n    \"\"\"Posterior distribution for an exponential likelihood with a gamma prior.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        gamma_prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    \"\"\"\n    alpha_post, beta_post = get_exponential_gamma_posterior_params(\n        alpha=gamma_prior.alpha, beta=gamma_prior.beta, x_total=x_total, n=n\n    )\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.exponential_gamma_posterior_predictive","title":"<code>exponential_gamma_posterior_predictive(gamma)</code>","text":"<p>Posterior predictive distribution for an exponential likelihood with a gamma prior</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>Gamma</code> <p>Gamma distribution</p> required <p>Returns:</p> Type Description <code>Lomax</code> <p>Lomax distribution related to posterior predictive</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Exponential, Gamma\nfrom conjugate.models import exponential_gamma, expotential_gamma_posterior_predictive\n\ntrue = Exponential(1)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Gamma(1, 1)\n\nposterior = exponential_gamma(\n    n=n_samples,\n    x_total=data.sum(),\n    gamma_prior=prior\n)\n\nprior_predictive = expotential_gamma_posterior_predictive(prior)\nposterior_predictive = expotential_gamma_posterior_predictive(posterior)\n\nax = plt.subplot(111)\nprior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior predictive\")\ntrue.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"true distribution\")\nposterior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior predictive\")\nax.legend()\nplt.show()\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>def exponential_gamma_posterior_predictive(gamma: Gamma) -&gt; Lomax:\n    \"\"\"Posterior predictive distribution for an exponential likelihood with a gamma prior\n\n    Args:\n        gamma: Gamma distribution\n\n    Returns:\n        Lomax distribution related to posterior predictive\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Exponential, Gamma\n        from conjugate.models import exponential_gamma, expotential_gamma_posterior_predictive\n\n        true = Exponential(1)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Gamma(1, 1)\n\n        posterior = exponential_gamma(\n            n=n_samples,\n            x_total=data.sum(),\n            gamma_prior=prior\n        )\n\n        prior_predictive = expotential_gamma_posterior_predictive(prior)\n        posterior_predictive = expotential_gamma_posterior_predictive(posterior)\n\n        ax = plt.subplot(111)\n        prior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior predictive\")\n        true.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"true distribution\")\n        posterior_predictive.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior predictive\")\n        ax.legend()\n        plt.show()\n        ```\n    \"\"\"\n    return Lomax(alpha=gamma.beta, lam=gamma.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.geometric_beta","title":"<code>geometric_beta(x_total, n, beta_prior, one_start=True)</code>","text":"<p>Posterior distribution for a geometric likelihood with a beta prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <p>sum of all trials outcomes</p> required <code>n</code> <p>total number of trials</p> required <code>beta_prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <code>one_start</code> <code>bool</code> <p>whether to outcomes start at 1, defaults to True. False is 0 start.</p> <code>True</code> <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> Source code in <code>conjugate/models.py</code> <pre><code>def geometric_beta(x_total, n, beta_prior: Beta, one_start: bool = True) -&gt; Beta:\n    \"\"\"Posterior distribution for a geometric likelihood with a beta prior.\n\n    Args:\n        x_total: sum of all trials outcomes\n        n: total number of trials\n        beta_prior: Beta distribution prior\n        one_start: whether to outcomes start at 1, defaults to True. False is 0 start.\n\n    Returns:\n        Beta distribution posterior\n\n    \"\"\"\n    alpha_post = beta_prior.alpha + n\n    beta_post = beta_prior.beta + x_total\n\n    if one_start:\n        beta_post = beta_post - n\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.hypergeometric_beta_binomial","title":"<code>hypergeometric_beta_binomial(x_total, n, beta_binomial_prior)</code>","text":"<p>Hypergeometric likelihood with a BetaBinomial prior.</p> <p>The total population size is N and is known. Encode it in the BetaBinomial     prior as n=N</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all trials outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of trials</p> required <code>beta_binomial_prior</code> <code>BetaBinomial</code> <p>BetaBinomial prior n is the known N / total population size</p> required <p>Returns:</p> Type Description <code>BetaBinomial</code> <p>BetaBinomial posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def hypergeometric_beta_binomial(\n    x_total: NUMERIC, n: NUMERIC, beta_binomial_prior: BetaBinomial\n) -&gt; BetaBinomial:\n    \"\"\"Hypergeometric likelihood with a BetaBinomial prior.\n\n    The total population size is N and is known. Encode it in the BetaBinomial\n        prior as n=N\n\n    Args:\n        x_total: sum of all trials outcomes\n        n: total number of trials\n        beta_binomial_prior: BetaBinomial prior\n            n is the known N / total population size\n\n    Returns:\n        BetaBinomial posterior distribution\n\n    \"\"\"\n    n = beta_binomial_prior.n\n    alpha_post = beta_binomial_prior.alpha + x_total\n    beta_post = beta_binomial_prior.beta + (n - x_total)\n\n    return BetaBinomial(n=n, alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.linear_regression","title":"<code>linear_regression(X, y, normal_inverse_gamma_prior, inv=np.linalg.inv)</code>","text":"<p>Posterior distribution for a linear regression model with a normal inverse gamma prior.</p> <p>Derivation taken from this blog here.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>y</code> <code>NUMERIC</code> <p>response vector</p> required <code>normal_inverse_gamma_prior</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma prior</p> required <code>inv</code> <p>function to invert matrix, defaults to np.linalg.inv</p> <code>inv</code> <p>Returns:</p> Type Description <code>NormalInverseGamma</code> <p>NormalInverseGamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def linear_regression(\n    X: NUMERIC,\n    y: NUMERIC,\n    normal_inverse_gamma_prior: NormalInverseGamma,\n    inv=np.linalg.inv,\n) -&gt; NormalInverseGamma:\n    \"\"\"Posterior distribution for a linear regression model with a normal inverse gamma prior.\n\n    Derivation taken from this blog [here](https://gregorygundersen.com/blog/2020/02/04/bayesian-linear-regression/).\n\n    Args:\n        X: design matrix\n        y: response vector\n        normal_inverse_gamma_prior: NormalInverseGamma prior\n        inv: function to invert matrix, defaults to np.linalg.inv\n\n    Returns:\n        NormalInverseGamma posterior distribution\n\n    \"\"\"\n    N = X.shape[0]\n\n    delta = inv(normal_inverse_gamma_prior.delta_inverse)\n\n    delta_post = (X.T @ X) + delta\n    delta_post_inverse = inv(delta_post)\n\n    mu_post = (\n        # (B, B)\n        delta_post_inverse\n        # (B, 1)\n        # (B, B) * (B, 1) +  (B, N) * (N, 1)\n        @ (delta @ normal_inverse_gamma_prior.mu + X.T @ y)\n    )\n\n    alpha_post = normal_inverse_gamma_prior.alpha + (0.5 * N)\n    beta_post = normal_inverse_gamma_prior.beta + (\n        0.5\n        * (\n            (y.T @ y)\n            # (1, B) * (B, B) * (B, 1)\n            + (normal_inverse_gamma_prior.mu.T @ delta @ normal_inverse_gamma_prior.mu)\n            # (1, B) * (B, B) * (B, 1)\n            - (mu_post.T @ delta_post @ mu_post)\n        )\n    )\n\n    return NormalInverseGamma(\n        mu=mu_post, delta_inverse=delta_post_inverse, alpha=alpha_post, beta=beta_post\n    )\n</code></pre>"},{"location":"models/#conjugate.models.linear_regression_posterior_predictive","title":"<code>linear_regression_posterior_predictive(normal_inverse_gamma, X, eye=np.eye)</code>","text":"<p>Posterior predictive distribution for a linear regression model with a normal inverse gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>normal_inverse_gamma</code> <code>NormalInverseGamma</code> <p>NormalInverseGamma posterior</p> required <code>X</code> <code>NUMERIC</code> <p>design matrix</p> required <code>eye</code> <p>function to get identity matrix, defaults to np.eye</p> <code>eye</code> <p>Returns:</p> Type Description <code>MultivariateStudentT</code> <p>MultivariateStudentT posterior predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def linear_regression_posterior_predictive(\n    normal_inverse_gamma: NormalInverseGamma, X: NUMERIC, eye=np.eye\n) -&gt; MultivariateStudentT:\n    \"\"\"Posterior predictive distribution for a linear regression model with a normal inverse gamma prior.\n\n    Args:\n        normal_inverse_gamma: NormalInverseGamma posterior\n        X: design matrix\n        eye: function to get identity matrix, defaults to np.eye\n\n    Returns:\n        MultivariateStudentT posterior predictive distribution\n\n    \"\"\"\n    mu = X @ normal_inverse_gamma.mu\n    sigma = (normal_inverse_gamma.beta / normal_inverse_gamma.alpha) * (\n        eye(X.shape[0]) + (X @ normal_inverse_gamma.delta_inverse @ X.T)\n    )\n    nu = 2 * normal_inverse_gamma.alpha\n\n    return MultivariateStudentT(\n        mu=mu,\n        sigma=sigma,\n        nu=nu,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.multinomial_dirichlet","title":"<code>multinomial_dirichlet(x, dirichlet_prior)</code>","text":"<p>Posterior distribution of Multinomial model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NUMERIC</code> <p>counts</p> required <code>dirichlet_prior</code> <code>Dirichlet</code> <p>Dirichlet prior on the counts</p> required <p>Returns:</p> Type Description <code>Dirichlet</code> <p>Dirichlet posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def multinomial_dirichlet(x: NUMERIC, dirichlet_prior: Dirichlet) -&gt; Dirichlet:\n    \"\"\"Posterior distribution of Multinomial model with Dirichlet prior.\n\n    Args:\n        x: counts\n        dirichlet_prior: Dirichlet prior on the counts\n\n    Returns:\n        Dirichlet posterior distribution\n\n    \"\"\"\n    alpha_post = get_dirichlet_posterior_params(dirichlet_prior.alpha, x)\n\n    return Dirichlet(alpha=alpha_post)\n</code></pre>"},{"location":"models/#conjugate.models.multinomial_dirichlet_posterior_predictive","title":"<code>multinomial_dirichlet_posterior_predictive(dirichlet, n=1)</code>","text":"<p>Posterior predictive distribution of Multinomial model with Dirichlet prior.</p> <p>Parameters:</p> Name Type Description Default <code>dirichlet</code> <code>Dirichlet</code> <p>Dirichlet distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1.</p> <code>1</code> Source code in <code>conjugate/models.py</code> <pre><code>def multinomial_dirichlet_posterior_predictive(\n    dirichlet: Dirichlet, n: NUMERIC = 1\n) -&gt; DirichletMultinomial:\n    \"\"\"Posterior predictive distribution of Multinomial model with Dirichlet prior.\n\n    Args:\n        dirichlet: Dirichlet distribution\n        n: Number of trials for each sample, defaults to 1.\n\n    \"\"\"\n\n    return DirichletMultinomial(n=n, alpha=dirichlet.alpha)\n</code></pre>"},{"location":"models/#conjugate.models.negative_binomial_beta","title":"<code>negative_binomial_beta(r, n, x, beta_prior)</code>","text":"<p>Posterior distribution for a negative binomial likelihood with a beta prior.</p> <p>Assumed known number of failures r</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>NUMERIC</code> <p>number of failures</p> required <code>n</code> <code>NUMERIC</code> <p>number of trials</p> required <code>x</code> <code>NUMERIC</code> <p>number of successes</p> required <code>beta_prior</code> <code>Beta</code> <p>Beta distribution prior</p> required <p>Returns:</p> Type Description <code>Beta</code> <p>Beta distribution posterior</p> Source code in <code>conjugate/models.py</code> <pre><code>def negative_binomial_beta(\n    r: NUMERIC, n: NUMERIC, x: NUMERIC, beta_prior: Beta\n) -&gt; Beta:\n    \"\"\"Posterior distribution for a negative binomial likelihood with a beta prior.\n\n    Assumed known number of failures r\n\n    Args:\n        r: number of failures\n        n: number of trials\n        x: number of successes\n        beta_prior: Beta distribution prior\n\n    Returns:\n        Beta distribution posterior\n\n    \"\"\"\n    alpha_post = beta_prior.alpha + (r * n)\n    beta_post = beta_prior.beta + x\n\n    return Beta(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.negative_binomial_beta_posterior_predictive","title":"<code>negative_binomial_beta_posterior_predictive(r, beta)</code>","text":"<p>Posterior predictive distribution for a negative binomial likelihood with a beta prior</p> <p>Assumed known number of failures r</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>NUMERIC</code> <p>number of failures</p> required <code>beta</code> <code>Beta</code> <p>Beta distribution</p> required <p>Returns:</p> Type Description <code>BetaNegativeBinomial</code> <p>BetaNegativeBinomial posterior predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def negative_binomial_beta_posterior_predictive(\n    r: NUMERIC, beta: Beta\n) -&gt; BetaNegativeBinomial:\n    \"\"\"Posterior predictive distribution for a negative binomial likelihood with a beta prior\n\n    Assumed known number of failures r\n\n    Args:\n        r: number of failures\n        beta: Beta distribution\n\n    Returns:\n        BetaNegativeBinomial posterior predictive distribution\n\n    \"\"\"\n    return BetaNegativeBinomial(r=r, alpha=beta.alpha, beta=beta.beta)\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_mean","title":"<code>normal_known_mean(x_total, x2_total, n, mu, inverse_gamma_prior)</code>","text":"<p>Posterior distribution for a normal likelihood with a known mean and a variance prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>x2_total</code> <code>NUMERIC</code> <p>sum of all outcomes squared</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>mu</code> <code>NUMERIC</code> <p>known mean</p> required <code>inverse_gamma_prior</code> <code>InverseGamma</code> <p>InverseGamma prior for variance</p> required <p>Returns:</p> Type Description <code>InverseGamma</code> <p>InverseGamma posterior distribution for the variance</p> Source code in <code>conjugate/models.py</code> <pre><code>def normal_known_mean(\n    x_total: NUMERIC,\n    x2_total: NUMERIC,\n    n: NUMERIC,\n    mu: NUMERIC,\n    inverse_gamma_prior: InverseGamma,\n) -&gt; InverseGamma:\n    \"\"\"Posterior distribution for a normal likelihood with a known mean and a variance prior.\n\n    Args:\n        x_total: sum of all outcomes\n        x2_total: sum of all outcomes squared\n        n: total number of samples in x_total\n        mu: known mean\n        inverse_gamma_prior: InverseGamma prior for variance\n\n    Returns:\n        InverseGamma posterior distribution for the variance\n\n    \"\"\"\n    alpha_post = inverse_gamma_prior.alpha + (n / 2)\n    beta_post = inverse_gamma_prior.beta + (\n        0.5 * (x2_total - (2 * mu * x_total) + (n * (mu**2)))\n    )\n\n    return InverseGamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.normal_known_mean_posterior_predictive","title":"<code>normal_known_mean_posterior_predictive(mu, inverse_gamma)</code>","text":"<p>Posterior predictive distribution for a normal likelihood with a known mean and a variance prior.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>NUMERIC</code> <p>known mean</p> required <code>inverse_gamma</code> <code>InverseGamma</code> <p>InverseGamma prior</p> required <p>Returns:</p> Type Description <code>StudentT</code> <p>StudentT posterior predictive distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def normal_known_mean_posterior_predictive(\n    mu: NUMERIC, inverse_gamma: InverseGamma\n) -&gt; StudentT:\n    \"\"\"Posterior predictive distribution for a normal likelihood with a known mean and a variance prior.\n\n    Args:\n        mu: known mean\n        inverse_gamma: InverseGamma prior\n\n    Returns:\n        StudentT posterior predictive distribution\n\n    \"\"\"\n    return StudentT(\n        n=2 * inverse_gamma.alpha,\n        mu=mu,\n        sigma=(inverse_gamma.beta / inverse_gamma.alpha) ** 0.5,\n    )\n</code></pre>"},{"location":"models/#conjugate.models.pareto_gamma","title":"<code>pareto_gamma(n, ln_x_total, x_m, gamma_prior, ln=np.log)</code>","text":"<p>Posterior distribution for a pareto likelihood with a gamma prior.</p> <p>The parameter x_m is assumed to be known.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>ln_x_total</code> <code>NUMERIC</code> <p>sum of the log of all outcomes</p> required <code>x_m</code> <code>NUMERIC</code> <p>The known minimum value</p> required <code>gamma_prior</code> <code>Gamma</code> <p>Gamma prior</p> required <code>ln</code> <p>function to take the natural log, defaults to np.log</p> <code>log</code> <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> <p>Examples:</p> <p>Constructed example</p> <pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import Pareto, Gamma\nfrom conjugate.models import pareto_gamma\n\nx_m_known = 1\ntrue = Pareto(x_m_known, 1)\n\nn_samples = 15\ndata = true.dist.rvs(size=n_samples, random_state=42)\n\nprior = Gamma(1, 1)\n\nposterior = pareto_gamma(\n    n=n_samples,\n    ln_x_total=np.log(data).sum(),\n    x_m=x_m_known,\n    gamma_prior=prior\n)\n\nax = plt.subplot(111)\nposterior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior\")\nprior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x_m_known, color=\"black\", linestyle=\"--\", label=\"true x_m\")\nax.legend()\nplt.show()\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>def pareto_gamma(\n    n: NUMERIC, ln_x_total: NUMERIC, x_m: NUMERIC, gamma_prior: Gamma, ln=np.log\n) -&gt; Gamma:\n    \"\"\"Posterior distribution for a pareto likelihood with a gamma prior.\n\n    The parameter x_m is assumed to be known.\n\n    Args:\n        n: number of samples\n        ln_x_total: sum of the log of all outcomes\n        x_m: The known minimum value\n        gamma_prior: Gamma prior\n        ln: function to take the natural log, defaults to np.log\n\n    Returns:\n        Gamma posterior distribution\n\n    Examples:\n        Constructed example\n\n        ```python\n        import numpy as np\n\n        import matplotlib.pyplot as plt\n\n        from conjugate.distributions import Pareto, Gamma\n        from conjugate.models import pareto_gamma\n\n        x_m_known = 1\n        true = Pareto(x_m_known, 1)\n\n        n_samples = 15\n        data = true.dist.rvs(size=n_samples, random_state=42)\n\n        prior = Gamma(1, 1)\n\n        posterior = pareto_gamma(\n            n=n_samples,\n            ln_x_total=np.log(data).sum(),\n            x_m=x_m_known,\n            gamma_prior=prior\n        )\n\n        ax = plt.subplot(111)\n        posterior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"posterior\")\n        prior.set_bounds(0, 2.5).plot_pdf(ax=ax, label=\"prior\")\n        ax.axvline(x_m_known, color=\"black\", linestyle=\"--\", label=\"true x_m\")\n        ax.legend()\n        plt.show()\n        ```\n\n    \"\"\"\n    alpha_post = gamma_prior.alpha + n\n    beta_post = gamma_prior.beta + ln_x_total - n * ln(x_m)\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.poisson_gamma","title":"<code>poisson_gamma(x_total, n, gamma_prior)</code>","text":"<p>Posterior distribution for a poisson likelihood with a gamma prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_total</code> <code>NUMERIC</code> <p>sum of all outcomes</p> required <code>n</code> <code>NUMERIC</code> <p>total number of samples in x_total</p> required <code>gamma_prior</code> <code>Gamma</code> <p>Gamma prior</p> required <p>Returns:</p> Type Description <code>Gamma</code> <p>Gamma posterior distribution</p> Source code in <code>conjugate/models.py</code> <pre><code>def poisson_gamma(x_total: NUMERIC, n: NUMERIC, gamma_prior: Gamma) -&gt; Gamma:\n    \"\"\"Posterior distribution for a poisson likelihood with a gamma prior.\n\n    Args:\n        x_total: sum of all outcomes\n        n: total number of samples in x_total\n        gamma_prior: Gamma prior\n\n    Returns:\n        Gamma posterior distribution\n\n    \"\"\"\n    alpha_post, beta_post = get_poisson_gamma_posterior_params(\n        alpha=gamma_prior.alpha, beta=gamma_prior.beta, x_total=x_total, n=n\n    )\n\n    return Gamma(alpha=alpha_post, beta=beta_post)\n</code></pre>"},{"location":"models/#conjugate.models.poisson_gamma_posterior_predictive","title":"<code>poisson_gamma_posterior_predictive(gamma, n=1)</code>","text":"<p>Posterior predictive distribution for a poisson likelihood with a gamma prior</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>Gamma</code> <p>Gamma distribution</p> required <code>n</code> <code>NUMERIC</code> <p>Number of trials for each sample, defaults to 1. Can be used to scale the distributions to a different unit of time.</p> <code>1</code> <p>Returns:</p> Type Description <code>NegativeBinomial</code> <p>NegativeBinomial distribution related to posterior predictive</p> Source code in <code>conjugate/models.py</code> <pre><code>def poisson_gamma_posterior_predictive(\n    gamma: Gamma, n: NUMERIC = 1\n) -&gt; NegativeBinomial:\n    \"\"\"Posterior predictive distribution for a poisson likelihood with a gamma prior\n\n    Args:\n        gamma: Gamma distribution\n        n: Number of trials for each sample, defaults to 1.\n            Can be used to scale the distributions to a different unit of time.\n\n    Returns:\n        NegativeBinomial distribution related to posterior predictive\n\n    \"\"\"\n    n = n * gamma.alpha\n    p = gamma.beta / (1 + gamma.beta)\n\n    return NegativeBinomial(n=n, p=p)\n</code></pre>"},{"location":"models/#conjugate.models.uniform_pareto","title":"<code>uniform_pareto(x_max, n, pareto_prior, max_fn=np.maximum)</code>","text":"<p>Posterior distribution for a uniform likelihood with a pareto prior.</p> <p>Parameters:</p> Name Type Description Default <code>x_max</code> <code>NUMERIC</code> <p>maximum value</p> required <code>n</code> <code>NUMERIC</code> <p>number of samples</p> required <code>pareto_prior</code> <code>Pareto</code> <p>Pareto prior</p> required <code>max_fn</code> <p>elementwise max function, defaults to np.maximum</p> <code>maximum</code> <p>Returns:</p> Type Description <code>Pareto</code> <p>Pareto posterior distribution</p> <p>Examples:</p> <p>Get the posterior for this model with simulated data:</p> <pre><code>from conjugate.distributions import Uniform, Pareto\nfrom conjugate.models import uniform_pareto\n\ntrue_max = 5\ntrue = Uniform(0, true_max)\n\nn_samples = 10\ndata = true.dist.rvs(size=n_samples)\n\nprior = Pareto(1, 1)\n\nposterior = uniform_pareto(\n    x_max=data.max(),\n    n=n_samples,\n    pareto_prior=prior\n)\n</code></pre> Source code in <code>conjugate/models.py</code> <pre><code>def uniform_pareto(\n    x_max: NUMERIC, n: NUMERIC, pareto_prior: Pareto, max_fn=np.maximum\n) -&gt; Pareto:\n    \"\"\"Posterior distribution for a uniform likelihood with a pareto prior.\n\n    Args:\n        x_max: maximum value\n        n: number of samples\n        pareto_prior: Pareto prior\n        max_fn: elementwise max function, defaults to np.maximum\n\n    Returns:\n        Pareto posterior distribution\n\n    Examples:\n        Get the posterior for this model with simulated data:\n\n        ```python\n        from conjugate.distributions import Uniform, Pareto\n        from conjugate.models import uniform_pareto\n\n        true_max = 5\n        true = Uniform(0, true_max)\n\n        n_samples = 10\n        data = true.dist.rvs(size=n_samples)\n\n        prior = Pareto(1, 1)\n\n        posterior = uniform_pareto(\n            x_max=data.max(),\n            n=n_samples,\n            pareto_prior=prior\n        )\n        ```\n\n    \"\"\"\n    alpha_post = pareto_prior.alpha + n\n    x_m_post = max_fn(pareto_prior.x_m, x_max)\n\n    return Pareto(x_m=x_m_post, alpha=alpha_post)\n</code></pre>"},{"location":"examples/bayesian-update/","title":"Bayesian Update","text":"<p>Easy to use Bayesian inference incrementally by making the posterior the prior for the next update.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseGamma\nfrom conjugate.models import linear_regression\n\ndef create_sampler(mu, sigma, rng): \n    \"\"\"Generate a sampler from a normal distribution with mean `mu` and standard deviation `sigma`.\"\"\"\n    def sample(n: int): \n        return rng.normal(loc=mu, scale=sigma, size=n)\n\n    return sample\n\n\nmu = 5.0\nsigma = 2.5\nrng = np.random.default_rng(0)\nsample = create_sampler(mu=mu, sigma=sigma, rng=rng)\n\n\nprior = NormalInverseGamma(\n    mu=np.array([0]), \n    delta_inverse=np.array([[1]]), \n    alpha=1, beta=1, \n)\n\n\ncumsum = 0\nbatch_sizes = [5, 10, 25]\nax = plt.gca()\nfor batch_size in batch_sizes:\n    y = sample(n=batch_size)\n    X = np.ones_like(y)[:, None]\n\n    posterior = linear_regression(X, y, prior)\n    beta_samples, variance_samples = posterior.sample_beta(size=1000, return_variance=True, random_state=rng)\n\n    cumsum += batch_size\n    label = f\"n={cumsum}\"\n    ax.scatter(variance_samples ** 0.5, beta_samples, alpha=0.25, label=label)\n\n    prior = posterior \n\nax.scatter(sigma, mu, color=\"black\", label=\"true\")\nax.set(\n    xlabel=\"$\\sigma$\", \n    ylabel=\"$\\mu$\", \n    xlim=(0, None), \n    ylim=(0, None), \n    title=\"Updated posterior samples of $\\mu$ and $\\sigma$\"\n)\nax.legend()\n\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/binomial/","title":"Binomial Model","text":"<pre><code>from conjugate.distributions import Beta, Binomial, BetaBinomial\nfrom conjugate.models import binomial_beta, binomial_beta_posterior_predictive\n\nimport matplotlib.pyplot as plt\n\nN = 10\ntrue_dist = Binomial(n=N, p=0.5)\n\n# Observed Data\nX = true_dist.dist.rvs(size=1, random_state=42)\n\n# Conjugate prior\nprior = Beta(alpha=1, beta=1)\nposterior: Beta = binomial_beta(n=N, x=X, beta_prior=prior)\n\n# Comparison\nprior_predictive: BetaBinomial = binomial_beta_posterior_predictive(n=N, beta=prior)\nposterior_predictive: BetaBinomial = binomial_beta_posterior_predictive(n=N, beta=posterior)\n\n# Figure \nfig, axes = plt.subplots(ncols=2, nrows=1, figsize=(8, 4))\n\nax: plt.Axes = axes[0]\nposterior.plot_pdf(ax=ax, label=\"posterior\")\nprior.plot_pdf(ax=ax, label=\"prior\")\nax.axvline(x=X/N, color=\"black\", ymax=0.05, label=\"MLE\")\nax.axvline(x=true_dist.p, color=\"black\", ymax=0.05, linestyle=\"--\", label=\"True\")\nax.set_title(\"Success Rate\")\nax.legend()\n\nax: plt.Axes = axes[1]\ntrue_dist.plot_pmf(ax=ax, label=\"true distribution\", color=\"C2\")\nposterior_predictive.plot_pmf(ax=ax, label=\"posterior predictive\")\nprior_predictive.plot_pmf(ax=ax, label=\"prior predictive\")\nax.axvline(x=X, color=\"black\", ymax=0.05, label=\"Sample\")\nax.set_title(\"Number of Successes\")\nax.legend()\n\nplt.show()\n</code></pre>"},{"location":"examples/generalized-inputs/","title":"Generalized Numerical Inputs","text":"<p>Though the plotting is meant for numpy and python numbers, the conjugate models work with anything that works like numbers. </p> <p>For instance, Bayesian models in SQL using the SQL Builder, PyPika</p> <pre><code>from pypika import Field \n\n# Columns from table in database\nN = Field(\"total\")\nX = Field(\"successes\")\n\n# Conjugate prior\nprior = Beta(alpha=1, beta=1)\nposterior = binomial_beta(n=N, x=X, beta_prior=prior)\n\nprint(\"Posterior alpha:\", posterior.alpha)\nprint(\"Posterior beta:\", posterior.beta)\n# Posterior alpha: 1+\"successes\"\n# Posterior beta: 1+\"total\"-\"successes\"\n\n# Priors can be fields too\nalpha = Field(\"previous_successes\") - 1\nbeta = Field(\"previous_failures\") - 1\n\nprior = Beta(alpha=alpha, beta=beta)\nposterior = binomial_beta(n=N, x=X, beta_prior=prior)\n\nprint(\"Posterior alpha:\", posterior.alpha)\nprint(\"Posterior beta:\", posterior.beta)\n# Posterior alpha: \"previous_successes\"-1+\"successes\"\n# Posterior beta: \"previous_failures\"-1+\"total\"-\"successes\"\n</code></pre> <p>Using PyMC distributions for sampling with additional uncertainty</p> <pre><code>import pymc as pm \n\nalpha = pm.Gamma.dist(alpha=1, beta=20)\nbeta = pm.Gamma.dist(alpha=1, beta=20)\n\n# Observed Data\nN = 10\nX = 4\n\n# Conjugate prior \nprior = Beta(alpha=alpha, beta=beta)\nposterior = binomial_beta(n=N, x=X, beta_prior=prior)\n\n# Reconstruct the posterior distribution with PyMC\nprior_dist = pm.Beta.dist(alpha=prior.alpha, beta=prior.beta)\nposterior_dist = pm.Beta.dist(alpha=posterior.alpha, beta=posterior.beta)\n\nsamples = pm.draw([alpha, beta, prior_dist, posterior_dist], draws=1000)\n</code></pre>"},{"location":"examples/indexing/","title":"Indexing Parameters","text":"<p>The distributions can be indexed for subsets. </p> <pre><code>beta = np.arange(1, 10)\nprior = Beta(alpha=1, beta=beta)\n\nidx = [0, 5, -1]\nprior_subset = prior[idx]\nprior_subset.plot_pdf(label = lambda i: f\"prior {i}\")\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/linear-regression/","title":"Linear Regression","text":"<p>We can fit linear regression that includes a predictive distribution for new data using a conjugate prior. This example only has one covariate, but the same approach can be used for multiple covariates.</p>"},{"location":"examples/linear-regression/#simulate-data","title":"Simulate Data","text":"<p>We are going to simulate data from a linear regression model. The true intercept is 3.5, the true slope is -2.0, and the true variance is 2.5.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom conjugate.distributions import NormalInverseGamma, MultivariateStudentT\nfrom conjugate.models import linear_regression, linear_regression_posterior_predictive\n\nintercept = 3.5\nslope = -2.0\nsigma = 2.5\n\nrng = np.random.default_rng(0)\n\nx_lim = 3\nn_points = 100\nx = np.linspace(-x_lim, x_lim, n_points)\ny = intercept + slope * x + rng.normal(scale=sigma, size=n_points)\n</code></pre>"},{"location":"examples/linear-regression/#define-prior-and-find-posterior","title":"Define Prior and Find Posterior","text":"<p>There needs to be a prior for the intercept, slope, and the variance. </p> <pre><code>prior = NormalInverseGamma(\n    mu=np.array([0, 0]),\n    delta_inverse=np.array([[1, 0], [0, 1]]),\n    alpha=1,\n    beta=1,\n)\n\ndef create_X(x: np.ndarray) -&gt; np.ndarray:\n    return np.stack([np.ones_like(x), x]).T\n\nX = create_X(x)\nposterior: NormalInverseGamma = linear_regression(\n    X=X,\n    y=y,\n    normal_inverse_gamma_prior=prior,\n)\n</code></pre>"},{"location":"examples/linear-regression/#posterior-predictive-for-new-data","title":"Posterior Predictive for New Data","text":"<p>The multivariate student-t distribution is used for the posterior predictive distribution. We have to draw samples from it since the scipy implementation does not have a <code>ppf</code> method.</p> <pre><code># New Data\nx_lim_new = 1.5 * x_lim\nx_new = np.linspace(-x_lim_new, x_lim_new, 20)\nX_new = create_X(x_new)\npp: MultivariateStudentT = linear_regression_posterior_predictive(normal_inverse_gamma=posterior, X=X_new)\n\nsamples = pp.dist.rvs(5_000).T\ndf_samples = pd.DataFrame(samples, index=x_new)\n</code></pre>"},{"location":"examples/linear-regression/#plot-results","title":"Plot Results","text":"<p>We can see that the posterior predictive distribution begins to widen as we move away from the data. </p> <p>Overall, the posterior predictive distribution is a good fit for the data. The true line is within the 95% posterior predictive interval.</p> <pre><code>def plot_abline(intercept: float, slope: float, ax: plt.Axes = None, **kwargs):\n    \"\"\"Plot a line from slope and intercept\"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    x_vals = np.array(ax.get_xlim())\n    y_vals = intercept + slope * x_vals\n    ax.plot(x_vals, y_vals, **kwargs)\n\n\ndef plot_lines(ax: plt.Axes, samples: np.ndarray, label: str, color: str, alpha: float):\n    for i, betas in enumerate(samples):\n        label = label if i == 0 else None\n        plot_abline(betas[0], betas[1], ax=ax, color=color, alpha=alpha, label=label)\n\n\nfig, ax = plt.subplots()\nax.set_xlim(-x_lim, x_lim)\nax.set_ylim(y.min(), y.max())\n\nax.scatter(x, y, label=\"data\")\n\nplot_lines(\n    ax=ax,\n    samples=prior.sample_beta(size=100, random_state=rng),\n    label=\"prior\",\n    color=\"blue\",\n    alpha=0.05,\n)\nplot_lines(\n    ax=ax,\n    samples=posterior.sample_beta(size=100, random_state=rng),\n    label=\"posterior\",\n    color=\"black\",\n    alpha=0.2,\n)\n\nplot_abline(intercept, slope, ax=ax, label=\"true\", color=\"red\")\n\nax.set(xlabel=\"x\", ylabel=\"y\", title=\"Linear regression with conjugate prior\")\n\n# New Data\nax.plot(x_new, pp.mu, color=\"green\", label=\"posterior predictive mean\")\ndf_quantile = df_samples.T.quantile([0.025, 0.975]).T\nax.fill_between(\n    x_new,\n    df_quantile[0.025],\n    df_quantile[0.975],\n    alpha=0.2,\n    color=\"green\",\n    label=\"95% posterior predictive interval\",\n)\nax.legend()\nax.set(xlim=(-x_lim_new, x_lim_new))\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/plotting/","title":"Plotting Distributions","text":"<p>All the distributions can be plotted using the <code>plot_pdf</code> and <code>plot_pmf</code> methods. The <code>plot_pdf</code> method is used for continuous distributions and the <code>plot_pmf</code> method is used for discrete distributions.</p> <p>There is limited support for some distributions like the <code>Dirichlet</code> or those without a <code>dist</code> scipy.</p> <pre><code>from conjugate.distributions import Beta, Gamma, Normal\n\nimport matplotlib.pyplot as plt\n\nbeta = Beta(1, 1)\ngamma = Gamma(1, 1)\nnormal = Normal(0, 1)\n\nbound = 3\n\ndist = [beta, gamma, normal]\nlabels = [\"beta\", \"gamma\", \"normal\"]\nax = plt.gca()\nfor label, dist in zip(labels, dist):\n    dist.set_bounds(-bound, bound).plot_pdf(label=label)\n\nax.legend()\nplt.show()\n</code></pre> <p></p> <p>The plotting is also supported for vectorized inputs.</p>"},{"location":"examples/pymc-sampling/","title":"Unsupported Posterior Predictive Distributions with PyMC Sampling","text":"<p>The geometric beta model posterior predictive doesn't have a common dist, but what doesn't mean the posterior predictive can be used. For instance, PyMC can be used to fill in this gap.</p> <pre><code>import pymc as pm\n\nfrom conjugate.distribution import Beta\nfrom conjugate.models import geometric_beta\n\nprior = Beta(1, 1)\nposterior: Beta = geometric_beta(x=1, n=10, beta_prior=prior)\n\nposterior_dist = pm.Beta.dist(alpha=posterior.alpha, beta=posterior.beta)\ngeometric_posterior_predictive = pm.Geometric.dist(posterior_dist)\n\nposterior_predictive_samples = pm.draw(geometric_posterior_predictive, draws=100)\n</code></pre>"},{"location":"examples/scaling-distributions/","title":"Scaling Distributions","text":"<p>Some of the distributions can be scaled by a constant factor or added together. For instance, operations with Poisson distribution represent the number of events in a given time interval. </p> <pre><code>from conjugate.distributions import Poisson\n\nimport matplotlib.pyplot as plt\n\ndaily_rate = 0.25\ndaily_pois = Poisson(lam=daily_rate)\n\ntwo_day_pois = daily_pois + daily_pois\nweekly_pois = 7 * daily_pois\n\nmax_value = 7\nax = plt.gca()\ndists = [daily_pois, two_day_pois, weekly_pois]\nbase_labels = [\"daily\", \"two day\", \"weekly\"]\nfor dist, base_label in zip(dists, base_labels):\n    label = f\"{base_label} rate={dist.lam}\"\n    dist.set_max_value(max_value).plot_pmf(ax=ax, label=label)\n\nax.legend()\nplt.show()\n</code></pre> <p></p> <p>The normal distribution also supports scaling making use of the fact that the variance of a scaled normal distribution is the square of the scaling factor. </p> <pre><code>from conjugate.distributions import Normal\n\nimport matplotlib.pyplot as plt\n\nnorm = Normal(mu=0, sigma=1)\nnorm_times_2 = norm * 2\n\nbound = 6\nax = norm.set_bounds(-bound, bound).plot_pdf(label=f\"normal (std = {norm.sigma:.2f})\")\nnorm_times_2.set_bounds(-bound, bound).plot_pdf(ax=ax, label=f\"normal * 2 (std = {norm_times_2.sigma:.2f})\")\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/scipy-connection/","title":"Connection to SciPy Distributions","text":"<p>Many distributions have the <code>dist</code> attribute which is a scipy.stats distribution object. From there, the methods from scipy.stats to get the pdf, cdf, etc can be leveraged.</p> <pre><code>from conjugate.distribution import Beta \n\nbeta = Beta(1, 1)\nscipy_dist = beta.dist \n\nprint(scipy_dist.mean())\n# 0.5\nprint(scipy_dist.ppf([0.025, 0.975]))\n# [0.025 0.975]\n\nsamples = scipy_dist.rvs(100)\n</code></pre>"},{"location":"examples/vectorized-inputs/","title":"Vectorized Inputs","text":"<p>All data and priors will allow for vectorized assuming the shapes work for broadcasting. </p> <p>The plotting also supports arrays of results</p> <pre><code>import numpy as np\n\nfrom conjugate.distributions import Beta\nfrom conjugate.models import binomial_beta\n\nimport matplotlib.pyplot as plt\n\n# Analytics \nprior = Beta(alpha=1, beta=np.array([1, 5]))\nposterior = binomial_beta(n=N, x=x, beta_prior=prior)\n\n# Figure\nax = prior.plot_pdf(label=lambda i: f\"prior {i}\")\nposterior.plot_pdf(ax=ax, label=lambda i: f\"posterior {i}\")\nax.axvline(x=x / N, ymax=0.05, color=\"black\", linestyle=\"--\", label=\"MLE\")\nax.legend()\nplt.show()\n</code></pre> <p></p>"}]}